{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "3zqR49yEqi20",
        "JUt-1vt-0hDs",
        "ktzXa7MLNsS6",
        "kZ0JjBcaO_jr",
        "Ekx8wA37NMza",
        "EnbApG4bMwK4",
        "JitXyLJkM0Bi",
        "0UwZwUujSS_3",
        "bFXUmnfHcQIw",
        "5ixnONjXcQIw",
        "XChjoIdNcQIx",
        "w4PTSSzuxnor",
        "qMGup-e4v9cs",
        "QlsYpRO7xzI-",
        "xXcS9cEEog_-",
        "a2sJDB9koszz",
        "02nniCcbqmGm",
        "48XBTguQo67U",
        "FHaXCCwypFs5",
        "_tK2ycCTpMAu",
        "WnyAVDSxp7VD",
        "8I2NA8UVqD5N",
        "YiKDtWIeqO_Y",
        "GSaKQFvUqT5Y",
        "7wpzRnC9yFMr",
        "TDn6oD7e0ElF",
        "fKkeCtn40Ze8",
        "gEswKcgk0hHC",
        "FxlJoJdh0pq7",
        "JcvJ7_Q40pq9",
        "KlOU0UIN6oYb",
        "DSOrkT-J6swH",
        "rc-1ugrf7GWO",
        "P2P7coJ4idF0",
        "qTkUdqDuiqtK",
        "vnmrr63WlJ5V",
        "CoYqWkw9mr2N",
        "1lksDO4vnpBy",
        "DTGDp_c598wy",
        "G84zJbI_-GYr",
        "BUb-aUQy-GYu",
        "5VA9d8oj_aNH",
        "Nx6mwxVr_cms",
        "0H_I5RHv_cmv",
        "AzEyN2kg_-I8",
        "bvdqMX49ABjd",
        "tEYasryCABje",
        "dVEXyZscAcd9",
        "xm0gqrdNAftN",
        "pOc-dMuwAftR",
        "WWKeMOeiAv8n",
        "fvv4oIKNA5KL",
        "hNJSgWfeA5KN",
        "fjKvGJmy6pp6",
        "Epb7q6ss6sMk",
        "Qiw-NjUA7YYB",
        "bQVSQrUY7YYC",
        "gL1fqaL6IJBc",
        "lhceUZP2Kd-L",
        "zuLVa8tXYVFB",
        "qu7T4XziYZRh",
        "sEtjerCDZgIR",
        "aHkJy5BWaNa_",
        "mlB_gx9wa350",
        "thf8efD9e1wu",
        "kCnQc6BpNNjG",
        "WMA_VrOpPlST",
        "MsexGBUHQJPm",
        "6465mT-kV-hL",
        "pBfQpcCZhzwQ",
        "Q8Sdkq0Iqeg6",
        "jSHodfEBq0Qn",
        "R328g6FXq6pe",
        "6GsCyYlCrFNo",
        "gyYWuKXqsoR_",
        "rXhJOgSTsyaN",
        "6FwiilDps6-L",
        "gKj3fTGftCDC",
        "9eW-CnOKtQ_c",
        "bAKCD7dZtapD",
        "kFMTgE-utdzC",
        "Fsa4bdqXwGRt",
        "klXtR1T2tzkM",
        "Va8VZOlSs0KH",
        "a4iR1bx2s2Lx",
        "7T0E7IzWtK_X",
        "CaJiovidtjvr",
        "O5uNO_SStrwO",
        "aKRc6t9mt4SV",
        "domuVpa8uCc5",
        "fu_X2CwVuFHT",
        "g-Q5dzcwuYHT",
        "eIXdTcJfoy2p",
        "FYG-ZBINo0na",
        "Oyqc2ndNviAN",
        "fvR0QMWXwkJV",
        "iFi80ckvwl9x",
        "ugJvdQ2CxLzr",
        "P1eDY6O0y7Wi",
        "8L6vIHYYQrgS",
        "Iztnkw-2Spcv",
        "9CSHt1n1QtvO",
        "yepBvVQfwk-_",
        "yn1ndjIAVcY8",
        "iT3EjMGBw4QV",
        "hNbI7_evYia4",
        "IDnYziGj4jWj",
        "FG9OEirPSx0f",
        "4moqWeoTSx0h",
        "bFb-gM5rSx0j",
        "PDmD2JVGPxkM",
        "iKmf-kmluewb",
        "5bo-6oWMuq4t",
        "8OrqKnSPutzQ",
        "u0wZg1tYu35A",
        "0sUn02AIu_HB",
        "97na4TsvvAkR",
        "aiqDiYOGvKd1",
        "bC_ZlBgVvRBL",
        "QXPPzbLUNeD4",
        "ivxEbXWXvV5e",
        "K5xKCDYXvgOk",
        "oJZVvULmvzET",
        "fZZLn4p-wOUf",
        "RORVPjA1v64c",
        "XoyZJjVGv85c",
        "GYiKELZqwA_c",
        "5mGv5cOpwH9q",
        "kFbUOtBFwKB8",
        "OggZKodGeQ_X",
        "NPXtLy7qxln-",
        "W8xUHzNHxsAb",
        "cwcNnLdbxvcE",
        "PqRzk8dcN2Pd",
        "fUEc1pQsOO6V",
        "BSNigeqbQD7p",
        "g9FtJfQ2Qbg2",
        "886FmcQIyumF",
        "KLC1jEiGy18L",
        "gXz_Mprsy-Ld",
        "euZtuB-RzBw4",
        "UHoZ5jMFzKKR",
        "MiaTnJrRzRvZ",
        "Ar0Lmxc5zTIN",
        "HiiWapgkzdAa",
        "j-uqDxhKzukq",
        "AYYr-Zeizxzu",
        "ShI0kD_Rz134",
        "hlBBXr8r0D5m",
        "oekVvRth0N8p",
        "0_HEgsAm0W9F",
        "Hc5W1mh-wU2e",
        "fv-PYKr9wWZM",
        "8coRZDU_xG_F",
        "YageqrfN_r_q",
        "fuludRueADi2",
        "tq5hoG9kB8rY",
        "NkMLYklTDAPh",
        "nzvy6T7ZDJrD",
        "n8a9lPUuDZja",
        "mpe2ENO9CzTZ",
        "10jnwWztDqiv",
        "1eXYOVzJEGvI",
        "hOng-Sw5EYxC",
        "1rea9zwNV7Yo",
        "-B1m3G8jV9l3",
        "f22fdexIWKAr",
        "LWYH3IfOWXF1",
        "oUgS9Fo2WfrT",
        "A3bB1UAe2DSe",
        "D4vLLcCF6rI3",
        "uoG7v_C87CKI",
        "c-UtTvg_7gm5",
        "bf8PzyeW8Mpj",
        "ZwnJ9pYU81YL",
        "aAhv-pU-9Ayd",
        "L8y3PWB1jLnv",
        "O3Ujeei0hd0K",
        "Yd26Q6zjhfjv",
        "JstvUkhsh-Kd",
        "pjNjFqQDif61",
        "gt7mqb89jEpw",
        "JDSwy0lZjdAt",
        "w1RxxYJWjnGo",
        "k392FVRpjpHl",
        "4Az7PKTrj4bU",
        "91mPAjaxj9t9",
        "dDFYrpOAkH64",
        "t9mFCcUGozcI",
        "UND0AbFNpJpP",
        "r-j5pYqupkAr",
        "WzqjUmT-qNI5",
        "izI4DOngrVq8",
        "FtFgkrLKrtIV",
        "QMPeqFbAr1ZZ",
        "MDkHhX5ysLrc",
        "7qq0yxvhsfiU",
        "r-etOMfNt8Hm",
        "4pxLw3PxuPPb",
        "s8C4JWwCxfvL",
        "8JoEPiAYx-dr",
        "vHJBH3ssyAW7",
        "12y-o-SIyXjo",
        "DA742WRL3OVh",
        "D7-P8-Vp3eTq",
        "lvJ3yLVP3nFc",
        "L3Z2MALI3wdX",
        "oCCyxSDi3zKe",
        "WXqMwBC14BM2",
        "wbhXcvOf4XnS",
        "HFHrWjUqNjBX",
        "AWk9DayQ5FmR",
        "kCxJ4vUuf3aI",
        "OOnr0nBEf_40",
        "e7lrmPN8gWCJ",
        "JA5m_6o6gjaL",
        "moVKrMt4gwG0",
        "2HXE9z-EhG2F",
        "7WDRf8j6inhe",
        "uJvgOuwWiqto",
        "w6GuaCcTuDj8",
        "1JBl5zA5uq9A",
        "1SvKrwMdveil",
        "T22iug6e70XT",
        "MUNND7X372kq",
        "URkwZDeJDftL",
        "3ExbHxlrDjB5",
        "bsZVChf9L-iA",
        "2B89ZrDnEE1n",
        "r_CuMvbvKptV",
        "gRA72DjO-yP4",
        "Wip-SOTKOPos",
        "ysDyqPEi_FXX",
        "3UurIfvi_PQ_",
        "nv-vSRnh-GLy",
        "dpSZsQJj-GLz",
        "QuSEyRvyGDZs",
        "lgeUqtWJIMpo",
        "mc_Y6Uk1ULuP",
        "VQ1Pay4rdvVu",
        "NghkOs4jePk9",
        "h6GGVkjtiG6x",
        "Nb8zsQpWjVRw",
        "y6OIA4U7a2XR",
        "Y2Ls5mRia2Xc",
        "stiaDpj7a2Xe",
        "nR5CnAnchQ2M",
        "NYWNNrPnhQ2M",
        "WuN0PY0rhQ2Y",
        "AQ6WJyqQeEv6",
        "3HzgDvTeeEv8",
        "vGdncYoReEv_",
        "SLmVzNz0e8_7",
        "DC9-i5mKe8_-",
        "G5a6xHSme9AA",
        "M0VCKuY3gGaI",
        "WnDObQkxgGaK",
        "iOmO3MsigGaQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Prep"
      ],
      "metadata": {
        "id": "j5VoVBcVmgbM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library Import"
      ],
      "metadata": {
        "id": "99P9BqsWnO8R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkYR-vnKlqwt"
      },
      "outputs": [],
      "source": [
        "from ast import literal_eval\n",
        "import math\n",
        "import os\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "warnings.filterwarnings(action= 'ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Drive"
      ],
      "metadata": {
        "id": "GSVRuh7Xm-XZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "Tpi-uxpVmeYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copy Files from Drive"
      ],
      "metadata": {
        "id": "wHhI0m5jnbym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir update_changes/\n",
        "# !mkdir update_changes/20220816\n",
        "# !mkdir update_changes/20220816/cleaned\n",
        "# !cp -r /content/drive/MyDrive/update_changes/20220816/cleaned/* ./update_changes/20220816/cleaned/"
      ],
      "metadata": {
        "id": "EFEs1zyxnr65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -r update_changes"
      ],
      "metadata": {
        "id": "zjAbAkwtHd3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Folder Prep"
      ],
      "metadata": {
        "id": "QW9EB-0Pn7gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "APK_DATE = \"20220816\"\n",
        "MAIN_DIR = \"./update_changes\"\n",
        "MAIN_CLEANED_DIR = f\"{MAIN_DIR}/{APK_DATE}/cleaned\"\n",
        "MAIN_PARSED_DIR = f\"{MAIN_DIR}/{APK_DATE}/parsed\"\n",
        "\n",
        "if not os.path.isdir(MAIN_PARSED_DIR):\n",
        "  os.mkdir(MAIN_PARSED_DIR)"
      ],
      "metadata": {
        "id": "Ssp0pJHsn5rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Initializtion"
      ],
      "metadata": {
        "id": "Wda6OiBhoN3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_id_value(text: str, context: str, with_underscore: bool = False) -> tuple:\n",
        "  \"\"\"\n",
        "  Get the id for the key this id will be used\n",
        "  to connect the information to the other\n",
        "  tables (basically primary key for the information\n",
        "  provided)\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  text\n",
        "    Text in the form of the data dump mostly it \n",
        "    looks like this\n",
        "    `[\"AttrPool_11010023\"]=\"Refine to +9, ATK +5%\",`\n",
        "  context\n",
        "    The name of the key before the id, for \n",
        "    example for the text above, the context will\n",
        "    be `AttrPool`\n",
        "  with_underscore\n",
        "    Whether the attr contains underscore in its name\n",
        "    or not\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  id, value\n",
        "    tuple containing id and value of the attr\n",
        "  \"\"\"\n",
        "  \n",
        "  regex = f'\\\"{context}([\\d\\ \\_]*)\\\"]=\\\"(.*)\\\"'\n",
        "\n",
        "  if with_underscore:\n",
        "    regex = f'\\\"{context}_(\\w*)\\\"]=\\\"(.*)\\\"'\n",
        "\n",
        "  return re.findall(regex, text)[0]\n",
        "\n",
        "def create_and_add_entry(context: str, key: str, with_underscore: bool) -> None:\n",
        "  \"\"\"\n",
        "  Create entry for table and append it to the\n",
        "  existing dictionary\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  context\n",
        "    The name of the key before the id, for \n",
        "    example for the text above, the context will\n",
        "    be `AttrPool`\n",
        "  key\n",
        "    The name of the key in the dictionary\n",
        "  with_underscore\n",
        "    Whether the attr contains underscore in its name\n",
        "    or not\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  None\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    entry = {}\n",
        "\n",
        "    id, value = get_id_value(text, context, with_underscore=with_underscore)\n",
        "    entry[\"id\"] = id\n",
        "    entry[\"value\"] = value\n",
        "\n",
        "    parsed_data[key].append(entry)\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "nv3Dd_QPn_I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_and_convert(texts):\n",
        "  texts = \" \".join(texts)\n",
        "  texts = re.sub(r'\\[([\\w\\\"]+)\\]=', '\\g<1>:', texts)\n",
        "  texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "  texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "  texts = texts.replace(\"{}\", \"[]\")\n",
        "  texts = texts.replace(\"{ {\", \"[ {\")\n",
        "  texts = texts.replace(\"} }\", \"} ]\")\n",
        "\n",
        "  texts = \"{\" + texts + \"}\"\n",
        "\n",
        "  parsed_dict = literal_eval(texts)\n",
        "\n",
        "  return parsed_dict"
      ],
      "metadata": {
        "id": "Coy_322b-hnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parser"
      ],
      "metadata": {
        "id": "9mOG4TqroUnj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## En_langs"
      ],
      "metadata": {
        "id": "1KhUiMyeoYsR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Declare RE for cleaning Chinese chars"
      ],
      "metadata": {
        "id": "3zqR49yEqi20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RE = re.compile(u'[⺀-⺙⺛-⻳⼀-⿕々〇〡-〩〸-〺〻㐀-䶵一-鿃豈-鶴侮-頻並-龎]', re.UNICODE)"
      ],
      "metadata": {
        "id": "I8yCihsvqh9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "JUt-1vt-0hDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_data = {\n",
        "    \"area_name\": [],\n",
        "    \"area_name_new\": [],\n",
        "    \"attr_pool\": [],\n",
        "    \"attr\": [],\n",
        "    \"battle_pass_quest_desc\": [],\n",
        "    \"battle_pass_quest_name\": [],\n",
        "    \"size\": [],\n",
        "    \"buff_desc\": [],\n",
        "    \"buff_name\": [],\n",
        "    \"card_attr_desc\": [],\n",
        "    \"card_coordinates\": [],\n",
        "    \"equip_desc\": [],\n",
        "    \"equip_name\": [],\n",
        "    \"equip_type\": [],\n",
        "    \"goods_desc\": [],\n",
        "    \"item_desc\": [],\n",
        "    \"item_name\": [],\n",
        "    \"item_type\": [],\n",
        "    \"instance_description\": [],\n",
        "    \"job_name\": [],\n",
        "    \"mvp_desc\": [],\n",
        "    \"mvp_name\": [],\n",
        "    \"map_npc_name\": [],\n",
        "    \"monster_desc\": [],\n",
        "    \"monster_name\": [],\n",
        "    \"monster_type\": [],\n",
        "    \"ox_exam_question\": [],\n",
        "    \"property\": [],\n",
        "    \"race\": [],\n",
        "    \"scene_name\": [],\n",
        "    \"shadow_weapon\": [],\n",
        "    \"shadow_weapon_name\": [],\n",
        "    \"shadow_weapon_task\": [],\n",
        "    \"shadow_weapon_task_name\": [],\n",
        "    \"shadow_weapon_prop_des\": [],\n",
        "    \"skill_name\": [],\n",
        "    \"skill_desc\": [],\n",
        "    \"suit_name\": [],\n",
        "    \"title\": [],\n",
        "    \"weather\": [],\n",
        "    \"weather_desc\": [],\n",
        "    \"mount_name\": [],\n",
        "    \"mount_desc\": [],\n",
        "    \"mount_job\": [],\n",
        "    \"scene_name\": []\n",
        "}\n",
        "\n",
        "# Initially I want to create something like this for DRY, but for\n",
        "# the sake of readability will do it manually\n",
        "# contexts = [\"Areaname\", \"AttrPool\", \"Attr\", \"BattlePassQuestDesc\"]\n",
        "\n",
        "with open(f\"{MAIN_CLEANED_DIR}/en_langs.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for text in filename.readlines():\n",
        "    if text.startswith('[\"areaname'):\n",
        "      create_and_add_entry(\"areaname\", \"area_name\", False)\n",
        "    elif text.startswith('[\"Areaname'):\n",
        "      create_and_add_entry(\"Areaname\", \"area_name_new\", False)\n",
        "    elif text.startswith('[\"AttrPool'):\n",
        "      create_and_add_entry(\"AttrPool\", \"attr_pool\", True)\n",
        "    elif text.startswith('[\"Attr'):\n",
        "      create_and_add_entry(\"Attr\", \"attr\", True)\n",
        "    elif text.startswith('[\"BattlePassQuestDesc'):\n",
        "      create_and_add_entry(\"BattlePassQuestDesc\", \"battle_pass_quest_desc\", True)\n",
        "    elif text.startswith('[\"BattlePassQuestName'):\n",
        "      create_and_add_entry(\"BattlePassQuestName\", \"battle_pass_quest_desc\", True)\n",
        "    elif text.startswith('[\"Body'):\n",
        "      create_and_add_entry(\"Body\", \"body\", True)\n",
        "    elif text.startswith('[\"BuffDes'):\n",
        "      create_and_add_entry(\"BuffDes\", \"buff_desc\", True)\n",
        "    elif text.startswith('[\"BuffName'):\n",
        "      create_and_add_entry(\"BuffName\", \"buff_name\", True)\n",
        "    elif text.startswith('[\"CardAttributeDescription'):\n",
        "      create_and_add_entry(\"CardAttributeDescription\", \"card_attr_desc\", True)\n",
        "    elif text.startswith('[\"CardCoordinates'):\n",
        "      create_and_add_entry(\"CardCoordinates\", \"card_coordinates\", True)\n",
        "    elif text.startswith('[\"EquipDesc'):\n",
        "      create_and_add_entry(\"EquipDesc\", \"equip_desc\", True)\n",
        "    elif text.startswith('[\"EquipName'):\n",
        "      create_and_add_entry(\"EquipName\", \"equip_name\", True)\n",
        "    elif text.startswith('[\"equipmentType'):\n",
        "      create_and_add_entry(\"equipmentType\", \"equip_type\", True)\n",
        "    elif text.startswith('[\"GoodsDes'):\n",
        "      create_and_add_entry(\"GoodsDes\", \"goods_desc\", False)\n",
        "    elif text.startswith('[\"ItemDes'):\n",
        "      create_and_add_entry(\"ItemDes\", \"item_desc\", True)\n",
        "    elif text.startswith('[\"ItemName'):\n",
        "      create_and_add_entry(\"ItemName\", \"item_name\", True)\n",
        "    elif text.startswith('[\"ItemType'):\n",
        "      create_and_add_entry(\"ItemType\", \"item_type\", False)\n",
        "    elif text.startswith('[\"InstanceDescription'):\n",
        "      create_and_add_entry(\"InstanceDescription\", \"instance_description\", False)\n",
        "    elif text.startswith('[\"JobName'):\n",
        "      create_and_add_entry(\"JobName\", \"job_name\", True)\n",
        "    elif text.startswith('[\"JobName'):\n",
        "      create_and_add_entry(\"JobName\", \"job_name\", True)\n",
        "    elif text.startswith('[\"MVPDes'):\n",
        "      create_and_add_entry(\"MVPDes\", \"mvp_desc\", True)\n",
        "    elif text.startswith('[\"MVPName'):\n",
        "      create_and_add_entry(\"MVPName\", \"mvp_name\", True)\n",
        "    elif text.startswith('[\"MapNpcName'):\n",
        "      create_and_add_entry(\"MapNpcName\", \"map_npc_name\", False)\n",
        "    elif text.startswith('[\"MonsterCollection'):\n",
        "      create_and_add_entry(\"MonsterCollection\", \"monster_desc\", False)\n",
        "    elif text.startswith('[\"MonsterName'):\n",
        "      create_and_add_entry(\"MonsterName\", \"monster_name\", False)\n",
        "    elif text.startswith('[\"MonsterType'):\n",
        "      create_and_add_entry(\"MonsterType\", \"monster_type\", True)\n",
        "    elif text.startswith('[\"OXExam'):\n",
        "      create_and_add_entry(\"OXExam\", \"ox_exam_question\", True)\n",
        "    elif text.startswith('[\"Property'):\n",
        "      create_and_add_entry(\"Property\", \"property\", False)\n",
        "    elif text.startswith('[\"Race'):\n",
        "      create_and_add_entry(\"Race\", \"race\", True)\n",
        "    elif text.startswith('[\"SceneName'):\n",
        "      create_and_add_entry(\"SceneName\", \"scene_name\", False)\n",
        "    elif text.startswith('[\"ShadowWeaponName'):\n",
        "      create_and_add_entry(\"ShadowWeaponName\", \"shadow_weapon_name\", True)\n",
        "    elif text.startswith('[\"ShadowWeaponTaskName'):\n",
        "      create_and_add_entry(\"ShadowWeaponTaskName\", \"shadow_weapon_task_name\", True)\n",
        "    elif text.startswith('[\"ShadowWeaponPropDes'):\n",
        "      create_and_add_entry(\"ShadowWeaponPropDes\", \"shadow_weapon_prop_des\", True)\n",
        "    elif text.startswith('[\"ShadowWeaponTask'):\n",
        "      create_and_add_entry(\"ShadowWeaponTask\", \"shadow_weapon_task\", True)\n",
        "    elif text.startswith('[\"SkillDesc'):\n",
        "      create_and_add_entry(\"SkillDesc\", \"skill_desc\", True)\n",
        "    elif text.startswith('[\"SkillName'):\n",
        "      create_and_add_entry(\"SkillName\", \"skill_name\", True)\n",
        "    elif text.startswith('[\"SuitName'):\n",
        "      create_and_add_entry(\"SuitName\", \"suit_name\", False)\n",
        "    elif text.startswith('[\"Title'):\n",
        "      create_and_add_entry(\"Title\", \"title\", True)\n",
        "    elif text.startswith('[\"WeatherDes'):\n",
        "      create_and_add_entry(\"WeatherDes\", \"weather_desc\", True)\n",
        "    elif text.startswith('[\"Weather'):\n",
        "      create_and_add_entry(\"Weather\", \"weather\", True)\n",
        "    elif text.startswith('[\"SceneName'):\n",
        "      create_and_add_entry(\"SceneName\", \"scene_name\", True)"
      ],
      "metadata": {
        "id": "QsPzGebpoRS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skill"
      ],
      "metadata": {
        "id": "ktzXa7MLNsS6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get information from `en_langs`"
      ],
      "metadata": {
        "id": "kZ0JjBcaO_jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_name_df = pd.DataFrame(parsed_data[\"skill_name\"]).rename(columns={\"value\": \"name\"})\n",
        "skill_desc_df = pd.DataFrame(parsed_data[\"skill_desc\"]).rename(columns={\"value\": \"description\"})"
      ],
      "metadata": {
        "id": "aRhSP8eYOBJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_df = pd.merge(skill_name_df, skill_desc_df, how=\"left\", left_on=\"id\", right_on=\"id\")"
      ],
      "metadata": {
        "id": "Plq8dfktNW6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_final_df = skill_df.copy()"
      ],
      "metadata": {
        "id": "iDIEly8YN0a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "Ekx8wA37NMza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_final_df.to_csv(f\"{MAIN_PARSED_DIR}/skill_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "t6Sa99-UPH6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skill Advanced"
      ],
      "metadata": {
        "id": "EnbApG4bMwK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "JitXyLJkM0Bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "LIMIT = 999999\n",
        "\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_skill_Skill.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for i, text in enumerate(filename.readlines()):\n",
        "    if i == LIMIT:\n",
        "      break\n",
        "    else:\n",
        "      texts.append(text.strip())\n",
        "\n",
        "  texts = \" \".join(texts)\n",
        "\n",
        "  texts = re.sub(r'\\[([\\w\\\"]+)\\]=', '\\g<1>:', texts)\n",
        "  texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "  texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "  texts = texts.replace(\"{}\", \"[]\")\n",
        "  texts = texts.replace(\"{ {\", \"[ {\")\n",
        "  texts = texts.replace(\"} } }, {\", \"AAAAA\")\n",
        "  texts = texts.replace(\"} } } }\", \"BBBBB\")\n",
        "  texts = texts.replace(\"} } }\", \"XXXXX\")\n",
        "  texts = texts.replace(\"} }, {\", \"ZZZZZ\")\n",
        "  texts = texts.replace(\"} }\", \"YYYYY\")\n",
        "  texts = texts.replace(\"XXXXX\", \"} } ]\")\n",
        "  texts = texts.replace(\"ZZZZZ\", \"} }, {\")\n",
        "  texts = texts.replace(\"YYYYY\", \"} ]\")\n",
        "  texts = texts.replace(\"AAAAA\", \"} ] }, {\")\n",
        "  texts = texts.replace(\"BBBBB\", \"} ] } ]\")\n",
        "\n",
        "  texts = \"{\" + texts + \"}\"\n",
        "  skills = literal_eval(texts)"
      ],
      "metadata": {
        "id": "zU5Cw1E5i0nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "0UwZwUujSS_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_entries = []\n",
        "\n",
        "for id, parsed_dict in skills.items():\n",
        "  skill_entry = {}\n",
        "  default_key_dict = {\n",
        "      \"is_mount_combat\": \"IsMountCombat\",\n",
        "      \"range\": \"range\",\n",
        "      \"is_damage_skill\": \"IsDamageSkill\",\n",
        "      \"require_mount_combat\": \"RequireMountCombat\",\n",
        "      \"skill_group_id\" : \"SkillGroupID\",\n",
        "      \"max_level\" : \"MaxLevel\",\n",
        "      \"pre_skill\" : \"PreSkill\",\n",
        "      \"extra_range_skill_id\": \"ExtraRangeSkillId\",\n",
        "      \"buff_list\": \"BuffList\",\n",
        "      \"type\": \"Type\",\n",
        "      \"cooldown\": \"CoolDown\",\n",
        "      \"related_buff\" : \"RelatedBuff\",\n",
        "      \"pet_skill_type\": \"PetSkillType\",\n",
        "      \"must_equip\": \"mustEquip\",\n",
        "      \"job\": \"Job\",\n",
        "      \"max_hp_cost\": \"MaxHpCost\",\n",
        "      \"skill_id\": \"SkillId\",\n",
        "      \"is_pet_skill_can_use_when_master_die\": \"IsPetSkillCanUseWhenMasterDie\",\n",
        "      \"auto_battle_type\": \"AutoBattleType\",\n",
        "      \"skill_weapon\": \"SkillWeapon\",\n",
        "      \"cost_zeny\": \"CostZeny\",\n",
        "      \"name\": \"Name\",\n",
        "      \"desc_args\": \"Desc_args\",\n",
        "      \"combo\": \"combo\",\n",
        "      \"skill_sketch\": \"SkillSketch\",\n",
        "      \"res_id\": \"ResID\",\n",
        "      \"require_mount_id\": \"RequireMountID\",\n",
        "      \"pet_skill_element\": \"PetSkillElement\",\n",
        "      \"desc\": \"Desc\",\n",
        "      \"fixed_cooldown\": \"FixedCoolDown\",\n",
        "      \"suit_skills_or_not\": \"SuitSkillsOrNot\",\n",
        "      \"pre_item\": 'PreItem',\n",
        "      \"cost_item\": \"CostItem\",\n",
        "      \"cost\": \"Cost\",\n",
        "      \"is_show_skill_tree\": \"isShowSkillTree\",\n",
        "\n",
        "  }\n",
        "  \n",
        "  skill_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      skill_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  skill_entries.append(skill_entry)\n",
        "\n",
        "skill_df = pd.DataFrame(skill_entries)"
      ],
      "metadata": {
        "id": "NbVoSeDXrhS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge with information from `en_langs`"
      ],
      "metadata": {
        "id": "bFXUmnfHcQIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_df = skill_df.fillna(\"-9999\")"
      ],
      "metadata": {
        "id": "3AQ-kXkWs9hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Skill name\n"
      ],
      "metadata": {
        "id": "5ixnONjXcQIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_name_df = pd.DataFrame(parsed_data[\"skill_name\"]).rename(columns={\"id\": \"skill_name_id\", \"value\": \"name\"})\n",
        "\n",
        "skill_df[\"skill_name_id\"] = skill_df[\"name\"].str.replace(\"SkillName_\", \"\")\n",
        "skill_df = skill_df.drop(\"name\", axis=1)\n",
        "skill_df = pd.merge(skill_df, skill_name_df, how=\"left\", left_on=[\"skill_name_id\"], right_on=[\"skill_name_id\"])\n"
      ],
      "metadata": {
        "id": "JqHCLT_7fndZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Skill description"
      ],
      "metadata": {
        "id": "XChjoIdNcQIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "isnull = skill_df[\"desc\"].isnull()\n",
        "skill_df.loc[isnull, 'desc'] = pd.Series([[None]] * isnull.sum()).values\n",
        "skill_df[\"desc\"] = skill_df[\"desc\"].apply(list).str[0]\n",
        "\n",
        "skill_df[\"skill_desc_id\"] = skill_df[\"desc\"].str.replace(\"SkillDesc_\", \"\")\n",
        "skill_df = skill_df.drop(\"desc\", axis=1)\n",
        "\n",
        "skill_desc_df = pd.DataFrame(parsed_data[\"skill_desc\"]).rename(columns={\"id\": \"skill_desc_id\", \"value\": \"desc\"})\n",
        "skill_df = pd.merge(skill_df, skill_desc_df, how=\"left\", left_on=[\"skill_desc_id\"], right_on=[\"skill_desc_id\"])"
      ],
      "metadata": {
        "id": "hGwLRIgpvRS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fix missing values"
      ],
      "metadata": {
        "id": "w4PTSSzuxnor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_df[\"is_damage_skill\"] = skill_df[\"is_damage_skill\"].fillna(1)\n",
        "\n",
        "skill_df[\"type\"] = skill_df[\"type\"].fillna(1)\n",
        "\n",
        "isnull = skill_df[\"cooldown\"].isnull()\n",
        "skill_df.loc[isnull, 'cooldown'] = pd.Series([[None]] * isnull.sum()).values\n",
        "skill_df[\"cooldown\"] = skill_df[\"cooldown\"].apply(list).str[0]\n",
        "\n",
        "isnull = skill_df[\"cost\"].isnull()\n",
        "skill_df.loc[isnull, 'cost'] = pd.Series([[None]] * isnull.sum()).values\n",
        "skill_df[\"cost\"] = skill_df[\"cost\"].apply(list).str[0]\n",
        "\n",
        "skill_df[\"is_mount_combat\"] = skill_df[\"is_mount_combat\"].fillna(0)\n",
        "\n",
        "skill_df[\"is_show_skill_tree\"] = skill_df[\"is_show_skill_tree\"].fillna(0)"
      ],
      "metadata": {
        "id": "eTmWN53hw1-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select columns for database"
      ],
      "metadata": {
        "id": "qMGup-e4v9cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_final_df = skill_df[[\"id\", \"name\", \"desc\", \"skill_group_id\", \"is_damage_skill\", \"max_level\", \"type\", \"cooldown\", \"job\", \"res_id\", \"cost\", \"is_mount_combat\", \"is_show_skill_tree\", \"skill_weapon\", \"fixed_cooldown\", \"combo\", \"range\", \"require_mount_combat\", \"pet_skill_type\", \"is_pet_skill_can_use_when_master_die\", \"pet_skill_element\", \"suit_skills_or_not\"]]"
      ],
      "metadata": {
        "id": "T_bDz9grwBcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_final_df = skill_final_df.rename(columns={\"desc\": \"description\", \"skill_group_id\": \"group_id\"})"
      ],
      "metadata": {
        "id": "VVBN6_0oxdNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_final_df[\"skill_weapon\"] = skill_final_df[\"skill_weapon\"].apply(lambda x: np.nan if x == [] else x)"
      ],
      "metadata": {
        "id": "23JVgLqbVgMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_final_df[\"fixed_cooldown\"] = skill_final_df[\"fixed_cooldown\"].apply(lambda x: np.nan if x == [] else x[0])"
      ],
      "metadata": {
        "id": "vBVn9SGSudGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save for database"
      ],
      "metadata": {
        "id": "QlsYpRO7xzI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_complex_final_df = skill_final_df.drop(\"skill_weapon\", axis=1)"
      ],
      "metadata": {
        "id": "lxELxNN5tIKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_complex_final_df.to_csv(f\"{MAIN_PARSED_DIR}/skill_complex_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "7AOTEgM-x1Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Item\n"
      ],
      "metadata": {
        "id": "xXcS9cEEog_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get item information from `en_langs`"
      ],
      "metadata": {
        "id": "a2sJDB9koszz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "item_name_df = pd.DataFrame(parsed_data[\"item_name\"])\n",
        "item_desc_df = pd.DataFrame(parsed_data[\"item_desc\"])\n",
        "item_type_df = pd.DataFrame(parsed_data[\"item_type\"])"
      ],
      "metadata": {
        "id": "JqW26rkuofoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "02nniCcbqmGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "LIMIT = 9999999\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_item_Item.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for i, text in enumerate(filename.readlines()):\n",
        "    if i == LIMIT:\n",
        "      break\n",
        "    else:\n",
        "      texts.append(text.strip())\n",
        "    \n",
        "  texts = \" \".join(texts)\n",
        "\n",
        "  texts = re.sub(r'\\[([\\w\\\"]+)\\] =', '\\g<1>:', texts)\n",
        "  texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "  texts = re.sub(r'\\{([\\d\\, ]+)\\}', '[\\g<1>]', texts)\n",
        "  texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "  \n",
        "  # print(texts)\n",
        "\n",
        "  texts = texts.replace(\"{ {\", \"AAAAA\")\n",
        "  texts = texts.replace(\"}, }, },\", \"BBBBB\")\n",
        "  texts = texts.replace(\"}, }, {\", \"DDDDD\")\n",
        "  texts = re.sub(r'\\}, \\}, (\\d)', 'FFFFF \\g<1>', texts)\n",
        "  texts = re.sub(r'\\}, \\},$', 'EEEEE', texts)\n",
        "  texts = texts.replace(\"}, },\", \"CCCCC\")\n",
        "\n",
        "  texts = texts.replace(\"AAAAA\", \"[ {\")\n",
        "  texts = texts.replace(\"BBBBB\", \"}, }, ],\")\n",
        "  texts = texts.replace(\"CCCCC\", \"}, ],\")\n",
        "  texts = texts.replace(\"DDDDD\", \"}, }, {\")\n",
        "  texts = texts.replace(\"EEEEE\", \"}, },\")\n",
        "  texts = texts.replace(\"FFFFF\", \"}, }, \")\n",
        "\n",
        "  texts = \"{\" + texts + \"}\"\n",
        "  \n",
        "\n",
        "  # print(texts)\n",
        "\n",
        "items = literal_eval(texts)\n",
        "# print(len(items))"
      ],
      "metadata": {
        "id": "aH90zT6-BEQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "48XBTguQo67U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "item_entries = []\n",
        "\n",
        "for id, parsed_dict in items.items():\n",
        "  item_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"cd\": \"cd\",\n",
        "      \"item_desc\": \"itemDesc\",\n",
        "      \"item_type\": \"itemType\",\n",
        "      \"max_stack\": \"maxStack\",\n",
        "      \"page\": \"page\",\n",
        "      \"res_id\": \"resId\",\n",
        "      \"stackable\": \"stackable\",\n",
        "      \"weight\": \"weight\",\n",
        "      \"static_id\": \"staticId\",\n",
        "      \"card_attrs\": \"CardAttrs\",\n",
        "      \"card_quality\": \"cardQuality\",\n",
        "      \"card_slots\": \"cardSlots\",\n",
        "      \"deposite_attrs\": \"DepositeAttrs\",\n",
        "      \"is_mvp_card\": \"IsMvpCard\",\n",
        "      \"item_subtype\": \"itemSubType\",\n",
        "      \"min_level\": \"minLevel\",\n",
        "      \"monster_id\": \"monster_id\",\n",
        "      \"name\": \"name\",\n",
        "      \"unlock_adventure_exp\": \"UnlockAdventureExp\",\n",
        "      \"expired_date\": \"ExpiredDate\",\n",
        "      \"is_bind\": \"isBind\",\n",
        "      \"item_expired_type\": \"itemExpiredType\",\n",
        "      \"sub_page\": \"subPage\",\n",
        "      \"is_hide\": \"isHide\",\n",
        "      \"use\": \"use\",\n",
        "      \"show_in_ui\": \"showInUi\",\n",
        "      \"acquire\": \"Acquire\",\n",
        "      \"card_coordinate_point\": \"CardCoordinatePoint\",\n",
        "      \"is_in_collection\": \"IsInCollection\",\n",
        "      \"monster\": \"Monster\",\n",
        "      \"sell_price\": \"SellPrice\",\n",
        "      \"area_id\": \"AreaId\",\n",
        "      \"cd_group_id\": 'CdGroupId',\n",
        "      \"cd_type\": 'CdType',\n",
        "      \"element\": 'Element',\n",
        "      \"exp\": 'Exp',\n",
        "      \"fish_rod_type\": 'FishRodType',\n",
        "      \"fish_tool_type\": 'FishToolType',\n",
        "      \"gift_send_limit\": 'GiftSendLimit',\n",
        "      \"if_can_quick_use\": 'IfCanQuickUse',\n",
        "      \"if_combined_for_life\": 'IfCombinedForLife',\n",
        "      \"if_get_off_mount\": 'IfGetOffMount',\n",
        "      \"if_stop_navigation\": 'IfStopNavigation',\n",
        "      \"interface_id\": 'InterfaceId',\n",
        "      \"is_gift_item\": 'IsGiftItem',\n",
        "      \"item_quality\": 'ItemQuality',\n",
        "      \"item_static_id\": 'ItemStaticId',\n",
        "      \"max_use\": 'MaxUse',\n",
        "      \"mine_tool_type\": 'MineToolType',\n",
        "      \"npc_id\": \"NpcId\",\n",
        "      \"npc_navigation\": 'NpcNavigation',\n",
        "      \"oon_box_loot_bind_status\": 'OONBoxLootBindStatus',\n",
        "      \"oon_box_loot_id\": 'OONBoxLootId',\n",
        "      \"oon_box_loot_number\": 'OONBoxLootNumber',\n",
        "      \"oon_box_loot_type\": 'OONBoxLootType',\n",
        "      \"pet_pill_bullet_id\": 'PetPillBulletId',\n",
        "      \"pet_pill_fixed_damage_rate\": 'PetPillFixedDamageRate',\n",
        "      \"pet_pill_max_damage\": 'PetPillMaxDamage',\n",
        "      \"related_activity_type\": 'RelatedActivityType',\n",
        "      \"related_pet_skill\": 'RelatedPetSkill',\n",
        "      \"scene_id\": 'SceneId',\n",
        "      \"sell_navigation\": 'SellNavigation',\n",
        "      \"sell_price\": 'SellPrice',\n",
        "      \"stall_currency_type\": 'StallCurrencyType',\n",
        "      \"stall_item_level\": 'StallItemLevel',\n",
        "      \"stall_price_lower_limit\": 'StallPriceLowerLimit',\n",
        "      \"stall_price_type\": 'StallPriceType',\n",
        "      \"stall_price_upper_limit\": 'StallPriceUpperLimit',\n",
        "      \"stall_type\": 'StallType',\n",
        "      \"stall_zeny_child_label\": 'StallZenyChildLabel',\n",
        "      \"is_all_job\": 'isAllJob',\n",
        "      \"is_bind\": 'isBind',\n",
        "      \"item_expired_type\": 'itemExpiredType',\n",
        "      \"item_subtype_task\": 'itemSubTypeTask',\n",
        "      \"job_limit\": 'jobLimit',\n",
        "      \"min_level\": 'minLevel',\n",
        "      \"pet_cage_type\": 'petcagetype',\n",
        "      \"related_gm_activity_type\": 'relatedGMActivityType',\n",
        "      \"res_id\": 'resId',\n",
        "      \"stackable\": 'stackable',\n",
        "      \"static_id\": 'staticId',\n",
        "  }\n",
        "\n",
        "  item_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      item_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  item_entries.append(item_entry)\n",
        "\n",
        "item_df = pd.DataFrame(item_entries)"
      ],
      "metadata": {
        "id": "D8R5f8-MKUap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge with information from `en_langs`"
      ],
      "metadata": {
        "id": "FHaXCCwypFs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Item name\n"
      ],
      "metadata": {
        "id": "_tK2ycCTpMAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "item_name_df = item_name_df.rename(columns={\"value\": \"item_name\"})\n",
        "item_df[\"id\"] = item_df[\"id\"].apply(int)\n",
        "item_name_df[\"id\"] = item_name_df[\"id\"].apply(int)\n",
        "item_df = pd.merge(item_df, item_name_df, how=\"left\", left_on=\"id\", right_on=\"id\")"
      ],
      "metadata": {
        "id": "49x9yh6_o_sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Item description"
      ],
      "metadata": {
        "id": "WnyAVDSxp7VD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "item_desc_df[\"id\"] = item_desc_df[\"id\"].apply(lambda x: f\"ItemDes_{x}\")\n",
        "item_desc_df = item_desc_df.rename(columns={\"id\": \"item_desc\", \"value\": \"item_desc_en\"})\n",
        "item_df = pd.merge(item_df, item_desc_df, how=\"left\", left_on=\"item_desc\", right_on=\"item_desc\")"
      ],
      "metadata": {
        "id": "-664TvlIp6cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Item type"
      ],
      "metadata": {
        "id": "8I2NA8UVqD5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "item_df[\"item_type\"] = item_df[\"item_type\"].fillna(0).apply(int)\n",
        "item_df[\"item_subtype\"] = item_df[\"item_subtype\"].fillna(0).apply(int)\n",
        "item_df[\"item_type_subtype\"] = item_df.apply(lambda x: f'{x[\"item_type\"]}_{x[\"item_subtype\"]}', axis=1)\n",
        "item_type_df = item_type_df.rename(columns={\"id\": \"item_type_subtype\", \"value\": \"item_type_en\"})\n",
        "item_df = pd.merge(item_df, item_type_df, how=\"left\", left_on=\"item_type_subtype\", right_on=\"item_type_subtype\")"
      ],
      "metadata": {
        "id": "vozVvY_YqCn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save raw data"
      ],
      "metadata": {
        "id": "YiKDtWIeqO_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "item_df.to_csv(f\"{MAIN_PARSED_DIR}/item_raw_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "hxoSFyjYqHYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "GSaKQFvUqT5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "item_df.loc[(~item_df[\"card_coordinate_point\"].isnull()), 'res_id'] = 99999\n",
        "item_final_df = item_df[[\"id\", \"item_name\", \"item_desc_en\", \"res_id\", \"item_type_en\", \"cd\", \"max_stack\", \"stackable\", \"weight\", \"sell_price\", \"stall_price_lower_limit\", \"stall_price_upper_limit\", \"item_quality\"]]\n",
        "item_final_df[\"res_id\"] = item_final_df[\"res_id\"].fillna(item_final_df[\"id\"])\n",
        "item_final_df = item_final_df[~item_final_df[\"item_name\"].isnull()]\n",
        "\n",
        "item_final_df = item_final_df.rename(columns={\n",
        "    \"item_name\": \"name\",\n",
        "    \"item_desc_en\": \"description\",\n",
        "    \"res_id\": \"res_id\",\n",
        "    \"item_type_en\": \"type\",\n",
        "    \"item_quality\": \"quality\"\n",
        "    })\n",
        "\n",
        "item_final_df[\"type\"] = item_final_df[\"type\"].fillna(\"Uncategorized\")\n",
        "item_final_df[\"name\"] = item_final_df[\"name\"].str.lower()\n",
        "item_final_df[\"is_visible\"] = item_final_df[\"id\"].apply(lambda x: 0 if x < 20000 else 1)\n",
        "\n",
        "item_final_df.to_csv(f\"{MAIN_PARSED_DIR}/item_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "ptcwCXATqRpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skill Preitem"
      ],
      "metadata": {
        "id": "7wpzRnC9yFMr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for dataframe creation"
      ],
      "metadata": {
        "id": "TDn6oD7e0ElF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_pre_item_records = skill_df[~skill_df[\"pre_item\"].isnull()][[\"id\", \"pre_item\"]].to_dict(orient=\"records\")"
      ],
      "metadata": {
        "id": "x3IV2TmKzM-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_pre_item_fins = []\n",
        "\n",
        "for record in skill_pre_item_records:\n",
        "  if record[\"pre_item\"] != {}:\n",
        "    for pre_item in record[\"pre_item\"]:\n",
        "      skill_pre_item_fin = {}\n",
        "      skill_pre_item_fin[\"skill_id\"] = record[\"id\"]\n",
        "      skill_pre_item_fin[\"item_id\"] = pre_item[\"ItemId\"]\n",
        "      skill_pre_item_fin[\"item_num\"] = pre_item[\"Number\"]\n",
        "      \n",
        "      skill_pre_item_fins.append(skill_pre_item_fin)"
      ],
      "metadata": {
        "id": "Pi-zshkEyuD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_pre_item_df = pd.DataFrame(skill_pre_item_fins)"
      ],
      "metadata": {
        "id": "aHN8kc9kyuIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intersections = set(skill_pre_item_df[\"skill_id\"].astype(float)).intersection(set(skill_complex_final_df[\"id\"].astype(float)))\n",
        "skill_pre_item_df = skill_pre_item_df[skill_pre_item_df[\"skill_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "intersections = set(skill_pre_item_df[\"item_id\"].astype(float)).intersection(set(item_final_df[\"id\"].astype(float)))\n",
        "skill_pre_item_df = skill_pre_item_df[skill_pre_item_df[\"item_id\"].astype(float).isin(intersections)]"
      ],
      "metadata": {
        "id": "kZWArX9bMe9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_pre_item_final_df = skill_pre_item_df.reset_index().rename(columns={\"index\": \"id\"})"
      ],
      "metadata": {
        "id": "yzgjvoIxyuNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save for database"
      ],
      "metadata": {
        "id": "fKkeCtn40Ze8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_pre_item_final_df.to_csv(f\"{MAIN_PARSED_DIR}/skill_pre_item_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "CKp8HP_Q0Ze_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skill Buff"
      ],
      "metadata": {
        "id": "gEswKcgk0hHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for dataframe creation"
      ],
      "metadata": {
        "id": "FxlJoJdh0pq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_buff_list_records = skill_df[~skill_df[\"buff_list\"].isnull()][[\"id\", \"buff_list\"]].to_dict(orient=\"records\")"
      ],
      "metadata": {
        "id": "p7T6ij0a0pq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_buff_list_fins = []\n",
        "\n",
        "for record in skill_buff_list_records:\n",
        "  if record[\"buff_list\"] != {}:\n",
        "    for buff_list in list(record[\"buff_list\"]):\n",
        "      skill_buff_list_fin = {}\n",
        "      skill_buff_list_fin[\"skill_id\"] = record[\"id\"]\n",
        "      skill_buff_list_fin[\"buff\"] = buff_list\n",
        "      \n",
        "      skill_buff_list_fins.append(skill_buff_list_fin)"
      ],
      "metadata": {
        "id": "ABLZG5HA0pq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_buff_df = pd.DataFrame(skill_buff_list_fins)"
      ],
      "metadata": {
        "id": "sY_pQvBV0pq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intersections = set(skill_buff_df[\"skill_id\"].astype(float)).intersection(set(skill_complex_final_df[\"id\"].astype(float)))\n",
        "skill_buff_df = skill_buff_df[skill_buff_df[\"skill_id\"].astype(float).isin(intersections)]"
      ],
      "metadata": {
        "id": "TBE4DtpNN1mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_buff_final_df = skill_buff_df.reset_index().rename(columns={\"index\": \"id\"})"
      ],
      "metadata": {
        "id": "GKybZ-Qk0pq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save for database"
      ],
      "metadata": {
        "id": "JcvJ7_Q40pq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_buff_final_df.to_csv(f\"{MAIN_PARSED_DIR}/skill_buff_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "_Z-6_omb0pq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skill Cost Item"
      ],
      "metadata": {
        "id": "KlOU0UIN6oYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for dataframe creation"
      ],
      "metadata": {
        "id": "DSOrkT-J6swH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_cost_item_records = skill_df[~skill_df[\"cost_item\"].isnull()][[\"id\", \"cost_item\"]].to_dict(orient=\"records\")"
      ],
      "metadata": {
        "id": "aC7XccrC6swI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_cost_item_fins = []\n",
        "\n",
        "for record in skill_cost_item_records:\n",
        "  if record[\"cost_item\"] != {}:\n",
        "    for cost_item in record[\"cost_item\"]:\n",
        "      skill_cost_item_fin = {}\n",
        "      skill_cost_item_fin[\"skill_id\"] = record[\"id\"]\n",
        "      skill_cost_item_fin[\"item_id\"] = cost_item[\"ItemId\"]\n",
        "      skill_cost_item_fin[\"item_num\"] = cost_item[\"Number\"]\n",
        "      \n",
        "      skill_cost_item_fins.append(skill_cost_item_fin)"
      ],
      "metadata": {
        "id": "V_K1JcUz6swI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_cost_item_df = pd.DataFrame(skill_cost_item_fins)"
      ],
      "metadata": {
        "id": "8yD_XW-t6swJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_cost_item_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "hMrrgp7H6QAt",
        "outputId": "e7920210-74c9-4b84-fc94-b2968d297ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   skill_id   item_id  item_num\n",
              "0    199994  10202072         1\n",
              "1    199995  10202070         1\n",
              "2    199995  10202071         1\n",
              "3    199996  10202157         1\n",
              "4    199997  10202158         1\n",
              "5    199997  10202159         1\n",
              "6    199997  10202160         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-deeb085c-e83f-4f5a-a33d-933f68d0e501\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>skill_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>item_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>199994</td>\n",
              "      <td>10202072</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>199995</td>\n",
              "      <td>10202070</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>199995</td>\n",
              "      <td>10202071</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>199996</td>\n",
              "      <td>10202157</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>199997</td>\n",
              "      <td>10202158</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>199997</td>\n",
              "      <td>10202159</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>199997</td>\n",
              "      <td>10202160</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-deeb085c-e83f-4f5a-a33d-933f68d0e501')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-deeb085c-e83f-4f5a-a33d-933f68d0e501 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-deeb085c-e83f-4f5a-a33d-933f68d0e501');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intersections = set(skill_cost_item_df[\"skill_id\"].astype(float)).intersection(set(skill_complex_final_df[\"id\"].astype(float)))\n",
        "skill_cost_item_df = skill_cost_item_df[skill_cost_item_df[\"skill_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "intersections = set(skill_cost_item_df[\"item_id\"].astype(float)).intersection(set(item_final_df[\"id\"].astype(float)))\n",
        "skill_cost_item_df = skill_cost_item_df[skill_cost_item_df[\"item_id\"].astype(float).isin(intersections)]"
      ],
      "metadata": {
        "id": "a72zq1tDOoMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_cost_item_final_df = skill_cost_item_df.reset_index().rename(columns={\"index\": \"id\"})"
      ],
      "metadata": {
        "id": "ssEEOTL-6swJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save for database"
      ],
      "metadata": {
        "id": "rc-1ugrf7GWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_cost_item_final_df.to_csv(f\"{MAIN_PARSED_DIR}/skill_cost_item_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "L-4oXmFu7GWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skill Factor"
      ],
      "metadata": {
        "id": "P2P7coJ4idF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "qTkUdqDuiqtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "LIMIT = 9029399292\n",
        "# with open(f\"test.txt\", \"r\", encoding=\"utf8\") as filename:\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_SkillFactor.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for i, text in enumerate(filename.readlines()):\n",
        "    if i == LIMIT:\n",
        "      break\n",
        "    else:\n",
        "      texts.append(text.strip())\n",
        "\n",
        "texts = \" \".join(texts)\n",
        "texts = re.sub(r'([A-Za-z]+) =', '\"\\g<1>\" :', texts)\n",
        "texts = re.sub(r'\\[[\\d]+\\] = ', '', texts)\n",
        "\n",
        "# texts += ']'\n",
        "\n",
        "skill_factors = literal_eval(texts)"
      ],
      "metadata": {
        "id": "vqx9M7HQiqtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame"
      ],
      "metadata": {
        "id": "vnmrr63WlJ5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_factor_entries = []\n",
        "\n",
        "for skill_factor in skill_factors:\n",
        "  skill_factor_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"id\": \"Id\",\n",
        "      \"factor_name\": \"FactorName\",\n",
        "      \"factor_order\": \"FactorOrder\",\n",
        "      \"final_factor\": \"FinalFactor\",\n",
        "      \"skill_id\": \"SkillId\",\n",
        "      \"skill_level\": \"SkillLevel\"\n",
        "  }\n",
        "\n",
        "  try:\n",
        "    skill_factor_entry[\"id\"] = skill_factor[\"Id\"]\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      skill_factor_entry[col] = skill_factor[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  skill_factor_entries.append(skill_factor_entry)\n",
        "\n",
        "skill_factor_df = pd.DataFrame(skill_factor_entries)"
      ],
      "metadata": {
        "id": "QQGwpfPvAvh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fix missing values"
      ],
      "metadata": {
        "id": "CoYqWkw9mr2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_factor_df[\"factor_order\"] = skill_factor_df[\"factor_order\"].fillna(1)\n",
        "skill_factor_df[\"id\"] = skill_factor_df[\"id\"].fillna(1)\n",
        "skill_factor_df[\"skill_level\"] = skill_factor_df[\"skill_level\"].fillna(1)\n",
        "skill_factor_df[\"skill_id\"] = skill_factor_df[\"skill_id\"].fillna(0)\n",
        "skill_factor_df[\"final_factor\"] = skill_factor_df[\"final_factor\"].fillna(20)"
      ],
      "metadata": {
        "id": "n4or4JgRmWVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save for database"
      ],
      "metadata": {
        "id": "1lksDO4vnpBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intersections = set(skill_factor_df[\"skill_id\"].astype(int)).intersection(set(skill_complex_final_df[\"id\"].astype(int)))\n",
        "skill_factor_final_df = skill_factor_df[skill_factor_df[\"skill_id\"].astype(int).isin(intersections)]\n",
        "\n",
        "skill_factor_final_df.to_csv(f\"{MAIN_PARSED_DIR}/skill_factor_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "DqdtNDrenpBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skill Description Arguments"
      ],
      "metadata": {
        "id": "DTGDp_c598wy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for dataframe creation"
      ],
      "metadata": {
        "id": "G84zJbI_-GYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_desc_args_records = skill_df[skill_df[\"desc_args\"].str.len() != 0][[\"id\", \"desc_args\"]].to_dict(orient=\"records\")"
      ],
      "metadata": {
        "id": "pmxbBC_m-GYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_desc_args_fins = []\n",
        "\n",
        "for record in skill_desc_args_records:\n",
        "  if record[\"desc_args\"] != []:\n",
        "    for desc_args in record[\"desc_args\"]:\n",
        "      skill_desc_args_fin = {}\n",
        "      skill_desc_args_fin[\"skill_id\"] = record[\"id\"]\n",
        "      skill_desc_args_fin[\"factor\"] = desc_args[\"Factor\"]\n",
        "      skill_desc_args_fin[\"factor_bit\"] = desc_args[\"FactorBit\"]\n",
        "      skill_desc_args_fin[\"level_type\"] = desc_args[\"LevelType\"]\n",
        "\n",
        "      try:\n",
        "        skill_desc_args_fin[\"type\"] = desc_args[\"type\"]\n",
        "      except:\n",
        "        pass\n",
        "      \n",
        "      skill_desc_args_fins.append(skill_desc_args_fin)\n",
        "\n",
        "skill_desc_args_df = pd.DataFrame(skill_desc_args_fins)"
      ],
      "metadata": {
        "id": "7Q2nj9pg-GYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intersections = set(skill_desc_args_df[\"skill_id\"].astype(int)).intersection(set(skill_complex_final_df[\"id\"].astype(int)))\n",
        "skill_factor_final_df = skill_desc_args_df[skill_desc_args_df[\"skill_id\"].astype(int).isin(intersections)]"
      ],
      "metadata": {
        "id": "7W7-pUOGPMpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_desc_args_final_df = skill_desc_args_df.reset_index().rename(columns={\"index\": \"id\"})"
      ],
      "metadata": {
        "id": "LEYNA925-GYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save for database"
      ],
      "metadata": {
        "id": "BUb-aUQy-GYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_desc_args_final_df.to_csv(f\"{MAIN_PARSED_DIR}/skill_desc_args_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "xDdgDzlC-GYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skill Preskill"
      ],
      "metadata": {
        "id": "5VA9d8oj_aNH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for dataframe creation"
      ],
      "metadata": {
        "id": "Nx6mwxVr_cms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_pre_skill_records = skill_df[~skill_df[\"pre_skill\"].isnull()][[\"id\", \"pre_skill\"]].to_dict(orient=\"records\")\n",
        "\n",
        "skill_pre_skill_fins = []\n",
        "\n",
        "for record in skill_pre_skill_records:\n",
        "  if record[\"pre_skill\"] != []:\n",
        "    for pre_skill in record[\"pre_skill\"]:\n",
        "      skill_pre_skill_fin = {}\n",
        "      skill_pre_skill_fin[\"skill_id\"] = record[\"id\"]\n",
        "      skill_pre_skill_fin[\"pre_skill\"] = pre_skill[\"SkillId\"]\n",
        "      skill_pre_skill_fin[\"pre_skill_level\"] = pre_skill[\"SkillLevel\"]\n",
        "      \n",
        "      skill_pre_skill_fins.append(skill_pre_skill_fin)\n",
        "\n",
        "skill_pre_skill_df = pd.DataFrame(skill_pre_skill_fins)\n",
        "\n",
        "skill_pre_skill_df = skill_pre_skill_df.reset_index().rename(columns={\"index\": \"id\"})"
      ],
      "metadata": {
        "id": "Hxhxpf0__lxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intersections = set(skill_pre_skill_df[\"pre_skill\"].astype(int)).intersection(set(skill_complex_final_df[\"id\"].astype(int)))\n",
        "skill_pre_skill_df = skill_pre_skill_df[skill_pre_skill_df[\"pre_skill\"].astype(int).isin(intersections)]\n",
        "\n",
        "intersections = set(skill_pre_skill_df[\"skill_id\"].astype(int)).intersection(set(skill_complex_final_df[\"id\"].astype(int)))\n",
        "skill_pre_skill_final_df = skill_pre_skill_df[skill_pre_skill_df[\"skill_id\"].astype(int).isin(intersections)]"
      ],
      "metadata": {
        "id": "PLt_1qbBPioQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save for database"
      ],
      "metadata": {
        "id": "0H_I5RHv_cmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_pre_skill_final_df.to_csv(f\"{MAIN_PARSED_DIR}/skill_pre_skill_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "pxM_u9xB_cmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skill Required Mount"
      ],
      "metadata": {
        "id": "AzEyN2kg_-I8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for dataframe creation"
      ],
      "metadata": {
        "id": "bvdqMX49ABjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_require_mount_id_records = skill_df[~skill_df[\"require_mount_id\"].isnull()][[\"id\", \"require_mount_id\"]].to_dict(orient=\"records\")\n",
        "\n",
        "skill_require_mount_id_fins = []\n",
        "\n",
        "for record in skill_require_mount_id_records:\n",
        "  if record[\"require_mount_id\"] != []:\n",
        "    for require_mount_id in list(record[\"require_mount_id\"]):\n",
        "      skill_require_mount_id_fin = {}\n",
        "      skill_require_mount_id_fin[\"skill_id\"] = record[\"id\"]\n",
        "      skill_require_mount_id_fin[\"require_mount_id\"] = require_mount_id\n",
        "      \n",
        "      skill_require_mount_id_fins.append(skill_require_mount_id_fin)\n",
        "\n",
        "skill_require_mount_id_df = pd.DataFrame(skill_require_mount_id_fins)\n",
        "\n",
        "skill_require_mount_id_df = skill_require_mount_id_df.reset_index().rename(columns={\"index\": \"id\"})"
      ],
      "metadata": {
        "id": "6Vt-gtILABjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intersections = set(skill_require_mount_id_df[\"skill_id\"].astype(float)).intersection(set(skill_complex_final_df[\"id\"].astype(float)))\n",
        "skill_require_mount_id_final_df = skill_require_mount_id_df[skill_require_mount_id_df[\"skill_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "# intersections = set(skill_require_mount_id_df[\"require_mount_id\"].astype(float)).intersection(set(item_final_df[\"id\"].astype(float)))\n",
        "# skill_require_mount_id_final_df = skill_require_mount_id_df[skill_require_mount_id_df[\"require_mount_id\"].astype(float).isin(intersections)]"
      ],
      "metadata": {
        "id": "t32MPcKlP11d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save for database"
      ],
      "metadata": {
        "id": "tEYasryCABje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_require_mount_id_final_df.to_csv(f\"{MAIN_PARSED_DIR}/skill_require_mount_id_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "1MngNnhNABje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skill Max HP Cost"
      ],
      "metadata": {
        "id": "dVEXyZscAcd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for dataframe creation"
      ],
      "metadata": {
        "id": "xm0gqrdNAftN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_max_hp_cost_records = skill_df[~skill_df[\"max_hp_cost\"].isnull()][[\"id\", \"max_hp_cost\"]].to_dict(orient=\"records\")\n",
        "\n",
        "skill_max_hp_cost_fins = []\n",
        "\n",
        "for record in skill_max_hp_cost_records:\n",
        "  if record[\"max_hp_cost\"] != []:\n",
        "    for max_hp_cost in list(record[\"max_hp_cost\"]):\n",
        "      skill_max_hp_cost_fin = {}\n",
        "      skill_max_hp_cost_fin[\"skill_id\"] = record[\"id\"]\n",
        "      skill_max_hp_cost_fin[\"max_hp_cost\"] = max_hp_cost\n",
        "      \n",
        "      skill_max_hp_cost_fins.append(skill_max_hp_cost_fin)\n",
        "\n",
        "skill_max_hp_cost_df = pd.DataFrame(skill_max_hp_cost_fins)\n",
        "\n",
        "skill_max_hp_cost_df = skill_max_hp_cost_df.reset_index().rename(columns={\"index\": \"id\"})"
      ],
      "metadata": {
        "id": "mIXZeF30AftP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intersections = set(skill_max_hp_cost_df[\"skill_id\"].astype(float)).intersection(set(skill_complex_final_df[\"id\"].astype(float)))\n",
        "skill_max_hp_cost_final_df = skill_max_hp_cost_df[skill_max_hp_cost_df[\"skill_id\"].astype(float).isin(intersections)]"
      ],
      "metadata": {
        "id": "PTVNcGgaQtbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save for database"
      ],
      "metadata": {
        "id": "pOc-dMuwAftR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_max_hp_cost_final_df.to_csv(f\"{MAIN_PARSED_DIR}/skill_max_hp_cost_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "5Cl2QxEpAftS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Skill Zeny Cost"
      ],
      "metadata": {
        "id": "WWKeMOeiAv8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for dataframe creation"
      ],
      "metadata": {
        "id": "fvv4oIKNA5KL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_cost_zeny_records = skill_df[~skill_df[\"cost_zeny\"].isnull()][[\"id\", \"cost_zeny\"]].to_dict(orient=\"records\")\n",
        "\n",
        "skill_cost_zeny_fins = []\n",
        "\n",
        "for record in skill_cost_zeny_records:\n",
        "  if record[\"cost_zeny\"] != []:\n",
        "    for cost_zeny in list(record[\"cost_zeny\"]):\n",
        "      skill_cost_zeny_fin = {}\n",
        "      skill_cost_zeny_fin[\"skill_id\"] = record[\"id\"]\n",
        "      skill_cost_zeny_fin[\"cost_zeny\"] = cost_zeny\n",
        "      \n",
        "      skill_cost_zeny_fins.append(skill_cost_zeny_fin)\n",
        "\n",
        "skill_cost_zeny_df = pd.DataFrame(skill_cost_zeny_fins)\n",
        "\n",
        "skill_cost_zeny_df = skill_cost_zeny_df.reset_index().rename(columns={\"index\": \"id\"})"
      ],
      "metadata": {
        "id": "2FFRyZzGA5KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intersections = set(skill_cost_zeny_df[\"skill_id\"].astype(float)).intersection(set(skill_complex_final_df[\"id\"].astype(float)))\n",
        "skill_zeny_cost_final_df = skill_cost_zeny_df[skill_cost_zeny_df[\"skill_id\"].astype(float).isin(intersections)]"
      ],
      "metadata": {
        "id": "WUZXXtGVQ7m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save for database"
      ],
      "metadata": {
        "id": "hNJSgWfeA5KN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_zeny_cost_final_df.to_csv(f\"{MAIN_PARSED_DIR}/skill_zeny_cost_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "9Y2WIvmEA5KO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SGJJMZfsJU6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Equip Suit"
      ],
      "metadata": {
        "id": "fjKvGJmy6pp6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "Epb7q6ss6sMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "LIMIT = 328932992\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_equip_EquipmentSuit.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for i, text in enumerate(filename.readlines()):\n",
        "    if i == LIMIT:\n",
        "      break\n",
        "    else:\n",
        "      texts.append(text.strip())\n",
        "\n",
        "texts = \" \".join(texts)\n",
        "texts = re.sub(r'\\[([\\w\\\"]+)\\] =', '\\g<1>:', texts)\n",
        "texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\{([\\d\\, ]+)\\}', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "# print(texts)\n",
        "\n",
        "texts = texts.replace(\"{ {\", \"AAAAA\")\n",
        "texts = texts.replace(\"}, }, },\", \"BBBBB\")\n",
        "texts = texts.replace(\"}, }, {\", \"DDDDD\")\n",
        "texts = re.sub(r'\\}, \\}, (\\d)', 'FFFFF \\g<1>', texts)\n",
        "texts = re.sub(r'\\}, \\},$', 'EEEEE', texts)\n",
        "texts = texts.replace(\"}, },\", \"CCCCC\")\n",
        "\n",
        "texts = texts.replace(\"AAAAA\", \"[ {\")\n",
        "texts = texts.replace(\"BBBBB\", \"}, }, ],\")\n",
        "texts = texts.replace(\"CCCCC\", \"}, ],\")\n",
        "texts = texts.replace(\"DDDDD\", \"}, }, {\")\n",
        "texts = texts.replace(\"EEEEE\", \"}, },\")\n",
        "texts = texts.replace(\"FFFFF\", \"}, }, \")\n",
        "\n",
        "texts = \"{\" + texts + \"}\"\n",
        "\n",
        "equipment_suits = literal_eval(texts)    "
      ],
      "metadata": {
        "id": "zAJl96w3KjMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "Qiw-NjUA7YYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equipment_suit_entries = []\n",
        "\n",
        "for id, parsed_dict in equipment_suits.items():\n",
        "  equipment_suit_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"id\": \"ID\",\n",
        "      \"argument_id\": \"argumentID\",\n",
        "      \"argument_order\": \"argumentOrder\",\n",
        "      \"argument_value\": \"argumentValue\",\n",
        "      \"equip_id\": \"equip_id\",\n",
        "      \"name\": \"name\",\n",
        "      \"skill_id\": \"skillId\",\n",
        "      \"suit_id\": \"suitId\",\n",
        "      \"suit_num\": \"suitNum\"\n",
        "  }\n",
        "  equipment_suit_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      equipment_suit_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  equipment_suit_entries.append(equipment_suit_entry)\n",
        "\n",
        "equip_suit_raw_df = pd.DataFrame(equipment_suit_entries)"
      ],
      "metadata": {
        "id": "GvL9ueaYKwmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_raw_df[\"argument_value\"] = equip_suit_raw_df[\"argument_value\"].apply(list)"
      ],
      "metadata": {
        "id": "Mqn6oMfhLvbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Break entries down"
      ],
      "metadata": {
        "id": "bQVSQrUY7YYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_raw_df = equip_suit_raw_df[~equip_suit_raw_df[\"equip_id\"].isnull()]\n",
        "\n",
        "isnull =equip_suit_raw_df[\"argument_value\"].isnull()\n",
        "equip_suit_raw_df.loc[isnull, 'argument_value'] = pd.Series([[None]] * isnull.sum()).values\n",
        "\n",
        "isnull =equip_suit_raw_df[\"argument_order\"].isnull()\n",
        "equip_suit_raw_df.loc[isnull, 'argument_order'] = pd.Series([[None]] * isnull.sum()).values\n",
        "\n",
        "equip_suit_rec_df = equip_suit_raw_df[[\"id\", \"name\", \"skill_id\", \"equip_id\", \"argument_order\", \"argument_value\", \"suit_num\"]]\n",
        "equip_suit_recs = equip_suit_rec_df.to_dict(orient=\"records\")\n",
        "\n",
        "equip_suit_rec_news = []\n",
        "\n",
        "for equip_suit_rec in equip_suit_recs:\n",
        "  for i, equip_id in enumerate(equip_suit_rec[\"equip_id\"]):\n",
        "    new_entry = {}\n",
        "    new_entry[\"id\"] = equip_suit_rec[\"id\"]\n",
        "    new_entry[\"equip_id\"] = equip_id\n",
        "    new_entry[\"argument_value\"] = equip_suit_rec[\"argument_value\"][0]\n",
        "    new_entry[\"argument_order\"] = equip_suit_rec[\"argument_order\"][0]\n",
        "    new_entry[\"name\"] = equip_suit_rec[\"name\"]\n",
        "    new_entry[\"skill_id\"] = equip_suit_rec[\"skill_id\"]\n",
        "    new_entry[\"suit_num\"] = equip_suit_rec[\"suit_num\"]\n",
        "  \n",
        "    equip_suit_rec_news.append(new_entry)\n",
        "\n",
        "equip_suit_df = pd.DataFrame(equip_suit_rec_news)"
      ],
      "metadata": {
        "id": "JK6Ydg6u7YYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data manipulation"
      ],
      "metadata": {
        "id": "gL1fqaL6IJBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_manip_df = equip_suit_df[[\"argument_value\", \"name\", \"skill_id\", \"suit_num\"]].drop_duplicates().sort_values(\"name\")"
      ],
      "metadata": {
        "id": "DlpsyPSo7DHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_manip_df[\"skill_id\"] = equip_suit_manip_df[\"skill_id\"].fillna(\"81010000\")\n",
        "equip_suit_manip_df = equip_suit_manip_df[~equip_suit_manip_df[\"name\"].isnull()]\n",
        "equip_suit_manip_df = equip_suit_manip_df[~equip_suit_manip_df[\"name\"].str.startswith(\"Fashion_ShowEffect\")]"
      ],
      "metadata": {
        "id": "TtJrldCpIOFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_blue_argument_value(x):\n",
        "\n",
        "  try:\n",
        "    match = re.match(\"SuitName(\\w+)\", x[\"name\"])\n",
        "    equipment_suit_code = int(match.group(1))\n",
        "  except:\n",
        "    pass\n",
        "    # match = re.match(\"Fashion_ShowEffect(\\w+)\", x[\"name\"])\n",
        "    # equipment_suit_code = int(match.group(1))\n",
        "  \n",
        "  if 100 < equipment_suit_code and equipment_suit_code < 500:\n",
        "    if int(x[\"skill_id\"]) == 81010000:\n",
        "      return (equipment_suit_code - 99) * 0.005\n",
        "    if int(x[\"skill_id\"]) == 81010001:\n",
        "      return 0.20 + ((equipment_suit_code - 99) * 0.05)\n",
        "    if int(x[\"skill_id\"]) == 81010002:\n",
        "      return (equipment_suit_code - 99) * 0.05\n",
        "  elif equipment_suit_code == 4:\n",
        "    return 0.1\n",
        "  elif equipment_suit_code == 6000:\n",
        "    return 0.25\n",
        "  elif equipment_suit_code == 8114:\n",
        "    return 0.1\n",
        "  elif equipment_suit_code == 1020:\n",
        "    if int(x[\"suit_num\"]) == 3:\n",
        "      return 0.05\n",
        "    elif int(x[\"suit_num\"]) == 6:\n",
        "      return 0.075\n",
        "    elif int(x[\"suit_num\"]) == 8:\n",
        "      return 0.1\n",
        "  elif equipment_suit_code == 2020:\n",
        "    if int(x[\"suit_num\"]) == 3:\n",
        "      return 0.1\n",
        "    elif int(x[\"suit_num\"]) == 6:\n",
        "      return 0.15\n",
        "    elif int(x[\"suit_num\"]) == 8:\n",
        "      return 0.2\n",
        "  elif equipment_suit_code == 2060:\n",
        "    if int(x[\"suit_num\"]) == 3:\n",
        "      return 0.05\n",
        "    elif int(x[\"suit_num\"]) == 6:\n",
        "      return 0.075\n",
        "    elif int(x[\"suit_num\"]) == 8:\n",
        "      return 0.1\n",
        "  elif equipment_suit_code == 2070:\n",
        "    if int(x[\"suit_num\"]) == 3:\n",
        "      return 0.05\n",
        "    elif int(x[\"suit_num\"]) == 6:\n",
        "      return 0.075\n",
        "    elif int(x[\"suit_num\"]) == 8:\n",
        "      return 0.1\n",
        "  elif equipment_suit_code == 3020:\n",
        "    if int(x[\"suit_num\"]) == 3:\n",
        "      return 0.03\n",
        "    elif int(x[\"suit_num\"]) == 6:\n",
        "      return 0.04\n",
        "    elif int(x[\"suit_num\"]) == 8:\n",
        "      return 0.05\n",
        "  elif equipment_suit_code == 4020:\n",
        "    if int(x[\"suit_num\"]) == 3:\n",
        "      return 0.1\n",
        "    elif int(x[\"suit_num\"]) == 6:\n",
        "      return 0.15\n",
        "    elif int(x[\"suit_num\"]) == 8:\n",
        "      return 0.2\n",
        "  elif equipment_suit_code == 5020:\n",
        "    if int(x[\"suit_num\"]) == 3:\n",
        "      return 0.03\n",
        "    elif int(x[\"suit_num\"]) == 6:\n",
        "      return 0.04\n",
        "    elif int(x[\"suit_num\"]) == 8:\n",
        "      return 0.05\n",
        "\n",
        "  return np.nan "
      ],
      "metadata": {
        "id": "p8X6gNFBJGnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_manip_df[\"suit_num\"] = equip_suit_manip_df[\"suit_num\"].fillna(3)\n",
        "\n",
        "equip_suit_manip_df[\"init_argument_value\"] = equip_suit_manip_df.apply(get_blue_argument_value, axis=1)\n",
        "equip_suit_manip_df[\"argument_order\"] = 1\n",
        "equip_suit_manip_df = equip_suit_manip_df[~equip_suit_manip_df[\"init_argument_value\"].isnull()]"
      ],
      "metadata": {
        "id": "nunxkBlIKVVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manipulate `SuitName101`"
      ],
      "metadata": {
        "id": "lhceUZP2Kd-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_manip_copy_df = equip_suit_manip_df.query(\"name == 'SuitName102'\")\n",
        "equip_suit_manip_copy_df[\"name\"] = 'SuitName101'\n",
        "\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 3, \"init_argument_value\"] = 0.005\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 6, \"init_argument_value\"] = 0.25\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 8, \"init_argument_value\"] = 0.05\n",
        "\n",
        "equip_suit_manip_df = equip_suit_manip_df.append(equip_suit_manip_copy_df, ignore_index=True)"
      ],
      "metadata": {
        "id": "XW9Iiz3MKd-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manipulate `SuitName2020`"
      ],
      "metadata": {
        "id": "zuLVa8tXYVFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_manip_df.loc[equip_suit_manip_df[\"name\"] == \"SuitName2020\", \"argument_order\"] = 2\n",
        "\n",
        "equip_suit_manip_copy_df = equip_suit_manip_df.query(\"name == 'SuitName2020'\")\n",
        "\n",
        "equip_suit_manip_copy_df[\"argument_order\"] = 1\n",
        "\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 3, \"init_argument_value\"] = 0.3\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 3, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 6, \"init_argument_value\"] = 0.4\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 6, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 8, \"init_argument_value\"] = 0.5\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 8, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_df = equip_suit_manip_df.append(equip_suit_manip_copy_df, ignore_index=True)"
      ],
      "metadata": {
        "id": "o2R0aPZPXre3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manipulate `SuitName2060`"
      ],
      "metadata": {
        "id": "qu7T4XziYZRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_manip_df.loc[equip_suit_manip_df[\"name\"] == \"SuitName2060\", \"argument_order\"] = 3\n",
        "\n",
        "equip_suit_manip_copy_df = equip_suit_manip_df.query(\"name == 'SuitName2060'\")\n",
        "\n",
        "equip_suit_manip_copy_df[\"argument_order\"] = 1\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 3, \"init_argument_value\"] = 2\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 3, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 6, \"init_argument_value\"] = 3\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 6, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 8, \"init_argument_value\"] = 4\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 8, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_df = equip_suit_manip_df.append(equip_suit_manip_copy_df.copy(), ignore_index=True)\n",
        "\n",
        "equip_suit_manip_copy_df[\"argument_order\"] = 2\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 3, \"init_argument_value\"] = 0.3\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 3, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 6, \"init_argument_value\"] = 0.4\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 6, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 8, \"init_argument_value\"] = 0.5\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 8, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_df = equip_suit_manip_df.append(equip_suit_manip_copy_df.copy(), ignore_index=True)"
      ],
      "metadata": {
        "id": "CxeKCV1oYZRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manipulate `SuitName2070`"
      ],
      "metadata": {
        "id": "sEtjerCDZgIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_manip_df.loc[equip_suit_manip_df[\"name\"] == \"SuitName2070\", \"argument_order\"] = 2\n",
        "\n",
        "equip_suit_manip_copy_df = equip_suit_manip_df.query(\"name == 'SuitName2070'\")\n",
        "\n",
        "equip_suit_manip_copy_df[\"argument_order\"] = 1\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 3, \"init_argument_value\"] = 0.2\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 3, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 6, \"init_argument_value\"] = 0.15\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 6, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 8, \"init_argument_value\"] = 0.1\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 8, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_df = equip_suit_manip_df.append(equip_suit_manip_copy_df.copy(), ignore_index=True)\n",
        "\n",
        "equip_suit_manip_copy_df[\"argument_order\"] = 3\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 3, \"init_argument_value\"] = 3\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 3, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 6, \"init_argument_value\"] = 4\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 6, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 8, \"init_argument_value\"] = 5\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 8, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_df = equip_suit_manip_df.append(equip_suit_manip_copy_df.copy(), ignore_index=True)"
      ],
      "metadata": {
        "id": "FM1BGYM2ZgIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manipulate `SuitName4020`"
      ],
      "metadata": {
        "id": "aHkJy5BWaNa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_manip_copy_df = equip_suit_manip_df.query(\"name == 'SuitName4020'\")\n",
        "\n",
        "equip_suit_manip_copy_df[\"argument_order\"] = 2\n",
        "equip_suit_manip_copy_df[\"init_argument_value\"] = 1\n",
        "equip_suit_manip_copy_df[\"argument_value\"] = 0.5\n",
        "\n",
        "equip_suit_manip_df = equip_suit_manip_df.append(equip_suit_manip_copy_df.copy(), ignore_index=True)"
      ],
      "metadata": {
        "id": "RvlV2qA6aNbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Manipulate `SuitName5020`"
      ],
      "metadata": {
        "id": "mlB_gx9wa350"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_manip_df.loc[equip_suit_manip_df[\"name\"] == \"SuitName5020\", \"argument_order\"] = 2\n",
        "equip_suit_manip_copy_df = equip_suit_manip_df.query(\"name == 'SuitName5020'\")\n",
        "\n",
        "equip_suit_manip_copy_df[\"argument_order\"] = 1\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 3, \"init_argument_value\"] = 3\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 3, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 6, \"init_argument_value\"] = 4\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 6, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 8, \"init_argument_value\"] = 5\n",
        "equip_suit_manip_copy_df.loc[equip_suit_manip_df[\"suit_num\"] == 8, \"argument_value\"] = np.nan\n",
        "\n",
        "equip_suit_manip_df = equip_suit_manip_df.append(equip_suit_manip_copy_df.copy(), ignore_index=True)"
      ],
      "metadata": {
        "id": "st86vdo6a351"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge with information from `en_langs`"
      ],
      "metadata": {
        "id": "thf8efD9e1wu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Suit name"
      ],
      "metadata": {
        "id": "kCnQc6BpNNjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_manip_df[\"name\"] = equip_suit_manip_df[\"name\"].apply(lambda x: int(x.replace(\"SuitName\", \"\")))\n",
        "equip_suit_manip_df = equip_suit_manip_df.rename(columns={\"name\": \"suit_id\"})\n",
        "\n",
        "equip_suit_fin_df = equip_suit_manip_df\n",
        "equip_suit_fin_df = equip_suit_fin_df.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "suit_name_df = pd.DataFrame(parsed_data[\"suit_name\"])\n",
        "suit_name_df = suit_name_df.rename(columns={\"id\": \"suit_id\", \"value\": \"name\"})\n",
        "suit_name_df[\"suit_id\"] = suit_name_df[\"suit_id\"].apply(int)\n",
        "\n",
        "equip_suit_fin_df = pd.merge(equip_suit_fin_df, suit_name_df, how=\"left\", left_on=\"suit_id\", right_on=\"suit_id\")"
      ],
      "metadata": {
        "id": "zabv1KDaMsu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "WMA_VrOpPlST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Equipment suit"
      ],
      "metadata": {
        "id": "MsexGBUHQJPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_df = equip_suit_fin_df[[\"suit_id\", \"name\"]].drop_duplicates().reset_index(drop=True).rename(columns={\"suit_id\": \"id\"})"
      ],
      "metadata": {
        "id": "NxvJ1PDdMmFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_final_df = equip_suit_df.copy()"
      ],
      "metadata": {
        "id": "1LmKrB8_RerL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_final_df.to_csv(f\"{MAIN_PARSED_DIR}/equip_suit_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "P2ZaWPR7QLCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Equipment Suit Skill"
      ],
      "metadata": {
        "id": "6465mT-kV-hL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " equip_suit_skill_df = equip_suit_fin_df[[\"suit_id\", \"skill_id\", \"suit_num\"]].drop_duplicates([\"suit_id\", \"skill_id\", \"suit_num\"]).reset_index().rename(columns={\"index\": \"id\"})"
      ],
      "metadata": {
        "id": "w9frpKBvQrU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intersections = set(equip_suit_skill_df[\"skill_id\"].astype(float)).intersection(set(skill_complex_final_df[\"id\"].astype(float)))\n",
        "equip_suit_skill_final_df = equip_suit_skill_df[equip_suit_skill_df[\"skill_id\"].astype(float).isin(intersections)]"
      ],
      "metadata": {
        "id": "M8XSfR0XRoBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_skill_final_df.to_csv(f\"{MAIN_PARSED_DIR}/equip_suit_skill_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "1Kxrk3lHcwu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Equipment Suit Skill Argument"
      ],
      "metadata": {
        "id": "pBfQpcCZhzwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_skill_arg_df = pd.merge(equip_suit_fin_df, equip_suit_skill_final_df, how=\"left\", left_on=[\"suit_id\", \"skill_id\", \"suit_num\"], right_on=[\"suit_id\", \"skill_id\", \"suit_num\"]).rename(columns={\"id\": \"suit_skill_id\"})"
      ],
      "metadata": {
        "id": "arpo5ksadQAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_skill_arg_df = equip_suit_skill_arg_df[[\"suit_skill_id\", \"argument_order\", \"init_argument_value\", \"argument_value\"]].reset_index().rename(columns={\"index\": \"id\"})"
      ],
      "metadata": {
        "id": "Z39Pyw-JmiWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_skill_arg_final_df = equip_suit_skill_arg_df.drop_duplicates([\"suit_skill_id\",\t\"argument_order\"], keep=\"first\")"
      ],
      "metadata": {
        "id": "SoSufCON10YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equip_suit_skill_arg_final_df.to_csv(f\"{MAIN_PARSED_DIR}/equip_suit_skill_arg_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "kzn-0Bp2t4Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Equip"
      ],
      "metadata": {
        "id": "Q8Sdkq0Iqeg6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "jSHodfEBq0Qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_equip_Equip.bytes\", \"r\", encoding=\"utf-8\") as filename:\n",
        "\n",
        "  for text in filename.readlines():\n",
        "    texts.append(text.strip())\n",
        "    \n",
        "texts = \" \".join(texts)\n",
        "texts = re.sub(r'\\[([\\w\\\"]+)\\] =', '\\g<1>:', texts)\n",
        "texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\{([\\d\\, ]+)\\}', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "# print(texts)\n",
        "\n",
        "texts = texts.replace(\"{ {\", \"AAAAA\")\n",
        "texts = texts.replace(\"}, }, },\", \"BBBBB\")\n",
        "texts = texts.replace(\"}, }, {\", \"DDDDD\")\n",
        "texts = re.sub(r'\\}, \\}, (\\d)', 'FFFFF \\g<1>', texts)\n",
        "texts = re.sub(r'\\}, \\},$', 'EEEEE', texts)\n",
        "texts = texts.replace(\"}, },\", \"CCCCC\")\n",
        "\n",
        "texts = texts.replace(\"AAAAA\", \"[ {\")\n",
        "texts = texts.replace(\"BBBBB\", \"}, }, ],\")\n",
        "texts = texts.replace(\"CCCCC\", \"}, ],\")\n",
        "texts = texts.replace(\"DDDDD\", \"}, }, {\")\n",
        "texts = texts.replace(\"EEEEE\", \"}, },\")\n",
        "texts = texts.replace(\"FFFFF\", \"}, }, \")\n",
        "\n",
        "texts = \"{\" + texts + \"}\"\n",
        "\n",
        "\n",
        "equips = literal_eval(texts)"
      ],
      "metadata": {
        "id": "RshSF_82NymG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "R328g6FXq6pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_entries = []\n",
        "\n",
        "for id, parsed_dict in equips.items():\n",
        "  equip_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"sell_price\": 'SellPrice',\n",
        "      \"base_prop\": 'baseProperty',\n",
        "      \"name\": \"name\",\n",
        "      \"desc\": 'desc',\n",
        "      \"type\": 'equipmentType',\n",
        "      \"improved_level\": 'improvedLevel',\n",
        "      \"init_holes\": 'initHoles',\n",
        "      \"is_all_job\": 'isAllJob',\n",
        "      \"is_bind\": 'isBind',\n",
        "      \"is_fashion\": 'isFashion',\n",
        "      \"job_limit\": 'jobLimit',\n",
        "      \"max_holes\": 'maxHoles',\n",
        "      \"min_level_limit\" : 'minLvLimit',\n",
        "      \"prop_level\": 'propLevel',\n",
        "      \"quality\": 'quality',\n",
        "      \"res_id\": 'resId',\n",
        "      \"trade\": 'trade',\n",
        "      \"refine_id\": \"RefineID\",\n",
        "      \"static_id\": 'staticId',\n",
        "      \"wardrobe_value\":'wardrobeValue',\n",
        "      \"decomposition_output_id\": \"DecompositionOutputId\"\n",
        "  }\n",
        "\n",
        "  equip_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      equip_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  equip_entries.append(equip_entry)\n",
        "\n",
        "equip_df = pd.DataFrame(equip_entries)"
      ],
      "metadata": {
        "id": "bwZKhjpyOAWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get equipment information from `en_langs`"
      ],
      "metadata": {
        "id": "6GsCyYlCrFNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_name_df = pd.DataFrame(parsed_data[\"equip_name\"])\n",
        "equip_desc_df = pd.DataFrame(parsed_data[\"equip_desc\"])\n",
        "equip_type_df = pd.DataFrame(parsed_data[\"equip_type\"])\n",
        "equipment_attr_desc_df = pd.DataFrame(parsed_data[\"property\"])"
      ],
      "metadata": {
        "id": "KnV0p0ZSrAFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select columns for database"
      ],
      "metadata": {
        "id": "gyYWuKXqsoR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_all_df = equip_df[[\"id\", \"name\", \"desc\", \"type\", \"init_holes\", \"is_bind\", \"max_holes\", \"res_id\", \"static_id\", \"improved_level\", \"min_level_limit\", \"prop_level\", \"quality\", \"refine_id\", \"sell_price\", \"is_all_job\", \"is_fashion\", \"wardrobe_value\", \"decomposition_output_id\"]]"
      ],
      "metadata": {
        "id": "FdRaAKJhskA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge with information from `en_langs`"
      ],
      "metadata": {
        "id": "rXhJOgSTsyaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Equip name"
      ],
      "metadata": {
        "id": "6FwiilDps6-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_name_df[\"id\"] = equip_name_df[\"id\"].apply(lambda x: f\"EquipName_{x}\")\n",
        "equip_name_df = equip_name_df.rename(columns={\"id\": \"name\", \"value\":\"equipment_name\"})\n",
        "equip_all_df = pd.merge(equip_all_df, equip_name_df, how=\"left\", left_on=[\"name\"], right_on=[\"name\"])"
      ],
      "metadata": {
        "id": "XTa6WYv_ssU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Equip description"
      ],
      "metadata": {
        "id": "gKj3fTGftCDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_desc_df[\"id\"] = equip_desc_df[\"id\"].apply(lambda x: f\"EquipDesc_{x}\")\n",
        "equip_desc_df = equip_desc_df.rename(columns={\"id\": \"desc\", \"value\":\"equipment_desc\"})\n",
        "equip_all_df = pd.merge(equip_all_df, equip_desc_df, how=\"left\", left_on=[\"desc\"], right_on=[\"desc\"])"
      ],
      "metadata": {
        "id": "XhDs8dAms6UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Equip type"
      ],
      "metadata": {
        "id": "9eW-CnOKtQ_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_all_df[\"type\"] = equip_all_df[\"type\"].astype(float)\n",
        "equip_type_df = equip_type_df.rename(columns={\"id\": \"type\", \"value\":\"equipment_type\"})\n",
        "equip_type_df[\"type\"] = equip_type_df[\"type\"].astype(float)\n",
        "equip_all_df = pd.merge(equip_all_df, equip_type_df, how=\"left\", left_on=[\"type\"], right_on=[\"type\"])"
      ],
      "metadata": {
        "id": "mP9_j-2ntNlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter column for database"
      ],
      "metadata": {
        "id": "bAKCD7dZtapD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_final_df = equip_all_df[[\"id\", \"equipment_name\", \"equipment_desc\", \"equipment_type\", \"static_id\", \"res_id\", \"init_holes\", \"max_holes\", \"min_level_limit\", \"prop_level\", \"quality\", \"refine_id\", \"sell_price\", \"is_all_job\", \"wardrobe_value\", \"improved_level\", \"decomposition_output_id\"]]"
      ],
      "metadata": {
        "id": "eEvigAGwtUlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data correction"
      ],
      "metadata": {
        "id": "kFMTgE-utdzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_final_df[\"equipment_type\"] = equip_final_df[\"equipment_type\"].fillna(\"Accessory - Decoration\")\n",
        "equip_final_df = equip_final_df[~equip_final_df[\"equipment_name\"].isnull()]\n",
        "equip_final_df[\"equipment_name\"] = equip_final_df[\"equipment_name\"].str.replace(\"I\", \"I\")\n",
        "equip_final_df[\"equipment_group\"] = equip_final_df[\"equipment_name\"].str.replace(\" III\", \"\").str.replace(\" II\", \"\").str.replace(\" IV\", \"\").str.replace(\" VI\", \"\").str.replace(\" V\", \"\").str.replace(\" I\", \"\")\n",
        "equip_final_df[\"quality\"] = equip_final_df[\"quality\"].fillna(1)\n",
        "equip_final_df[\"improved_level\"] = equip_final_df[\"improved_level\"].fillna(0)\n",
        "equipment_group_df = equip_final_df.query(\"improved_level == 0\")[[\"equipment_group\", \"static_id\"]].rename(columns={\"static_id\":\"correct_static_id\"})\n",
        "equip_final_df = pd.merge(equip_final_df, equipment_group_df, how=\"left\", left_on=[\"equipment_group\"], right_on=[\"equipment_group\"])\n",
        "equip_final_df[\"static_id\"] = equip_final_df[\"correct_static_id\"]\n",
        "equip_final_df = equip_final_df.drop_duplicates(\"id\", keep=\"first\")"
      ],
      "metadata": {
        "id": "VogbTwcitdCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add equipment suit info"
      ],
      "metadata": {
        "id": "Fsa4bdqXwGRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_final_level(x):\n",
        "  return (x[\"prop_level\"] - (x[\"improved_level\"]*10))\n",
        "\n",
        "equip_final_df[\"final_level\"] = equip_final_df.apply(get_final_level, axis=1)\n",
        "\n",
        "def assign_equipment_suit(x):\n",
        "  final_level = x[\"final_level\"]\n",
        "  quality = x[\"quality\"]\n",
        "\n",
        "  if quality == 1:\n",
        "    if final_level == 30: \n",
        "      return 1020\n",
        "    elif final_level == 40:\n",
        "      return 2020\n",
        "    elif final_level == 50:\n",
        "      return 3020\n",
        "    elif final_level == 60:\n",
        "      return 4020\n",
        "    elif final_level == 70:\n",
        "      return 5020\n",
        "    elif final_level == 80:\n",
        "      return 2060\n",
        "    elif final_level == 90:\n",
        "      return 2070\n",
        "    elif final_level == 100:\n",
        "      return 2080\n",
        "    elif final_level == 110:\n",
        "      return 2090\n",
        "    elif final_level == 120:\n",
        "      return 2100\n",
        "  elif quality == 2:\n",
        "    return 100 + (final_level - 20) / 10\n",
        "  else:\n",
        "    return np.nan\n",
        "\n",
        "equip_final_df[\"suit_id\"] = equip_final_df.apply(assign_equipment_suit, axis=1)"
      ],
      "metadata": {
        "id": "V4OD8-XSuJDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equip_final_df.loc[equip_final_df[\"suit_id\"] == 2080, \"suit_id\"] = np.nan"
      ],
      "metadata": {
        "id": "bLkK23J0WjcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equip_final_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbWPBDVuS-dq",
        "outputId": "b2ff9c34-2329-4a1a-9e61-3fded89cea1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3934, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "equip_final_temp_df = equip_final_df[equip_final_df[\"suit_id\"].isnull()]"
      ],
      "metadata": {
        "id": "i0OUz9T1Ticp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intersections = set(equip_final_df[\"suit_id\"].astype(float)).intersection(set(equip_suit_final_df[\"id\"].astype(float)))\n",
        "equip_final_df = equip_final_df[equip_final_df[\"suit_id\"].astype(float).isin(intersections)]"
      ],
      "metadata": {
        "id": "bEfHpnT0SgpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equip_final_df = equip_final_df.append(equip_final_temp_df, ignore_index=True)"
      ],
      "metadata": {
        "id": "mOZpwnimTSVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "klXtR1T2tzkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_final_df = equip_final_df.rename(columns={\n",
        "    \"equipment_name\": \"name\",\n",
        "    \"equipment_desc\": \"description\",\n",
        "    \"equipment_type\": \"type\",\n",
        "    \"decomposition_output_id\": \"decomposition_id\"\n",
        "}).drop([\"equipment_group\", \"correct_static_id\", \"final_level\"], axis=1)\n",
        "\n",
        "equip_final_df[\"name\"] = equip_final_df[\"name\"].str.lower()\n",
        "equip_final_df.to_csv(f\"{MAIN_PARSED_DIR}/equip_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "Xp8Cn3bMtmaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Equip Attributes"
      ],
      "metadata": {
        "id": "Va8VZOlSs0KH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data from Equip"
      ],
      "metadata": {
        "id": "a4iR1bx2s2Lx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_records = []\n",
        "\n",
        "records = equip_df[[\"id\", \"base_prop\"]].to_dict(orient=\"records\")\n",
        "\n",
        "for record in records:\n",
        "  \n",
        "  if type(record[\"base_prop\"]) == dict:\n",
        "    for attr, value in record[\"base_prop\"].items():\n",
        "      new_record = {}\n",
        "\n",
        "      new_record[\"id\"] = record[\"id\"]\n",
        "      new_record[\"attr\"] = attr\n",
        "      new_record[\"value\"] = value\n",
        "\n",
        "      new_records.append(new_record)\n",
        "  else:\n",
        "    new_record = {}\n",
        "\n",
        "    new_record[\"id\"] = record[\"id\"]\n",
        "    new_record[\"attr\"] = np.nan\n",
        "    new_record[\"value\"] = np.nan\n",
        "\n",
        "    new_records.append(new_record)\n",
        "\n",
        "equipment_attributes_df = pd.DataFrame(new_records)"
      ],
      "metadata": {
        "id": "dU0A2-Hms9YK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge with information from `en_langs`"
      ],
      "metadata": {
        "id": "7T0E7IzWtK_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Attribute Description"
      ],
      "metadata": {
        "id": "CaJiovidtjvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equipment_attr_desc_df = equipment_attr_desc_df.rename(columns={\"id\": \"attr\", \"value\": \"attributes\"})\n",
        "\n",
        "equipment_attr_desc_df[\"attr\"] = equipment_attr_desc_df[\"attr\"].astype(float)\n",
        "equipment_attributes_df[\"attr\"] = equipment_attributes_df[\"attr\"].astype(float)\n",
        "\n",
        "equipment_attr_fin_df = pd.merge(equipment_attributes_df, equipment_attr_desc_df, how=\"left\", left_on=[\"attr\"], right_on=[\"attr\"])\n",
        "equipment_attr_fin_df = equipment_attr_fin_df[[\"id\", \"attributes\", \"value\"]]"
      ],
      "metadata": {
        "id": "VJqqVtNts9fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sava data for database"
      ],
      "metadata": {
        "id": "O5uNO_SStrwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equipment_attr_fin_df = equipment_attr_fin_df.rename(columns={\n",
        "    \"id\": \"equip_id\",\n",
        "    \"attributes\": \"attribute\",\n",
        "    \"value\": \"attribute_value\"\n",
        "})\n",
        "\n",
        "equipment_attr_fin_df = equipment_attr_fin_df.reset_index(drop=True)\n",
        "equipment_attr_fin_df[\"id\"] = pd.Series(range(0, equipment_attr_fin_df.shape[0]))\n",
        "\n",
        "intersections = set(equipment_attr_fin_df[\"equip_id\"].astype(int)).intersection(set(equip_final_df[\"id\"].astype(int)))\n",
        "equipment_attributes_final_df = equipment_attr_fin_df[equipment_attr_fin_df[\"equip_id\"].astype(int).isin(intersections)]"
      ],
      "metadata": {
        "id": "KiLW7LFYdF_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equipment_attributes_final_df.to_csv(f\"{MAIN_PARSED_DIR}/equip_attributes_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "Y19WG3YMUCFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Material"
      ],
      "metadata": {
        "id": "aKRc6t9mt4SV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get equip and item data"
      ],
      "metadata": {
        "id": "domuVpa8uCc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "material_one_df = item_final_df[[\"id\", \"name\", \"description\", \"res_id\"]]\n",
        "material_one_df[\"is_item\"] = 1\n",
        "material_two_df = equip_final_df[[\"id\", \"name\", \"description\", \"res_id\"]]\n",
        "material_two_df[\"is_item\"] = 0"
      ],
      "metadata": {
        "id": "x59bz4wkt-zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data correction"
      ],
      "metadata": {
        "id": "fu_X2CwVuFHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "material_final_df = material_one_df.append(material_two_df, ignore_index=True)\n",
        "material_final_df[\"name\"] = material_final_df[\"name\"].str.lower()\n",
        "\n",
        "material_final_df.loc[material_final_df[\"name\"].str.contains(\"card\"), 'res_id'] = 99999"
      ],
      "metadata": {
        "id": "kuvjpJzNuLn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "g-Q5dzcwuYHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "material_final_df.to_csv(f\"{MAIN_PARSED_DIR}/material_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "Eq1rnOeEuL-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "material_df = material_final_df.copy()"
      ],
      "metadata": {
        "id": "cvnBwbZhiEPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Job"
      ],
      "metadata": {
        "id": "eIXdTcJfoy2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data from `en_langs`"
      ],
      "metadata": {
        "id": "FYG-ZBINo0na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_df = pd.DataFrame(parsed_data[\"job_name\"]).rename(columns={\"value\": \"name\"})\n",
        "job_df[\"name\"] = job_df[\"name\"].str.lower()"
      ],
      "metadata": {
        "id": "VCVZj9Iso2DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_final_df = job_df.copy()"
      ],
      "metadata": {
        "id": "rmV1JLyvUSOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "Oyqc2ndNviAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_final_df.to_csv(f\"{MAIN_PARSED_DIR}/job_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "HWcneDZSqr1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Equip Job"
      ],
      "metadata": {
        "id": "fvR0QMWXwkJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data from Equip"
      ],
      "metadata": {
        "id": "iFi80ckvwl9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_job_raw_df = equip_df[[\"id\", \"job_limit\"]][~equip_df[\"job_limit\"].isnull()]\n",
        "equip_job_raw_df[\"job_limit\"] = equip_job_raw_df[\"job_limit\"].apply(list)"
      ],
      "metadata": {
        "id": "6fI5eI5swoox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create records"
      ],
      "metadata": {
        "id": "ugJvdQ2CxLzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_records = []\n",
        "\n",
        "records = equip_job_raw_df[[\"id\", \"job_limit\"]].to_dict(orient=\"records\")\n",
        "\n",
        "for record in records:\n",
        "  for job in record[\"job_limit\"]:\n",
        "    new_record = {}\n",
        "\n",
        "    new_record[\"id\"] = record[\"id\"]\n",
        "    new_record[\"job\"] = job\n",
        "\n",
        "    new_records.append(new_record)\n",
        "\n",
        "equip_job_df = pd.DataFrame(new_records)"
      ],
      "metadata": {
        "id": "li2IYBUhw9wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "P1eDY6O0y7Wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_job_df = equip_job_df.reset_index().rename(columns={\"id\" : \"equip_id\", \"job\": \"job_id\"}).rename(columns={\"index\": \"id\"})\n",
        "\n",
        "intersections = set(equip_job_df[\"job_id\"].astype(float)).intersection(set(job_final_df[\"id\"].astype(float)))\n",
        "equip_job_df = equip_job_df[equip_job_df[\"job_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "intersections = set(equip_job_df[\"equip_id\"].astype(float)).intersection(set(equip_final_df[\"id\"].astype(float)))\n",
        "equip_job_final_df = equip_job_df[equip_job_df[\"equip_id\"].astype(float).isin(intersections)]"
      ],
      "metadata": {
        "id": "bQFVk2E6yn7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equip_job_final_df.to_csv(f\"{MAIN_PARSED_DIR}/equip_job_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "--LWYtNz3BHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop"
      ],
      "metadata": {
        "id": "8L6vIHYYQrgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop V2"
      ],
      "metadata": {
        "id": "Iztnkw-2Spcv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "9CSHt1n1QtvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_dropV2_DropV2.bytes\", \"r\", encoding=\"utf-8\") as filename:\n",
        "\n",
        "  for text in filename.readlines():\n",
        "    texts.append(text.strip())\n",
        "    \n",
        "texts = \" \".join(texts)\n",
        "\n",
        "texts = re.sub(r'\\[([\\w\\\"]+)\\]=', '\\g<1>:', texts)\n",
        "texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "texts = texts.replace(\"{}\", \"[]\")\n",
        "texts = texts.replace(\"{ {\", \"[ {\")\n",
        "texts = texts.replace(\"} } }, {\", \"AAAAA\")\n",
        "texts = texts.replace(\"} } } }\", \"BBBBB\")\n",
        "texts = texts.replace(\"} } }\", \"XXXXX\")\n",
        "texts = texts.replace(\"} }, {\", \"ZZZZZ\")\n",
        "texts = texts.replace(\"} }\", \"YYYYY\")\n",
        "texts = texts.replace(\"XXXXX\", \"} } ]\")\n",
        "texts = texts.replace(\"ZZZZZ\", \"} }, {\")\n",
        "texts = texts.replace(\"YYYYY\", \"} ]\")\n",
        "texts = texts.replace(\"AAAAA\", \"} ] }, {\")\n",
        "texts = texts.replace(\"BBBBB\", \"} ] } ]\")\n",
        "\n",
        "texts = \"{\" + texts + \"}\"\n",
        "\n",
        "drops = literal_eval(texts)"
      ],
      "metadata": {
        "id": "lOlOng5hQzK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "yepBvVQfwk-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_entries = []\n",
        "\n",
        "for id, parsed_dict in drops.items():\n",
        "  drop_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"id\": \"id\",\n",
        "      \"is_card_drop\": \"IsCardDrop\",\n",
        "      \"fixed_drop_amount\": 'fixedDropAmount',\n",
        "      \"fixed_drop_static_id\": \"fixedDropStaticId\",\n",
        "      \"fixed_drop_type\": \"fixedDropType\",\n",
        "      \"random_drop_collections_id\": \"randomDropCollectionsId\",\n",
        "      \"random_drop_collections_sp_plus\": \"randomDropCollectionsSpPlus\",\n",
        "      \"random_drop_collections_sp_reduce\": \"randomDropCollectionsSpReduce\",\n",
        "      \"random_drop_collections_weight\": \"randomDropCollectionsWeight\",\n",
        "      \"random_drop_probability\": \"randomDropProbability\",\n",
        "      \"random_drop_probability_denominator\": \"randomDropProbabilityDenominator\",\n",
        "      \"random_times\": \"randomTimes\"\n",
        "  }\n",
        "\n",
        "  drop_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      drop_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  drop_entries.append(drop_entry)\n",
        "\n",
        "drop_info_df = pd.DataFrame(drop_entries)"
      ],
      "metadata": {
        "id": "dIq6StX7SYrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse Fixed Drop"
      ],
      "metadata": {
        "id": "yn1ndjIAVcY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_drop_info_df = drop_info_df[drop_info_df[\"fixed_drop_amount\"].apply(len) > 0]"
      ],
      "metadata": {
        "id": "ivgxiEH5Vahs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_drop_info_fins = []\n",
        "for record in fixed_drop_info_df.to_dict(orient=\"records\"):\n",
        "  for i in range(len(record[\"fixed_drop_amount\"])):\n",
        "    fixed_drop_info_fin = {}\n",
        "    fixed_drop_info_fin[\"drop_id\"] = record[\"id\"]\n",
        "    fixed_drop_info_fin[\"item_id\"] = record[\"fixed_drop_type\"][i]\n",
        "    fixed_drop_info_fin[\"item_num\"] = record[\"fixed_drop_amount\"][i]\n",
        "\n",
        "    fixed_drop_info_fins.append(fixed_drop_info_fin)\n",
        "\n",
        "fixed_drop_info_fin_df = pd.DataFrame(fixed_drop_info_fins)"
      ],
      "metadata": {
        "id": "ulzVWcXLW-ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Fixed Drop data"
      ],
      "metadata": {
        "id": "iT3EjMGBw4QV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_drop_info_fin_df.to_csv(f\"{MAIN_PARSED_DIR}/fixed_drop_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "i4NC51Mjw2Z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_drop_info_fin_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "JKAVYvE_Wq-V",
        "outputId": "958e0c98-e777-4059-a785-8b76bdbf28dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         drop_id  item_id  item_num\n",
              "0         100001        5         1\n",
              "1         100001        5        10\n",
              "2     1000011011        6      5000\n",
              "3     1000011011        7      5000\n",
              "4     1000011011        1       200\n",
              "...          ...      ...       ...\n",
              "8395       99999        4         1\n",
              "8396       99999        4         1\n",
              "8397       99999        4         1\n",
              "8398       99999        4         1\n",
              "8399       99999        4         1\n",
              "\n",
              "[8400 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-adf74429-9223-4980-8c3b-b9b4f3953b85\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>drop_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>item_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100001</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100001</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000011011</td>\n",
              "      <td>6</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000011011</td>\n",
              "      <td>7</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000011011</td>\n",
              "      <td>1</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8395</th>\n",
              "      <td>99999</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8396</th>\n",
              "      <td>99999</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8397</th>\n",
              "      <td>99999</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8398</th>\n",
              "      <td>99999</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8399</th>\n",
              "      <td>99999</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8400 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-adf74429-9223-4980-8c3b-b9b4f3953b85')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-adf74429-9223-4980-8c3b-b9b4f3953b85 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-adf74429-9223-4980-8c3b-b9b4f3953b85');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse Random Drop"
      ],
      "metadata": {
        "id": "hNbI7_evYia4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_drop_info_df = drop_info_df[drop_info_df[\"random_drop_collections_id\"].apply(len) > 0]"
      ],
      "metadata": {
        "id": "WlfxZK8aWnYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_drop_info_fins = []\n",
        "for record in random_drop_info_df.to_dict(orient=\"records\"):\n",
        "  for i in range(len(record[\"random_drop_collections_id\"])):\n",
        "    random_drop_info_fin = {}\n",
        "    random_drop_info_fin[\"drop_id\"] = record[\"id\"]\n",
        "    random_drop_info_fin[\"drop_collections_id\"] = record[\"random_drop_collections_id\"][i]\n",
        "    random_drop_info_fin[\"drop_collections_weight\"] = record[\"random_drop_collections_weight\"][i]\n",
        "    random_drop_info_fin[\"probability\"] = record[\"random_drop_probability\"]\n",
        "    random_drop_info_fin[\"probability_denominator\"] = record[\"random_drop_probability_denominator\"]\n",
        "    random_drop_info_fin[\"times\"] = record[\"random_times\"]\n",
        "\n",
        "    random_drop_info_fins.append(random_drop_info_fin)\n",
        "\n",
        "random_drop_info_fin_df = pd.DataFrame(random_drop_info_fins)"
      ],
      "metadata": {
        "id": "aGq1BLofZjPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Complex Random Drop Main for database"
      ],
      "metadata": {
        "id": "IDnYziGj4jWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random_drop_info_main_fin_df = random_drop_info_fin_df[[\"drop_id\", \"probability\", \"probability_denominator\", \"times\"]].drop_duplicates(\"drop_id\")"
      ],
      "metadata": {
        "id": "gWULykXWNcXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_drop_main_df = random_drop_info_fin_df[[\"drop_id\", \"probability\", \"probability_denominator\", \"times\"]].drop_duplicates().reset_index(drop=True).rename(columns={\"drop_id\": \"id\"})"
      ],
      "metadata": {
        "id": "IEXqYnSX4f9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_drop_main_df.to_csv(f\"{MAIN_PARSED_DIR}/random_drop_main_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "YYVSojJyU2gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop Collections"
      ],
      "metadata": {
        "id": "FG9OEirPSx0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "4moqWeoTSx0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_dropV2_DropCollection.bytes\", \"r\", encoding=\"utf-8\") as filename:\n",
        "\n",
        "  for text in filename.readlines():\n",
        "    texts.append(text.strip())\n",
        "    \n",
        "texts = \" \".join(texts)\n",
        "texts = re.sub(r'\\[([\\w\\\"]+)\\] =', '\\g<1>:', texts)\n",
        "texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\{([\\d\\, ]+)\\}', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "# print(texts)\n",
        "\n",
        "texts = texts.replace(\"{ {\", \"AAAAA\")\n",
        "texts = texts.replace(\"}, }, },\", \"BBBBB\")\n",
        "texts = texts.replace(\"}, }, {\", \"DDDDD\")\n",
        "texts = re.sub(r'\\}, \\}, (\\d)', 'FFFFF \\g<1>', texts)\n",
        "texts = re.sub(r'\\}, \\},$', 'EEEEE', texts)\n",
        "texts = texts.replace(\"}, },\", \"CCCCC\")\n",
        "\n",
        "texts = texts.replace(\"AAAAA\", \"[ {\")\n",
        "texts = texts.replace(\"BBBBB\", \"}, }, ],\")\n",
        "texts = texts.replace(\"CCCCC\", \"}, ],\")\n",
        "texts = texts.replace(\"DDDDD\", \"}, }, {\")\n",
        "texts = texts.replace(\"EEEEE\", \"}, },\")\n",
        "texts = texts.replace(\"FFFFF\", \"}, }, \")\n",
        "\n",
        "texts = \"{\" + texts + \"}\"\n",
        "\n",
        "drop_collections = literal_eval(texts)"
      ],
      "metadata": {
        "id": "heIjR4acSx0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "bFb-gM5rSx0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_entries = []\n",
        "\n",
        "for id, parsed_dict in drop_collections.items():\n",
        "  drop_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"drop_collections_id\": \"id\",\n",
        "      \"amount\": \"amount\",\n",
        "      \"drop_id\": 'dropId',\n",
        "      \"static_id\": \"staticId\",\n",
        "      \"type\": \"type\",\n",
        "      \"weight\": \"weight\",\n",
        "  }\n",
        "\n",
        "  # drop_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      drop_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  drop_entries.append(drop_entry)\n",
        "\n",
        "drop_collection_df = pd.DataFrame(drop_entries)"
      ],
      "metadata": {
        "id": "w99hTzfJSx0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random_drop_collection_info_df = pd.merge(complex_random_drop_com_df, drop_collection_df, how=\"left\", left_on=[\"drop_collections_id\"], right_on=[\"drop_collections_id\"])"
      ],
      "metadata": {
        "id": "_MWkbUUdadOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_drop_collection_info_df = drop_collection_df[~drop_collection_df[\"static_id\"].isnull()]"
      ],
      "metadata": {
        "id": "ou6A8bQyb1o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_drop_collection_info_fins = []\n",
        "for record in random_drop_collection_info_df.to_dict(orient=\"records\"):\n",
        "  for i in range(len(record[\"static_id\"])):\n",
        "    random_drop_collection_info_fin = {}\n",
        "    random_drop_collection_info_fin[\"drop_collections_id\"] = record[\"drop_collections_id\"]\n",
        "    # random_drop_collection_info_fin[\"drop_id\"] = record[\"id\"]\n",
        "    random_drop_collection_info_fin[\"item_id\"] = record[\"static_id\"][i]\n",
        "    random_drop_collection_info_fin[\"weight\"] = record[\"weight\"][i]\n",
        "    random_drop_collection_info_fin[\"amount\"] = record[\"amount\"][i]\n",
        "\n",
        "    random_drop_collection_info_fins.append(random_drop_collection_info_fin)\n",
        "\n",
        "random_drop_collection_info_fin_df = pd.DataFrame(random_drop_collection_info_fins)"
      ],
      "metadata": {
        "id": "qNWAi1ovUb45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_drop_collection_df = random_drop_collection_info_fin_df[[\"drop_collections_id\", \"item_id\", \"weight\", \"amount\"]].drop_duplicates().reset_index().rename(columns={\n",
        "    \"index\": \"id\",\n",
        "    \"item_id\": \"material_id\"\n",
        "})\n",
        "\n",
        "intersections = set(random_drop_collection_df[\"material_id\"].astype(float)).intersection(set(material_final_df[\"id\"].astype(float)))\n",
        "random_drop_collection_df = random_drop_collection_df[random_drop_collection_df[\"material_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "# intersections = set(random_drop_collection_df[\"drop_id\"].astype(float)).intersection(set(random_drop_com_df[\"id\"].astype(float)))\n",
        "# random_drop_collection_df = random_drop_collection_df[random_drop_collection_df[\"drop_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "random_drop_collection_df.to_csv(f\"{MAIN_PARSED_DIR}/random_drop_collection_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "uPV5QWoqdjai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_drop_collection_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "925BasjsSAEI",
        "outputId": "04818dcc-6a3b-461f-8f14-2525465ac3b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  drop_collections_id  material_id  weight  amount\n",
              "0          0               400001     10217127       1       1\n",
              "1          1               406301     10217127       1       1\n",
              "2          2               406401     10217127       1       1\n",
              "3          3               406402     10219517       1       1\n",
              "4          4               406501     10217127       1       1\n",
              "...      ...                  ...          ...     ...     ...\n",
              "10788  10791         110601170801     10201030     480       1\n",
              "10789  10792         110601170801     10201033    2390     100\n",
              "10790  10793         110601170801     10201026    2390      40\n",
              "10791  10794         110601170801     10201035     700      12\n",
              "10792  10795         110601170801     10207034       1       1\n",
              "\n",
              "[10561 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72a53a38-bf06-4080-b4bd-9124140ae7ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>drop_collections_id</th>\n",
              "      <th>material_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>400001</td>\n",
              "      <td>10217127</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>406301</td>\n",
              "      <td>10217127</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>406401</td>\n",
              "      <td>10217127</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>406402</td>\n",
              "      <td>10219517</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>406501</td>\n",
              "      <td>10217127</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10788</th>\n",
              "      <td>10791</td>\n",
              "      <td>110601170801</td>\n",
              "      <td>10201030</td>\n",
              "      <td>480</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10789</th>\n",
              "      <td>10792</td>\n",
              "      <td>110601170801</td>\n",
              "      <td>10201033</td>\n",
              "      <td>2390</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10790</th>\n",
              "      <td>10793</td>\n",
              "      <td>110601170801</td>\n",
              "      <td>10201026</td>\n",
              "      <td>2390</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10791</th>\n",
              "      <td>10794</td>\n",
              "      <td>110601170801</td>\n",
              "      <td>10201035</td>\n",
              "      <td>700</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10792</th>\n",
              "      <td>10795</td>\n",
              "      <td>110601170801</td>\n",
              "      <td>10207034</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10561 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72a53a38-bf06-4080-b4bd-9124140ae7ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72a53a38-bf06-4080-b4bd-9124140ae7ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72a53a38-bf06-4080-b4bd-9124140ae7ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Complex Random Drop Main Collections for database"
      ],
      "metadata": {
        "id": "PDmD2JVGPxkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_drop_main_collection_df = random_drop_info_fin_df[[\"drop_id\", \"drop_collections_id\", \"drop_collections_weight\"]].reset_index().rename(columns={\"drop_collections_weight\": \"weight\", \"index\": \"id\"})"
      ],
      "metadata": {
        "id": "U8zhiQykP1qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intersections = set(random_drop_main_collection_df[\"drop_id\"].astype(float)).intersection(set(random_drop_main_df[\"id\"].astype(float)))\n",
        "random_drop_main_collection_df = random_drop_main_collection_df[random_drop_main_collection_df[\"drop_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "intersections = set(random_drop_main_collection_df[\"drop_collections_id\"].astype(float)).intersection(set(random_drop_collection_df[\"drop_collections_id\"].astype(float)))\n",
        "random_drop_main_collection_df = random_drop_main_collection_df[random_drop_main_collection_df[\"drop_collections_id\"].astype(float).isin(intersections)]"
      ],
      "metadata": {
        "id": "Z-ULniZNjbIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_drop_main_collection_df.to_csv(f\"{MAIN_PARSED_DIR}/random_drop_main_collection_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "dUl11Lz7Q2p0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Monster"
      ],
      "metadata": {
        "id": "iKmf-kmluewb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "5bo-6oWMuq4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_monster_Monster.bytes\", \"r\", encoding=\"utf-8\") as filename:\n",
        "\n",
        "  for text in filename.readlines():\n",
        "    texts.append(text.strip())\n",
        "    \n",
        "  texts = \" \".join(texts)\n",
        "\n",
        "  texts = re.sub(r'\\[([\\w\\\"]+)\\] =', '\\g<1>:', texts)\n",
        "  texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "  texts = re.sub(r'\\{([\\d\\, ]+)\\}', '[\\g<1>]', texts)\n",
        "  texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "  \n",
        "  # print(texts)\n",
        "\n",
        "  texts = texts.replace(\"{ {\", \"AAAAA\")\n",
        "  texts = texts.replace(\"}, }, },\", \"BBBBB\")\n",
        "  texts = texts.replace(\"}, }, {\", \"DDDDD\")\n",
        "  texts = re.sub(r'\\}, \\}, (\\d)', 'FFFFF \\g<1>', texts)\n",
        "  texts = re.sub(r'\\}, \\},$', 'EEEEE', texts)\n",
        "  texts = texts.replace(\"}, },\", \"CCCCC\")\n",
        "\n",
        "  texts = texts.replace(\"AAAAA\", \"[ {\")\n",
        "  texts = texts.replace(\"BBBBB\", \"}, }, ],\")\n",
        "  texts = texts.replace(\"CCCCC\", \"}, ],\")\n",
        "  texts = texts.replace(\"DDDDD\", \"}, }, {\")\n",
        "  texts = texts.replace(\"EEEEE\", \"}, },\")\n",
        "  texts = texts.replace(\"FFFFF\", \"}, }, \")\n",
        "\n",
        "  texts = \"{\" + texts + \"}\"\n",
        "\n",
        "monsters = literal_eval(texts)"
      ],
      "metadata": {
        "id": "xiTkfDd5Sh-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "8OrqKnSPutzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monster_entries = []\n",
        "\n",
        "for id, parsed_dict in monsters.items():\n",
        "  monster_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      'name': 'name',\n",
        "      'Desc': 'Desc',\n",
        "      'DpsTestId': 'DpsTestId',\n",
        "      'DropListKV': 'DropListKV',\n",
        "      'EffectHang': 'EffectHang',\n",
        "      'EffectId': 'EffectId',\n",
        "      'EffectScale': 'EffectScale',\n",
        "      'ExtraEffect': 'ExtraEffect',\n",
        "      'HasDieEffect': 'HasDieEffect',\n",
        "      'IfCanShowInDpsTest': 'IfCanShowInDpsTest',\n",
        "      'IfIgnoreInvisibility': 'IfIgnoreInvisibility',\n",
        "      'IsSpecialSkillNotTarget': 'IsSpecialSkillNotTarget',\n",
        "      'MagicMap': 'MagicMap',\n",
        "      'MvpRankDrop': 'MvpRankDrop',\n",
        "      'MvpRareDrop': 'MvpRareDrop',\n",
        "      'PatrolPos': 'PatrolPos',\n",
        "      'PetId': 'PetId',\n",
        "      'RareDropType': 'RareDropType',\n",
        "      'RingScale': 'RingScale',\n",
        "      'Scale': 'Scale',\n",
        "      'ShowRing': 'ShowRing',\n",
        "      'SkillEffect': 'SkillEffect',\n",
        "      'Weather': 'Weather',\n",
        "      'alertRange': 'alertRange',\n",
        "      'aniSpeed': 'aniSpeed',\n",
        "      'attackSpeedIncrease': 'attackSpeedIncrease',\n",
        "      'baseExp': 'baseExp',\n",
        "      'bloodNums': 'bloodNums',\n",
        "      'bodily': 'bodily',\n",
        "      'bornSkillId': 'bornSkillId',\n",
        "      'bornSound': 'bornSound',\n",
        "      'bronEffectId': 'bronEffectId',\n",
        "      'calDamageToCreator': 'calDamageToCreator',\n",
        "      'canBattleTeleport': 'canBattleTeleport',\n",
        "      'cantSelect': 'cantSelect',\n",
        "      'castSkillRate': 'castSkillRate',\n",
        "      'chaseRange': 'chaseRange',\n",
        "      'criticalLevel': 'criticalLevel',\n",
        "      'criticalRate': 'criticalRate',\n",
        "      'criticalResistanceLevel': 'criticalResistanceLevel',\n",
        "      'criticalResistanceRate': 'criticalResistanceRate',\n",
        "      'criticalResistanceValue': 'criticalResistanceValue',\n",
        "      'criticalValue': 'criticalValue',\n",
        "      'dialogueBubbleList': 'dialogueBubbleList',\n",
        "      'dieEffectPath': 'dieEffectPath',\n",
        "      'dieSound': 'dieSound',\n",
        "      'dieSoundTime': 'dieSoundTime',\n",
        "      'dodgeLevel': 'dodgeLevel',\n",
        "      'dodgeRate': 'dodgeRate',\n",
        "      'dropAnnouncementId': 'dropAnnouncementId',\n",
        "      'finalMagicDefenseIncrease': 'finalMagicDefenseIncrease',\n",
        "      'finalPhysicDefenseIncrease': 'finalPhysicDefenseIncrease',\n",
        "      'fixedMagicDamage': 'fixedMagicDamage',\n",
        "      'fixedMagicDamageReduce': 'fixedMagicDamageReduce',\n",
        "      'fixedPhysicDamage': 'fixedPhysicDamage',\n",
        "      'fixedPhysicDamageReduce': 'fixedPhysicDamageReduce',\n",
        "      'followType': 'followType',\n",
        "      'forceType': 'forceType',\n",
        "      'hasWhiteEffect': 'hasWhiteEffect',\n",
        "      'hitIncrease': 'hitIncrease',\n",
        "      'hitLevel': 'hitLevel',\n",
        "      'id': 'id',\n",
        "      'idleSound': 'idleSound',\n",
        "      'ifActive': 'ifActive',\n",
        "      'ifChangeTarget': 'ifChangeTarget',\n",
        "      'ifControlledByPunishment': 'ifControlledByPunishment',\n",
        "      'ifSelectPlayerFirst': 'ifSelectPlayerFirst',\n",
        "      'isBeHitBack': 'isBeHitBack',\n",
        "      'isHideBlood': 'isHideBlood',\n",
        "      'isHideName': 'isHideName',\n",
        "      'isIgnoreForceAttack': 'isIgnoreForceAttack',\n",
        "      'isKeyMonster': 'isKeyMonster',\n",
        "      'isLevelEffect': 'isLevelEffect',\n",
        "      'isResetStateLeaveBattle': 'isResetStateLeaveBattle',\n",
        "      'isShowInMap': 'isShowInMap',\n",
        "      'isUnmove': 'isUnmove',\n",
        "      'jobExp': 'jobExp',\n",
        "      'level': 'level',\n",
        "      'lootForAll': 'lootForAll',\n",
        "      'magicDamageIncrease': 'magicDamageIncrease',\n",
        "      'magicDamagedIncrease': 'magicDamagedIncrease',\n",
        "      'magicDefenseLevel': 'magicDefenseLevel',\n",
        "      'magicDps': 'magicDps',\n",
        "      'magicPenetrationIncrease': 'magicPenetrationIncrease',\n",
        "      'magicPenetrationLevel': 'magicPenetrationLevel',\n",
        "      'magicRebound': 'magicRebound',\n",
        "      'maxHp': 'maxHp',\n",
        "      'monsterCollectionId': 'monsterCollectionId',\n",
        "      'monsterTypeForServer': 'monsterTypeForServer',\n",
        "      'mvpDropId': 'mvpDropId',\n",
        "      'name': 'name',\n",
        "      'nameLocalized': 'nameLocalized',\n",
        "      'navPos': 'navPos',\n",
        "      'navSceneId': 'navSceneId',\n",
        "      'navScenesId': 'navScenesId',\n",
        "      'overChaseChangeHatred': 'overChaseChangeHatred',\n",
        "      'patrolRange': 'patrolRange',\n",
        "      'patrolSpeed': 'patrolSpeed',\n",
        "      'patrolType': 'patrolType',\n",
        "      'physicDamageIncrease': 'physicDamageIncrease',\n",
        "      'physicDamagedIncrease': 'physicDamagedIncrease',\n",
        "      'physicDefenseLevel': 'physicDefenseLevel',\n",
        "      'physicDps': 'physicDps',\n",
        "      'physicPenetrationIncrease': 'physicPenetrationIncrease',\n",
        "      'physicPenetrationLevel': 'physicPenetrationLevel',\n",
        "      'property': 'property',\n",
        "      'race': 'race',\n",
        "      'radius': 'radius',\n",
        "      'readAttrFrom': 'readAttrFrom',\n",
        "      'rebound': 'rebound',\n",
        "      'resId': 'resId',\n",
        "      'runSound': 'runSound',\n",
        "      'showMiniProfile': 'showMiniProfile',\n",
        "      'skills': 'skills',\n",
        "      'soundVolume': 'soundVolume',\n",
        "      'speed': 'speed',\n",
        "      'staticId': 'staticId',\n",
        "      'tips': 'tips',\n",
        "      'type': 'type',\n",
        "      'magicVampire': 'magicVampire',\n",
        "      'vampire': 'vampire',\n",
        "      'zeny': 'zeny'\n",
        "  }\n",
        "\n",
        "  monster_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      monster_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  monster_entries.append(monster_entry)\n",
        "\n",
        "monster_info_df = pd.DataFrame(monster_entries)"
      ],
      "metadata": {
        "id": "lSbTP6UPSttX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge with information from `en_langs`"
      ],
      "metadata": {
        "id": "u0wZg1tYu35A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Monster name"
      ],
      "metadata": {
        "id": "0sUn02AIu_HB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monster_en_name_df = pd.DataFrame(parsed_data[\"monster_name\"])\n",
        "monster_en_name_df = monster_en_name_df.rename(columns={\"id\": \"name_id\", \"value\": \"en_name\"})\n",
        "\n",
        "monster_info_df[\"name_id\"] = monster_info_df[\"name\"].apply(lambda x: str(x).replace('\"', '').replace('MonsterName', \"\"))\n",
        "monster_info_df = pd.merge(monster_info_df, monster_en_name_df, how=\"left\", left_on=\"name_id\", right_on=\"name_id\")"
      ],
      "metadata": {
        "id": "qj9OCrNou3GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Monster description"
      ],
      "metadata": {
        "id": "97na4TsvvAkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monster_en_desc_df = pd.DataFrame(parsed_data[\"monster_desc\"])\n",
        "monster_en_desc_df[\"value\"] = monster_en_desc_df[\"value\"].apply(lambda x: str(x).replace(\"<color=#FFFFFF00>jayw</color>\", \"\"))\n",
        "monster_en_desc_df[\"value\"] = monster_en_desc_df[\"value\"].apply(lambda x: re.sub(r'\\<[\\/\\w\\=\\#]*\\>', '', x))\n",
        "monster_en_desc_df[\"value\"] = monster_en_desc_df[\"value\"].apply(lambda x: str(x).replace(\"\\\\n\", \"\").replace(\"\\\\\", \"\"))\n",
        "monster_en_desc_df = monster_en_desc_df.rename(columns={\"id\": \"desc_id\", \"value\": \"en_desc\"})\n",
        "monster_info_df[\"desc_id\"] = monster_info_df[\"Desc\"].apply(lambda x: str(x).replace('\"', '').replace('MonsterCollection', \"\"))\n",
        "monster_info_df = pd.merge(monster_info_df, monster_en_desc_df, how=\"left\", left_on=\"desc_id\", right_on=\"desc_id\")"
      ],
      "metadata": {
        "id": "1rFrG_Udu-kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter to include field monster only"
      ],
      "metadata": {
        "id": "aiqDiYOGvKd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monster_info_df.loc[monster_info_df[\"id\"] == 10001, \"level\"] = 1"
      ],
      "metadata": {
        "id": "CvVcWB_WS6Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monster_df = monster_info_df[(~monster_info_df[\"DropListKV\"].isnull()) & (~monster_info_df[\"navPos\"].isnull()) & (~monster_info_df[\"en_name\"].isnull()) & (~monster_info_df[\"en_name\"].isnull())]\n",
        "monster_df = monster_df[monster_df[\"level\"] <= 120]\n",
        "monster_df = monster_df[monster_df[\"id\"] <= 20000]\n",
        "\n",
        "monster_df = monster_df.drop_duplicates(\"en_name\", keep=\"first\")\n"
      ],
      "metadata": {
        "id": "T-90JMzUvE5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for Monster Drop"
      ],
      "metadata": {
        "id": "bC_ZlBgVvRBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monster_drop_records = monster_df[[\"id\", \"en_name\", \"DropListKV\"]].to_dict(orient=\"records\")"
      ],
      "metadata": {
        "id": "5UC5SHOHvI_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monster Skills"
      ],
      "metadata": {
        "id": "QXPPzbLUNeD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monster_skills_raw_df = monster_df[[\"id\", \"skills\"]]"
      ],
      "metadata": {
        "id": "dNutjFDhNg8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter columns and column name correction"
      ],
      "metadata": {
        "id": "ivxEbXWXvV5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monster_df = monster_df.rename(columns={\n",
        "    \"id\": \"id\",\n",
        "    \"attackSpeedIncrease\": \"final_aspd\",\n",
        "    \"baseExp\": \"b_exp\",\n",
        "    \"criticalLevel\": \"crit\",\n",
        "    \"criticalRate\": \"final_crit\",\n",
        "    \"criticalResistanceLevel\": \"crit_res\",\n",
        "    \"criticalResistanceRate\" : \"final_crit_res\",\n",
        "    \"dodgeLevel\": \"dodge\",\n",
        "    \"dodgeRate\": \"final_dodge\",\n",
        "    \"hitLevel\": \"hit\",\n",
        "    \"hitIncrease\": \"final_hit\",\n",
        "    \"jobExp\": \"j_exp\",\n",
        "    \"magicDefenseLevel\": \"m_def\",\n",
        "    \"finalMagicDefenseIncrease\" : \"final_m_def\",\n",
        "    \"magicDamageIncrease\": \"final_m_dmg_bonus\",\n",
        "    \"magicDamagedIncrease\": \"final_m_dmg_res\",\n",
        "    \"magicDps\": \"m_dps\",\n",
        "    \"magicPenetrationLevel\": \"m_pen\",\n",
        "    \"magicPenetrationIncrease\": \"final_m_pen\",\n",
        "    \"magicRebound\": \"m_reflect\",\n",
        "    \"magicVampire\": \"m_lifesteal\",\n",
        "    \"fixedMagicDamage\": \"m_dmg_bonus\",\n",
        "    \"fixedMagicDamageReduce\": \"m_dmg_res\",\n",
        "    \"maxHp\": \"max_hp\",\n",
        "    \"navSceneId\": \"location\",\n",
        "    \"bodily\": \"size\",\n",
        "    \"physicDefenseLevel\": \"p_def\",\n",
        "    \"physicDps\": \"p_dps\",\n",
        "    \"physicDamageIncrease\": \"final_p_dmg_bonus\",\n",
        "    \"fixedPhysicDamage\": \"p_dmg_bonus\",\n",
        "    \"physicDamagedIncrease\" : \"final_p_dmg_res\",\n",
        "    \"physicPenetrationIncrease\": \"final_p_pen\",\n",
        "    \"finalPhysicDefenseIncrease\": \"final_p_def\",\n",
        "    \"physicPenetrationLevel\": \"p_pen\",\n",
        "    \"fixedPhysicDamageReduce\": \"p_dmg_res\",\n",
        "    \"vampire\": \"p_lifesteal\",\n",
        "    \"rebound\": 'p_reflect',\n",
        "    \"property\": \"property\",\n",
        "    \"race\": \"race\",\n",
        "    \"type\": \"type\",\n",
        "    \"level\": \"level\",\n",
        "    \"resId\": \"res_id\",\n",
        "    \"en_desc\": \"description\"\n",
        "    })\n",
        "\n",
        "monster_df = monster_df[['id', 'en_name', 'b_exp', 'crit', 'final_crit', 'crit_res', 'final_crit_res', 'dodge', 'final_dodge', 'final_aspd', 'hit', 'final_hit', 'j_exp', 'm_def', 'final_m_def', 'final_m_dmg_bonus', 'final_m_dmg_res', 'm_dps', 'm_pen', 'final_m_pen', 'm_dmg_bonus', 'm_dmg_res', 'max_hp', 'location', 'size', 'p_def', 'final_p_def', 'p_dps', 'final_p_dmg_bonus', 'final_p_dmg_res', 'final_p_pen', 'p_pen', 'p_reflect', 'p_dmg_res', 'p_dmg_bonus', 'property', 'race', 'type', 'level', 'res_id', 'description', \"zeny\"]]"
      ],
      "metadata": {
        "id": "oaqjTjspvVPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data correction"
      ],
      "metadata": {
        "id": "K5xKCDYXvgOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['crit', 'crit_res', 'dodge', 'hit', 'j_exp', 'm_def', 'm_dps', 'm_pen', 'max_hp', 'location', 'p_def', 'p_dps', 'p_pen']\n",
        "\n",
        "for col in cols:\n",
        "  monster_df[col] = monster_df[col].fillna(0)\n",
        "\n",
        "monster_df[\"size\"] = monster_df[\"size\"].fillna(1)\n",
        "monster_df[\"race\"] = monster_df[\"race\"].fillna(32)\n",
        "\n",
        "cols = ['property', 'type']\n",
        "\n",
        "for col in cols:\n",
        "  monster_df[col] = monster_df[col].fillna(0)\n",
        "\n",
        "monster_df[\"level\"] = monster_df[\"level\"].fillna(1)\n",
        "monster_df = monster_df.rename(columns={\"size\": \"size_id\", \"property\": \"attr_id\", \"race\": \"race_id\", \"type\": \"type_id\", \"location\": \"loc_id\"})"
      ],
      "metadata": {
        "id": "TN-dz7vXvcjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge with information from `en_langs`"
      ],
      "metadata": {
        "id": "oJZVvULmvzET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save data for database"
      ],
      "metadata": {
        "id": "fZZLn4p-wOUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Monster size"
      ],
      "metadata": {
        "id": "RORVPjA1v64c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monster_size_df = pd.DataFrame({\"size_id\": [0, 1, 2, 3], \"size\": [\"Large\", \"Medium\", \"Small\", \"Giant\"]})\n",
        "monster_df[\"size_id\"] = monster_df[\"size_id\"].astype(float)\n",
        "monster_df = pd.merge(monster_df, monster_size_df, how=\"left\", left_on=\"size_id\", right_on=\"size_id\")"
      ],
      "metadata": {
        "id": "ET8PVlNvvxHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Monster attributes"
      ],
      "metadata": {
        "id": "XoyZJjVGv85c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monster_attr_df = pd.DataFrame(parsed_data[\"attr\"])\n",
        "monster_attr_df = monster_attr_df.rename(columns={\"id\": \"attr_id\", \"value\": \"attr\"})\n",
        "monster_attr_df[\"attr_id\"] = monster_attr_df[\"attr_id\"].astype(float)\n",
        "monster_df[\"attr_id\"] = monster_df[\"attr_id\"].astype(float)\n",
        "monster_attr_df[\"attr_id\"] = monster_attr_df[\"attr_id\"] - 1\n",
        "monster_df = pd.merge(monster_df, monster_attr_df, how=\"left\", left_on=\"attr_id\", right_on=\"attr_id\")"
      ],
      "metadata": {
        "id": "lT1Uh2Puv8Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Monster race"
      ],
      "metadata": {
        "id": "GYiKELZqwA_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monster_race_df = pd.DataFrame(parsed_data[\"race\"])\n",
        "monster_race_df = monster_race_df.rename(columns={\"id\": \"race_id\", \"value\": \"race\"})\n",
        "monster_race_df[\"race_id\"] = monster_race_df[\"race_id\"].astype(float)\n",
        "monster_df[\"race_id\"] = monster_df[\"race_id\"].astype(float)\n",
        "monster_df = pd.merge(monster_df, monster_race_df, how=\"left\", left_on=\"race_id\", right_on=\"race_id\")"
      ],
      "metadata": {
        "id": "GkR9ImmkwAhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Monster location"
      ],
      "metadata": {
        "id": "5mGv5cOpwH9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monster_loc_df = pd.DataFrame(parsed_data[\"scene_name\"])\n",
        "monster_loc_df = monster_loc_df.rename(columns={\"id\": \"loc_id\", \"value\": \"loc\"})\n",
        "monster_loc_df[\"loc_id\"] = monster_loc_df[\"loc_id\"].astype(float)\n",
        "monster_df[\"loc_id\"] = monster_df[\"loc_id\"].astype(float)\n",
        "monster_df = pd.merge(monster_df, monster_loc_df, how=\"left\", left_on=\"loc_id\", right_on=\"loc_id\")"
      ],
      "metadata": {
        "id": "TV6qWAC3wDyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data correction (cont)"
      ],
      "metadata": {
        "id": "kFbUOtBFwKB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monster_df = monster_df.drop([\"size_id\", \"attr_id\", \"race_id\"], axis=1)\n",
        "cols = [\"en_name\", \"size\", \"attr\", \"race\"]\n",
        "\n",
        "for col in cols:\n",
        "  monster_df[col] = monster_df[col].str.lower()\n",
        "\n",
        "monster_df[\"race\"] = monster_df[\"race\"].fillna(\"demi-human\")\n",
        "monster_df = monster_df.drop(\"type_id\", axis=1)\n",
        "monster_df = monster_df.rename(columns={\n",
        "    \"en_name\": \"name\",\n",
        "})"
      ],
      "metadata": {
        "id": "Eh_8L0n0wLya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monster_df = monster_df.query(\"loc != '???'\")"
      ],
      "metadata": {
        "id": "TQDRAqRLX60T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monster_final_df = monster_df.copy()"
      ],
      "metadata": {
        "id": "IE3fPCdOVJ-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save data for database"
      ],
      "metadata": {
        "id": "OggZKodGeQ_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monster_final_df.to_csv(f\"{MAIN_PARSED_DIR}/monster_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "1ouHQCXLeQ_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Monster Drop"
      ],
      "metadata": {
        "id": "NPXtLy7qxln-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Monster Drop information from Monster"
      ],
      "metadata": {
        "id": "W8xUHzNHxsAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get monster drop info\n",
        "drop_records = []\n",
        "\n",
        "for monster_drop_record in monster_drop_records:\n",
        "  try:\n",
        "    for drop in monster_drop_record[\"DropListKV\"].items():\n",
        "      drop_record = {}\n",
        "\n",
        "      drop_id, value = drop\n",
        "      drop_record[\"drop_id\"] = drop_id\n",
        "      drop_record[\"value\"] = value\n",
        "      drop_record[\"monster_name\"] = monster_drop_record[\"en_name\"]\n",
        "      drop_record[\"monster_id\"] = monster_drop_record[\"id\"]\n",
        "\n",
        "      drop_records.append(drop_record)\n",
        "  except:\n",
        "    drop_record[\"drop_id\"] = drop_id\n",
        "    drop_record[\"value\"] = value\n",
        "    drop_record[\"monster_name\"] = monster_drop_record[\"en_name\"]\n",
        "    drop_record[\"monster_id\"] = monster_drop_record[\"id\"]\n",
        "\n",
        "    drop_records.append(drop_record)\n",
        "\n",
        "monster_drop_df = pd.DataFrame(drop_records)"
      ],
      "metadata": {
        "id": "rf69kVfPxJT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Monster Random Drop"
      ],
      "metadata": {
        "id": "cwcNnLdbxvcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monster_random_drop_df = monster_drop_df[[\"monster_id\", \"drop_id\"]].drop_duplicates().reset_index().rename(columns={\"index\": \"id\"})\n",
        "monster_random_drop_df = monster_random_drop_df[monster_random_drop_df[\"drop_id\"] != 0]\n",
        "\n",
        "intersections = set(monster_random_drop_df[\"drop_id\"].astype(int)).intersection(set(random_drop_main_df[\"id\"].astype(int)))\n",
        "monster_random_drop_df = monster_random_drop_df[monster_random_drop_df[\"drop_id\"].astype(int).isin(intersections)]\n",
        "\n",
        "intersections = set(monster_random_drop_df[\"monster_id\"].astype(int)).intersection(set(monster_df[\"id\"].astype(int)))\n",
        "monster_random_drop_df = monster_random_drop_df[monster_random_drop_df[\"monster_id\"].astype(int).isin(intersections)]\n",
        "\n",
        "monster_random_drop_df.to_csv(f\"{MAIN_PARSED_DIR}/monster_random_drop_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "Fb0dEK-nB7CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Monster Skills"
      ],
      "metadata": {
        "id": "PqRzk8dcN2Pd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get information from Monster"
      ],
      "metadata": {
        "id": "fUEc1pQsOO6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monster_skills_records = monster_skills_raw_df.to_dict(orient=\"records\")"
      ],
      "metadata": {
        "id": "4xVfXspwN40Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skill_records = []\n",
        "\n",
        "for monster_skills_record in monster_skills_records:\n",
        "  for monster_skill_record in monster_skills_record[\"skills\"]:\n",
        "    skill_record = {}\n",
        "\n",
        "    skill_record[\"monster_id\"] = monster_skills_record[\"id\"]\n",
        "    skill_record[\"skill_id\"] = monster_skill_record[\"skillId\"]\n",
        "    skill_record[\"cast_weight\"] = monster_skill_record[\"castWeight\"]\n",
        "  \n",
        "    skill_records.append(skill_record)\n",
        "\n",
        "monster_skill_df = pd.DataFrame(skill_records)"
      ],
      "metadata": {
        "id": "u1rw0ouYOIHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monster_skill_df = monster_skill_df.reset_index().rename(columns={\"index\": \"id\"})"
      ],
      "metadata": {
        "id": "oyLXxmuHPskt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check for missing information"
      ],
      "metadata": {
        "id": "BSNigeqbQD7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intersections = set(monster_skill_df[\"skill_id\"].astype(int)).intersection(set(skill_complex_final_df[\"id\"].astype(int)))\n",
        "monster_skill_final_df = monster_skill_df[monster_skill_df[\"skill_id\"].astype(int).isin(intersections)]\n",
        "\n",
        "intersections = set(monster_skill_df[\"monster_id\"].astype(int)).intersection(set(monster_final_df[\"id\"].astype(int)))\n",
        "monster_skill_final_df = monster_skill_df[monster_skill_df[\"monster_id\"].astype(int).isin(intersections)]"
      ],
      "metadata": {
        "id": "-83Hht3LP9Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save data for database"
      ],
      "metadata": {
        "id": "g9FtJfQ2Qbg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monster_skill_final_df.to_csv(f\"{MAIN_PARSED_DIR}/monster_skill_final_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "HrjP3AZAkTXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boss"
      ],
      "metadata": {
        "id": "886FmcQIyumF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Boss information from Monster"
      ],
      "metadata": {
        "id": "KLC1jEiGy18L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monster_info_df = monster_info_df[~monster_info_df[\"id\"].isnull()]"
      ],
      "metadata": {
        "id": "Js_ALdevkc2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monster_info_df[\"id\"] = monster_info_df[\"id\"].astype(int)\n",
        "\n",
        "mvp_mini_info_df = monster_info_df[(~monster_info_df[\"MvpRareDrop\"].isnull()) & (monster_info_df[\"id\"] < 32000)]"
      ],
      "metadata": {
        "id": "E-mg3Rn8ytVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mvp_mini_info_df = mvp_mini_info_df[mvp_mini_info_df[\"level\"] <= 120]"
      ],
      "metadata": {
        "id": "l42SWgzle6k5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter columns to contain columns of interest"
      ],
      "metadata": {
        "id": "gXz_Mprsy-Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mvp_mini_df = mvp_mini_info_df.rename(columns={\n",
        "    \"id\": \"id\",\n",
        "    \"attackSpeedIncrease\": \"final_aspd\",\n",
        "    \"baseExp\": \"b_exp\",\n",
        "    \"criticalLevel\": \"crit\",\n",
        "    \"criticalRate\": \"final_crit\",\n",
        "    \"criticalResistanceLevel\": \"crit_res\",\n",
        "    \"criticalResistanceRate\" : \"final_crit_res\",\n",
        "    \"dodgeLevel\": \"dodge\",\n",
        "    \"dodgeRate\": \"final_dodge\",\n",
        "    \"hitLevel\": \"hit\",\n",
        "    \"hitIncrease\": \"final_hit\",\n",
        "    \"jobExp\": \"j_exp\",\n",
        "    \"magicDefenseLevel\": \"m_def\",\n",
        "    \"finalMagicDefenseIncrease\" : \"final_m_def\",\n",
        "    \"magicDamageIncrease\": \"final_m_dmg_bonus\",\n",
        "    \"magicDamagedIncrease\": \"final_m_dmg_res\",\n",
        "    \"magicDps\": \"m_dps\",\n",
        "    \"magicPenetrationLevel\": \"m_pen\",\n",
        "    \"magicPenetrationIncrease\": \"final_m_pen\",\n",
        "    \"magicRebound\": \"m_reflect\",\n",
        "    \"magicVampire\": \"m_lifesteal\",\n",
        "    \"fixedMagicDamage\": \"m_dmg_bonus\",\n",
        "    \"fixedMagicDamageReduce\": \"m_dmg_res\",\n",
        "    \"maxHp\": \"max_hp\",\n",
        "    \"navSceneId\": \"location\",\n",
        "    \"bodily\": \"size\",\n",
        "    \"physicDefenseLevel\": \"p_def\",\n",
        "    \"physicDps\": \"p_dps\",\n",
        "    \"physicDamageIncrease\": \"final_p_dmg_bonus\",\n",
        "    \"fixedPhysicDamage\": \"p_dmg_bonus\",\n",
        "    \"physicDamagedIncrease\" : \"final_p_dmg_res\",\n",
        "    \"physicPenetrationIncrease\": \"final_p_pen\",\n",
        "    \"finalPhysicDefenseIncrease\": \"final_p_def\",\n",
        "    \"physicPenetrationLevel\": \"p_pen\",\n",
        "    \"fixedPhysicDamageReduce\": \"p_dmg_res\",\n",
        "    \"vampire\": \"p_lifesteal\",\n",
        "    \"rebound\": 'p_reflect',\n",
        "    \"property\": \"property\",\n",
        "    \"race\": \"race\",\n",
        "    \"type\": \"type\",\n",
        "    \"level\": \"level\",\n",
        "    \"resId\": \"res_id\",\n",
        "    \"en_desc\": \"description\"\n",
        "    })\n",
        "\n",
        "mvp_mini_df = mvp_mini_df[['id', 'en_name', 'b_exp', 'crit', 'final_crit', 'crit_res', 'final_crit_res', 'dodge', 'final_dodge', 'final_aspd', 'hit', 'final_hit', 'j_exp', 'm_def', 'final_m_def', 'final_m_dmg_bonus', 'final_m_dmg_res', 'm_dps', 'm_pen', 'final_m_pen', 'm_dmg_bonus', 'm_dmg_res', 'max_hp', 'location', 'size', 'p_def', 'final_p_def', 'p_dps', 'final_p_dmg_bonus', 'final_p_dmg_res', 'final_p_pen', 'p_pen', 'p_reflect', 'p_dmg_res', 'p_dmg_bonus', 'property', 'race', 'type', 'level', 'res_id', 'description', \"zeny\"]]"
      ],
      "metadata": {
        "id": "OoeASfZWy4p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Correction"
      ],
      "metadata": {
        "id": "euZtuB-RzBw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cols:\n",
        "  if col in list(mvp_mini_df.columns):\n",
        "    mvp_mini_df[col] = mvp_mini_df[col].fillna(0)\n",
        "\n",
        "mvp_mini_df[\"race\"] = mvp_mini_df[\"race\"].fillna(32)\n",
        "cols = ['type', 'size']\n",
        "\n",
        "for col in cols:\n",
        "  if col in list(mvp_mini_df.columns):\n",
        "    mvp_mini_df[col] = mvp_mini_df[col].fillna(1)\n",
        "\n",
        "mvp_mini_df[\"level\"] = mvp_mini_df[\"level\"].fillna(110)\n",
        "mvp_mini_df = mvp_mini_df.rename(columns={\"size\": \"size_id\", \"property\": \"attr_id\", \"race\": \"race_id\", \"type\": \"type_id\", \"location\": \"loc_id\"})"
      ],
      "metadata": {
        "id": "B58MW_iJzBIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge with information from `en_langs`"
      ],
      "metadata": {
        "id": "UHoZ5jMFzKKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Boss size"
      ],
      "metadata": {
        "id": "MiaTnJrRzRvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mvp_mini_df = pd.merge(mvp_mini_df, monster_size_df, how=\"left\", left_on=\"size_id\", right_on=\"size_id\")"
      ],
      "metadata": {
        "id": "EVpchS8gzJmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Boss attribute"
      ],
      "metadata": {
        "id": "Ar0Lmxc5zTIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mvp_mini_df = pd.merge(mvp_mini_df, monster_attr_df, how=\"left\", left_on=\"attr_id\", right_on=\"attr_id\")"
      ],
      "metadata": {
        "id": "tJmbBRJwzRGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Boss race"
      ],
      "metadata": {
        "id": "HiiWapgkzdAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mvp_mini_df = pd.merge(mvp_mini_df, monster_race_df, how=\"left\", left_on=\"race_id\", right_on=\"race_id\")"
      ],
      "metadata": {
        "id": "pVnzqxC1zbJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final correction"
      ],
      "metadata": {
        "id": "j-uqDxhKzukq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mvp_mini_df = mvp_mini_df.rename(columns=({\"en_name\": \"name\"}))"
      ],
      "metadata": {
        "id": "yju_lOk7l0E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mvp_mini_df= mvp_mini_df.drop([\"size_id\", \"attr_id\", \"race_id\"], axis=1)\n",
        "\n",
        "cols = [\"name\", \"size\", \"attr\", \"race\"]\n",
        "\n",
        "for col in cols:\n",
        "  mvp_mini_df[col] = mvp_mini_df[col].str.lower()\n",
        "\n",
        "mvp_mini_df[\"race\"] = mvp_mini_df[\"race\"].fillna(\"demi-human\")"
      ],
      "metadata": {
        "id": "n_VlcPDSzsO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mvp_mini_df[\"attr\"] = mvp_mini_df[\"attr\"].fillna(\"neutral\")"
      ],
      "metadata": {
        "id": "H47fYBEWkRkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "AYYr-Zeizxzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boss_df = mvp_mini_df.copy()"
      ],
      "metadata": {
        "id": "2jsKRd1wgpFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boss_final_df = boss_df[~boss_df[\"name\"].isnull()]"
      ],
      "metadata": {
        "id": "4tCImP6tVy_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boss_final_df = boss_final_df.drop([\"type_id\", \"loc_id\"], axis=1)"
      ],
      "metadata": {
        "id": "KCmsaaA9mGR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boss_final_df.to_csv(f\"{MAIN_PARSED_DIR}/boss_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "0-meHoj9zxPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boss Drop"
      ],
      "metadata": {
        "id": "ShI0kD_Rz134"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Boss Drop information from Boss"
      ],
      "metadata": {
        "id": "hlBBXr8r0D5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boss_drop_records = mvp_mini_info_df[[\"id\", \"MvpRareDrop\"]].to_dict(orient=\"records\")\n",
        "\n",
        "drop_records = []\n",
        "\n",
        "for boss_drop_record in boss_drop_records:\n",
        "  try:\n",
        "    for drop in boss_drop_record[\"MvpRareDrop\"]:\n",
        "      drop_record = {}\n",
        "\n",
        "      drop_record[\"drop_id\"] = drop[\"DropId\"]\n",
        "      drop_record[\"boss_id\"] = boss_drop_record[\"id\"]\n",
        "\n",
        "      drop_records.append(drop_record)\n",
        "  except:\n",
        "    drop_record[\"drop_id\"] = drop[\"DropId\"]\n",
        "    drop_record[\"boss_id\"] = boss_drop_record[\"id\"]\n",
        "\n",
        "    drop_records.append(drop_record)\n",
        "\n",
        "boss_drop_df = pd.DataFrame(drop_records)"
      ],
      "metadata": {
        "id": "HhnbgB__z0PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge with Random Drop"
      ],
      "metadata": {
        "id": "oekVvRth0N8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boss_random_drop_df = boss_drop_df.reset_index().rename(columns={\"index\": \"id\"})\n",
        "\n",
        "intersections = set(boss_random_drop_df[\"drop_id\"].astype(int)).intersection(set(random_drop_main_df[\"id\"].astype(int)))\n",
        "boss_random_drop_df = boss_random_drop_df[boss_random_drop_df[\"drop_id\"].astype(int).isin(intersections)]\n",
        "\n",
        "intersections = set(boss_random_drop_df[\"boss_id\"].astype(int)).intersection(set(boss_final_df[\"id\"].astype(int)))\n",
        "boss_random_drop_df = boss_random_drop_df[boss_random_drop_df[\"boss_id\"].astype(int).isin(intersections)]"
      ],
      "metadata": {
        "id": "oWwXG6rz0NhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Boss Drop for database"
      ],
      "metadata": {
        "id": "0_HEgsAm0W9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boss_random_drop_df.to_csv(f\"{MAIN_PARSED_DIR}/boss_random_drop_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "YWG1AVYo0W9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creature"
      ],
      "metadata": {
        "id": "Hc5W1mh-wU2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data from Monster and Boss"
      ],
      "metadata": {
        "id": "fv-PYKr9wWZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "creature_one_df = monster_final_df[[\"id\", \"name\", \"description\", \"res_id\"]]\n",
        "creature_one_df[\"is_boss\"] = 0\n",
        "\n",
        "creature_two_df = boss_final_df[[\"id\", \"name\", \"description\", \"res_id\"]]\n",
        "creature_two_df[\"is_boss\"] = 1"
      ],
      "metadata": {
        "id": "yNZTKPfowm7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creature_final_df = creature_one_df.append(creature_two_df, ignore_index=True)\n",
        "creature_final_df[\"name\"] = creature_final_df[\"name\"].str.lower()"
      ],
      "metadata": {
        "id": "IY5UHIpVxNi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creature_final_df = creature_final_df.copy()\n",
        "creature_df = creature_final_df.copy()"
      ],
      "metadata": {
        "id": "Ju8iZw_Kr45U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "8coRZDU_xG_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "creature_final_df.to_csv(f\"{MAIN_PARSED_DIR}/creature_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "hMN72IQ8xG_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instance Drop"
      ],
      "metadata": {
        "id": "YageqrfN_r_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data for Instance Drop"
      ],
      "metadata": {
        "id": "fuludRueADi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_info_df[\"id\"] = drop_info_df[\"id\"].astype(int)\n",
        "instance_drop_info_df = drop_info_df.query(\"id < 208999 and id >= 201000\")"
      ],
      "metadata": {
        "id": "fJowIz-mADFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Instance Fixed Drop information"
      ],
      "metadata": {
        "id": "tq5hoG9kB8rY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "NkMLYklTDAPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instance_fixed_drop_info_fin_df = fixed_drop_info_fin_df.query(\"drop_id < 208999 and drop_id >= 201000\")"
      ],
      "metadata": {
        "id": "di1LS804kOI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data manipulation"
      ],
      "metadata": {
        "id": "nzvy6T7ZDJrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instance_fixed_drop_info_fin_df[\"instance_id\"] = instance_fixed_drop_info_fin_df[\"drop_id\"] // 100\n",
        "instance_fixed_drop_info_fin_df[\"item_id\"] = instance_fixed_drop_info_fin_df[\"item_id\"] - 1 + 1000\n",
        "instance_fixed_drop_info_fin_df[\"item_id\"] = instance_fixed_drop_info_fin_df[\"item_id\"].apply(lambda x : 1001 if x == 1000 else x)\n",
        "instance_fixed_drop_info_fin_df = instance_fixed_drop_info_fin_df.reset_index().rename(columns={\"index\": \"id\", \"item_id\": \"material_id\", \"item_num\": \"material_num\"})"
      ],
      "metadata": {
        "id": "bvldtVmFDN7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save Instance Fixed Drop for database"
      ],
      "metadata": {
        "id": "n8a9lPUuDZja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instance_fixed_drop_info_fin_df.to_csv(f\"{MAIN_PARSED_DIR}/instance_fixed_drop_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "gC-L12YRDYj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Instance Random Drop information"
      ],
      "metadata": {
        "id": "mpe2ENO9CzTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instance_random_drop_info_fin_df = random_drop_info_fin_df.query(\"drop_id < 208999 and drop_id >= 201000\")"
      ],
      "metadata": {
        "id": "RPzBL6I0XoZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "10jnwWztDqiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data manipulation"
      ],
      "metadata": {
        "id": "1eXYOVzJEGvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instance_random_drop_info_fin_df[\"instance_id\"] = instance_random_drop_info_fin_df[\"drop_id\"] // 100\n",
        "eligible_instances = instance_random_drop_info_fin_df[\"instance_id\"].unique()[np.where(instance_random_drop_info_fin_df[\"instance_id\"].unique() >= 2020)]\n",
        "eligible_instances = eligible_instances[np.where((eligible_instances % 10 != 3) & (eligible_instances % 10 != 4))]\n",
        "\n",
        "for eligible_instance in eligible_instances:\n",
        "  temp_df = instance_random_drop_info_fin_df.query(\"drop_id == 202300\").copy()\n",
        "\n",
        "  temp_df[\"drop_id\"] = (eligible_instance + 100) * 100\n",
        "  temp_df[\"instance_id\"] = eligible_instance\n",
        "  instance_random_drop_info_fin_df = instance_random_drop_info_fin_df.append(temp_df, ignore_index=True)\n",
        "\n",
        "eligible_instances = [2000 + (i * 10) + 3 for i in range(1, 9)]\n",
        "\n",
        "for eligible_instance in eligible_instances:\n",
        "  drop_ids = [eligible_instance * 100 + 1, eligible_instance * 100 + 2]\n",
        "  temp_df = instance_random_drop_info_fin_df.query(f\"instance_id == {eligible_instance} and drop_id == @drop_ids\").copy()\n",
        "\n",
        "  for i in range(2):\n",
        "    temp_df[\"instance_id\"] = eligible_instance - (i + 2)\n",
        "    temp_df[\"drop_id\"] = temp_df[\"drop_id\"] + i + 99 \n",
        "    instance_random_drop_info_fin_df = instance_random_drop_info_fin_df.append(temp_df, ignore_index=True)\n",
        "\n",
        "  if eligible_instance != 2023:\n",
        "    drop_ids = [eligible_instance * 100 + 3, eligible_instance * 100 + 4]\n",
        "    temp_df = instance_random_drop_info_fin_df.query(f\"instance_id == {eligible_instance} and drop_id == @drop_ids\").copy()\n",
        "\n",
        "    temp_df[\"instance_id\"] = eligible_instance - 1\n",
        "\n",
        "    instance_random_drop_info_fin_df = instance_random_drop_info_fin_df.append(temp_df, ignore_index=True)\n",
        "  else:\n",
        "    drop_ids = [eligible_instance * 100 + 6, eligible_instance * 100 + 9]\n",
        "    temp_df = instance_random_drop_info_fin_df.query(f\"instance_id == {eligible_instance} and drop_id == @drop_ids\").copy()\n",
        "\n",
        "    temp_df[\"instance_id\"] = eligible_instance - 1\n",
        "\n",
        "    instance_random_drop_info_fin_df = instance_random_drop_info_fin_df.append(temp_df, ignore_index=True)\n",
        "\n",
        "instance_random_drop_info_fin_df = instance_random_drop_info_fin_df[instance_random_drop_info_fin_df[\"instance_id\"] % 10 != 3]\n",
        "instance_random_drop_info_fin_df = instance_random_drop_info_fin_df[instance_random_drop_info_fin_df[\"instance_id\"] % 10 != 4]"
      ],
      "metadata": {
        "id": "wuM_cE5JEIcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "available_instances = instance_random_drop_info_fin_df[\"instance_id\"].unique().tolist()\n",
        "\n",
        "for available_instance in available_instances:\n",
        "  extra_drop_temp_df = random_drop_info_fin_df.query(\"drop_id == 202305\").copy()\n",
        "  extra_drop_temp_df[\"drop_id\"] = available_instance + 58 + 290000\n",
        "  extra_drop_temp_df[\"instance_id\"] = available_instance\n",
        "\n",
        "  instance_random_drop_info_fin_df = instance_random_drop_info_fin_df.append(extra_drop_temp_df, ignore_index=True)  "
      ],
      "metadata": {
        "id": "SnkYAeOhaQcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save Complex Instance Random Drop for database"
      ],
      "metadata": {
        "id": "hOng-Sw5EYxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instance_complex_random_drop_df = instance_random_drop_info_fin_df[[\"drop_id\", \"instance_id\"]].drop_duplicates().reset_index().rename(columns={\"index\": \"id\"})\n",
        "\n",
        "intersections = set(instance_complex_random_drop_df[\"drop_id\"].astype(int)).intersection(set(random_drop_main_df[\"id\"].astype(int)))\n",
        "instance_complex_random_drop_df = instance_complex_random_drop_df[instance_complex_random_drop_df[\"drop_id\"].astype(int).isin(intersections)]\n",
        "\n",
        "instance_complex_random_drop_df.to_csv(f\"{MAIN_PARSED_DIR}/instance_random_drop_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "gjbGTV2OEeEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instance"
      ],
      "metadata": {
        "id": "1rea9zwNV7Yo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data from Instance Random Drop"
      ],
      "metadata": {
        "id": "-B1m3G8jV9l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instance_df = instance_random_drop_info_fin_df[[\"instance_id\"]].dropna().drop_duplicates().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "bbmIvM5xWStn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge with information from `en_langs`"
      ],
      "metadata": {
        "id": "f22fdexIWKAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scene Name"
      ],
      "metadata": {
        "id": "LWYH3IfOWXF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scene_name_df = pd.DataFrame(parsed_data[\"scene_name\"]).rename(columns={\"value\": \"name\"})\n",
        "scene_name_df[\"id\"] = scene_name_df[\"id\"].apply(int)\n",
        "\n",
        "instance_df = instance_df.rename(columns={\"instance_id\": \"id\"})\n",
        "instance_df = pd.merge(instance_df, scene_name_df, how=\"left\", left_on=[\"id\"], right_on=[\"id\"])"
      ],
      "metadata": {
        "id": "OTPGZLxrWVSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instance_df.loc[instance_df[\"id\"] == 2030, \"name\"] = \"Ancient Pyramid\"\n",
        "instance_df.loc[instance_df[\"id\"] == 2031, \"name\"] = \"Ancient Pyramid (Hard)\"\n",
        "\n",
        "instance_df.loc[instance_df[\"id\"] == 2040, \"name\"] = \"Lost Temple\"\n",
        "instance_df.loc[instance_df[\"id\"] == 2041, \"name\"] = \"Lost Temple (Hard)\""
      ],
      "metadata": {
        "id": "q9buXky0cvBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data manipulation"
      ],
      "metadata": {
        "id": "oUgS9Fo2WfrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_instance_name(row):\n",
        "  if row[\"id\"] % 10 == 0:\n",
        "    instance_id = row[\"id\"]\n",
        "    instance_name = f\"{instance_df.query(f'id == {instance_id}')['name'].values[0]} (Normal)\"\n",
        "    return instance_name\n",
        "  elif row[\"id\"] % 10 == 1:\n",
        "    instance_id = row[\"id\"] - 1\n",
        "    instance_name = f\"{instance_df.query(f'id == {instance_id}')['name'].values[0]} (Hard)\"\n",
        "    return instance_name\n",
        "  elif row[\"id\"] % 10 == 2:\n",
        "    instance_id = row[\"id\"] - 2\n",
        "    instance_name = f\"{instance_df.query(f'id == {instance_id}')['name'].values[0]} (Nightmare)\"\n",
        "    return instance_name\n",
        "\n",
        "instance_df[\"name\"] = instance_df.apply(generate_instance_name, axis=1)"
      ],
      "metadata": {
        "id": "Fpou3MIOWAU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instance Group"
      ],
      "metadata": {
        "id": "A3bB1UAe2DSe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "D4vLLcCF6rI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_InstanceGroup_InstanceGroup.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for text in filename.readlines():\n",
        "    texts.append(text.strip())\n",
        "\n",
        "texts = \" \".join(texts)\n",
        "\n",
        "texts = re.sub(r'\\[([\\w\\\"]+)\\] =', '\\g<1>:', texts)\n",
        "texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\{([\\d\\, ]+)\\}', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "# print(texts)\n",
        "\n",
        "texts = texts.replace(\"{ {\", \"AAAAA\")\n",
        "texts = texts.replace(\"}, }, },\", \"BBBBB\")\n",
        "texts = texts.replace(\"}, }, {\", \"DDDDD\")\n",
        "texts = re.sub(r'\\}, \\}, (\\d)', 'FFFFF \\g<1>', texts)\n",
        "texts = re.sub(r'\\}, \\},$', 'EEEEE', texts)\n",
        "texts = texts.replace(\"}, },\", \"CCCCC\")\n",
        "\n",
        "texts = texts.replace(\"AAAAA\", \"[ {\")\n",
        "texts = texts.replace(\"BBBBB\", \"}, }, ],\")\n",
        "texts = texts.replace(\"CCCCC\", \"}, ],\")\n",
        "texts = texts.replace(\"DDDDD\", \"}, }, {\")\n",
        "texts = texts.replace(\"EEEEE\", \"}, },\")\n",
        "texts = texts.replace(\"FFFFF\", \"}, }, \")\n",
        "\n",
        "texts = \"{\" + texts + \"}\"\n",
        "\n",
        "instance_groups = literal_eval(texts)"
      ],
      "metadata": {
        "id": "wrVgqw5iaMpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "uoG7v_C87CKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instance_group_entries = []\n",
        "\n",
        "for id, parsed_dict in instance_groups.items():\n",
        "  instance_group_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"id\": \"id\",\n",
        "      \"active_condition\": \"activeCondition\",\n",
        "      \"boss_id\": 'bossId',\n",
        "      \"boss_skill_id\": 'bossSkillid',\n",
        "      \"crystal_res_id\": 'crystalResId',\n",
        "      \"hero_boss_id\": 'heroBossId',\n",
        "      \"hero_id\": 'heroId',\n",
        "      \"instance_description\": 'instanceDescription',\n",
        "      \"name\": 'name',\n",
        "      \"normal_id\": 'normalId',\n",
        "      \"normal_res_id\": 'normalResId',\n",
        "      \"normal_target\": 'normalTarget',\n",
        "      \"purgatorial_scene_id\": 'purgatorialSceneId',\n",
        "      \"purgatorial_unlock_lv\": 'purgatorialUnlockLv'\n",
        "  }\n",
        "\n",
        "  instance_group_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      instance_group_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  instance_group_entries.append(instance_group_entry)\n",
        "\n",
        "instance_group_df = pd.DataFrame(instance_group_entries)"
      ],
      "metadata": {
        "id": "m2SbgxbEaVsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data filtration"
      ],
      "metadata": {
        "id": "c-UtTvg_7gm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instance_group_df[\"id\"] = instance_group_df[\"id\"].astype(int)\n",
        "instance_group_df = instance_group_df.query(\"id <= 10\")"
      ],
      "metadata": {
        "id": "GxBx4wub7Iro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge with information from `en_langs`"
      ],
      "metadata": {
        "id": "bf8PzyeW8Mpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instance description"
      ],
      "metadata": {
        "id": "ZwnJ9pYU81YL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instance_description_df = pd.DataFrame(parsed_data[\"instance_description\"])\n",
        "instance_description_df = instance_description_df.rename(columns={\"value\": \"description\"})\n",
        "instance_group_df[\"id\"] = instance_group_df[\"instance_description\"].apply(lambda x: int(x.replace(\"InstanceDescription\", \"\")))\n",
        "\n",
        "instance_description_df[\"id\"] = instance_description_df[\"id\"].apply(int)\n",
        "instance_group_df[\"id\"] = instance_group_df[\"id\"].apply(int)\n",
        "\n",
        "instance_group_df = pd.merge(instance_group_df, instance_description_df, how=\"left\", left_on=[\"id\"], right_on=[\"id\"])"
      ],
      "metadata": {
        "id": "5IfIZww57son"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data correction and manipulation"
      ],
      "metadata": {
        "id": "aAhv-pU-9Ayd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instance_group_df = instance_group_df[[\"normal_id\", \"description\", \"boss_id\", \"boss_skill_id\", \"crystal_res_id\"]].rename(columns={\"normal_id\": \"code\"})\n",
        "\n",
        "instance_df[\"code\"] = instance_df[\"id\"].apply(lambda x : round(x, -1))"
      ],
      "metadata": {
        "id": "H9ZHshXs89-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instance_df = pd.merge(instance_df, instance_group_df, how=\"left\", left_on=[\"code\"], right_on=[\"code\"])\n",
        "\n",
        "def get_difficulty(x):\n",
        "  if x % 10 == 0:\n",
        "    return \"normal\"\n",
        "  elif x % 10 == 1:\n",
        "    return \"hard\"\n",
        "  elif x % 10 == 2:\n",
        "    return \"nightmare\"\n",
        "\n",
        "instance_df[\"difficulty\"] = instance_df[\"id\"].apply(get_difficulty)\n",
        "instance_df = instance_df[[\"id\", \"name\", \"description\", \"boss_id\", \"crystal_res_id\", \"difficulty\"]]\n",
        "instance_df[\"name\"] = instance_df[\"name\"].str.lower()\n",
        "\n",
        "lost_temple_desc = instance_description_df.loc[instance_description_df[\"id\"] == 3, \"description\"].values[0]\n",
        "ancient_pyramid_desc = instance_description_df.loc[instance_description_df[\"id\"] == 5, \"description\"].values[0]\n",
        "\n",
        "instance_df.loc[instance_df[\"id\"].isin([2030, 2031, 2032]), \"description\"] = ancient_pyramid_desc\n",
        "instance_df.loc[instance_df[\"id\"].isin([2040, 2041, 2042]), \"description\"] = lost_temple_desc\n",
        "\n",
        "instance_df.loc[instance_df[\"id\"].isin([2030, 2031, 2032]), \"boss_id\"] = 30013\n",
        "instance_df.loc[instance_df[\"id\"].isin([2040, 2041, 2042]), \"boss_id\"] = 30005"
      ],
      "metadata": {
        "id": "roQUZmKiVnap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "L8y3PWB1jLnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instance_df.to_csv(f\"{MAIN_PARSED_DIR}/instance_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "Gm2_oduWb44q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Refine"
      ],
      "metadata": {
        "id": "O3Ujeei0hd0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "Yd26Q6zjhfjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_equip_Refine.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for text in filename.readlines():\n",
        "    texts.append(text.strip())\n",
        "    \n",
        "texts = \" \".join(texts)\n",
        "texts = re.sub(r'\\[([\\w\\\"]+)\\]=', '\\g<1>:', texts)\n",
        "texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "texts = texts.replace(\"{}\", \"[]\")\n",
        "\n",
        "texts = texts.replace(\"} } }\", \"X X X X\")\n",
        "texts = texts.replace(\"} }, {\", \"A A A A\")\n",
        "\n",
        "texts = texts.replace(\"{ {\", \"[ {\")\n",
        "texts = texts.replace(\"} }\", \"} ]\")\n",
        "texts = texts.replace(\"X X X X\", \"} } ]\")\n",
        "texts = texts.replace(\"A A A A\", \"} }, {\")\n",
        "\n",
        "texts = \"{\" + texts + \"}\"\n",
        "\n",
        "\n",
        "refines = literal_eval(texts)"
      ],
      "metadata": {
        "id": "tIxxmv5-bPOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "JstvUkhsh-Kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "refine_entries = []\n",
        "\n",
        "for id, parsed_dict in refines.items():\n",
        "  refine_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"id\": \"id\",\n",
        "      \"inherit_zeny\": \"InheritZeny\",\n",
        "      \"break_refine\": 'break_refine',\n",
        "      \"break_num\": 'break_num',\n",
        "      \"break_rate\": 'break_rate',\n",
        "      'downgrade_lv': 'downgrade_lv',\n",
        "      'downgrade_rate': 'downgrade_rate',\n",
        "      'extraupgrade_rate': 'extraupgrade_rate',\n",
        "      'leavebreak_rate': 'leavebreak_rate',\n",
        "      'leavedowngrade_rate': 'leavedowngrade_rate',\n",
        "      'leaveupgrade_rate': 'leaveupgrade_rate',\n",
        "      'need_luck': 'need_luck',\n",
        "      'need_zeny': 'need_zeny',\n",
        "      'normal_material': 'normal_material',\n",
        "      'normal_num':'normal_num',\n",
        "      'property_id':'propertyId',\n",
        "      'property_percent': 'propertyPercent',\n",
        "      'quality': 'quality',\n",
        "      'refine_id': 'refineId',\n",
        "      'refine_lv': 'refine_lv',\n",
        "      'return_luck': 'return_luck',\n",
        "      'return_material': 'return_material',\n",
        "      'return_num': 'return_num',\n",
        "      'special_material': 'special_material',\n",
        "      'special_num': 'special_num',\n",
        "      'upgrade_rate': 'upgrade_rate'\n",
        "  }\n",
        "\n",
        "\n",
        "  refine_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      refine_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  refine_entries.append(refine_entry)\n",
        "\n",
        "refine_df = pd.DataFrame(refine_entries)"
      ],
      "metadata": {
        "id": "m80FJc-4bXbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data manipulation"
      ],
      "metadata": {
        "id": "pjNjFqQDif61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "refine_df[\"quality\"] = refine_df[\"quality\"].fillna(1)\n",
        "\n",
        "equip_refine_df = equip_df[[\"id\", \"refine_id\"]].copy().rename(columns={\"id\": \"equip_id\"})\n",
        "equip_refine_df = equip_refine_df[~equip_refine_df[\"refine_id\"].isnull()]\n",
        "refine_fin_df = refine_df[[\"id\", \"inherit_zeny\", \"need_zeny\", \"normal_material\", \"normal_num\", \"property_id\", \"property_percent\", \"refine_lv\", \"break_rate\", \"refine_id\", \"downgrade_rate\", \"upgrade_rate\", \"special_material\", \"special_num\", \"quality\"]]\n",
        "# refine_fin_df = refine_fin_df[~refine_fin_df[\"property_id\"].isnull()]\n",
        "\n",
        "isnull = refine_fin_df[\"property_id\"].isnull()\n",
        "refine_fin_df.loc[isnull, 'property_id'] = pd.Series([[49, 17]] * isnull.sum()).values\n",
        "\n",
        "refine_fin_df['normal_num'] = refine_fin_df['normal_num'].fillna(\"8\").apply(list).str[0]\n",
        "\n",
        "for col in [\"property_percent\", \"refine_lv\", \"break_rate\", \"downgrade_rate\", \"special_material\", \"special_num\"]:\n",
        "  refine_fin_df[col] = refine_fin_df[col].fillna(0)\n",
        "\n",
        "refine_fin_df[\"normal_material\"] = refine_fin_df[\"normal_material\"].fillna(\"\").apply(list).str[0]\n",
        "\n",
        "refine_fin_df[\"property_percent\"] = refine_fin_df.apply(lambda x: [0] * len(x[\"property_id\"]) if x[\"property_percent\"] == 0 else list(x[\"property_percent\"]), axis=1)\n",
        "refine_fin_df = refine_fin_df[~refine_fin_df[\"refine_id\"].isnull()]"
      ],
      "metadata": {
        "id": "-Q-Zrahkh9Vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge with Item"
      ],
      "metadata": {
        "id": "gt7mqb89jEpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_refine_fin_df = refine_fin_df[[\"id\", \"refine_id\", \"inherit_zeny\", \"need_zeny\", \"normal_material\", \"normal_num\", \"break_rate\", \"upgrade_rate\", \"downgrade_rate\", \"refine_lv\", \"special_material\", \"special_num\", \"quality\"]]\n",
        "\n",
        "item_name_df[\"id\"] = item_name_df[\"id\"].apply(int)\n",
        "\n",
        "equip_refine_fin_df = pd.merge(equip_refine_fin_df, item_name_df.rename(columns={\"id\": \"normal_material\", \"value\": \"normal_item\"}), how=\"left\", left_on=[\"normal_material\"], right_on=[\"normal_material\"])\n",
        "equip_refine_fin_df = pd.merge(equip_refine_fin_df, item_name_df.rename(columns={\"id\": \"special_material\", \"value\": \"special_item\"}), how=\"left\", left_on=[\"special_material\"], right_on=[\"special_material\"])\n",
        "equip_refine_fin_df = equip_refine_fin_df.drop([\"normal_material\", \"special_material\"], axis=1)\n",
        "equip_refine_fin_df = equip_refine_fin_df.rename(columns={\"item_name_x\": \"normal_item\", \"item_name_y\": \"special_item\"})"
      ],
      "metadata": {
        "id": "HRqkNncsjGkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "JDSwy0lZjdAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_refine_fin_df.to_csv(f\"{MAIN_PARSED_DIR}/equip_refine_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "G1BLBvQyihW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Refine Attributes"
      ],
      "metadata": {
        "id": "w1RxxYJWjnGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data from Refine"
      ],
      "metadata": {
        "id": "k392FVRpjpHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "refine_fin_entries = refine_fin_df[[\"refine_id\", \"property_id\", \"property_percent\", \"refine_lv\", \"quality\"]].to_dict(orient=\"records\")"
      ],
      "metadata": {
        "id": "VAkjSNg4jmks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "4Az7PKTrj4bU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "refine_attr_entries = []\n",
        "\n",
        "for refine_fin_entry in refine_fin_entries:\n",
        "  for i in range(len(refine_fin_entry[\"property_id\"])):\n",
        "    refine_attr_entry = {}\n",
        "    refine_attr_entry[\"refine_id\"] = refine_fin_entry[\"refine_id\"]\n",
        "\n",
        "    refine_attr_entry[\"property_id\"] = refine_fin_entry[\"property_id\"][i]\n",
        "    try:\n",
        "      refine_attr_entry[\"property_percent\"] = refine_fin_entry[\"property_percent\"][i]\n",
        "    except:\n",
        "      refine_attr_entry[\"property_percent\"] = refine_fin_entry[\"property_percent\"][0]\n",
        "\n",
        "    refine_attr_entry[\"refine_lv\"] = refine_fin_entry[\"refine_lv\"]\n",
        "    refine_attr_entry[\"quality\"] = refine_fin_entry[\"quality\"]\n",
        "\n",
        "    refine_attr_entries.append(refine_attr_entry)\n",
        "\n",
        "equip_refine_attr_df = pd.DataFrame(refine_attr_entries)"
      ],
      "metadata": {
        "id": "QbBi6M5Kj3wN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data manipulation"
      ],
      "metadata": {
        "id": "91mPAjaxj9t9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equipment_attr_desc_df = pd.DataFrame(parsed_data[\"property\"])"
      ],
      "metadata": {
        "id": "k3xe7unM28yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equip_refine_attr_df[\"id\"] = pd.Series(range(0, equip_refine_attr_df.shape[0]))\n",
        "equipment_attr_desc_df[\"id\"] = equipment_attr_desc_df[\"id\"].apply(int)\n",
        "\n",
        "equip_refine_attr_df = pd.merge(equip_refine_attr_df, equipment_attr_desc_df.rename(columns={\"id\": \"property_id\", \"value\": \"property\"}), how=\"left\")\n",
        "\n",
        "equip_refine_attr_df = equip_refine_attr_df.drop([\"property_id\"], axis=1)"
      ],
      "metadata": {
        "id": "lWF2MN8Cj9AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "dDFYrpOAkH64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_refine_attr_df.to_csv(f\"{MAIN_PARSED_DIR}/equip_refine_attributes_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "JDBIj0sWkHMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ghJeaVo9a2eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Item Split"
      ],
      "metadata": {
        "id": "t9mFCcUGozcI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "UND0AbFNpJpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_equip_ItemSplit.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for text in filename.readlines():\n",
        "    texts.append(text.strip())\n",
        "    \n",
        "texts = \" \".join(texts)\n",
        "\n",
        "texts = re.sub(r'\\[([\\w\\\"]+)\\] =', '\\g<1>:', texts)\n",
        "texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\{([\\d\\, ]+)\\}', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "# print(texts)\n",
        "\n",
        "texts = texts.replace(\"{ {\", \"AAAAA\")\n",
        "texts = texts.replace(\"}, }, },\", \"BBBBB\")\n",
        "texts = texts.replace(\"}, }, {\", \"DDDDD\")\n",
        "texts = re.sub(r'\\}, \\}, (\\d)', 'FFFFF \\g<1>', texts)\n",
        "texts = re.sub(r'\\}, \\},$', 'EEEEE', texts)\n",
        "texts = texts.replace(\"}, },\", \"CCCCC\")\n",
        "\n",
        "texts = texts.replace(\"AAAAA\", \"[ {\")\n",
        "texts = texts.replace(\"BBBBB\", \"}, }, ],\")\n",
        "texts = texts.replace(\"CCCCC\", \"}, ],\")\n",
        "texts = texts.replace(\"DDDDD\", \"}, }, {\")\n",
        "texts = texts.replace(\"EEEEE\", \"}, },\")\n",
        "texts = texts.replace(\"FFFFF\", \"}, }, \")\n",
        "\n",
        "texts = \"{\" + texts + \"}\"\n",
        "\n",
        "\n",
        "dismantles = literal_eval(texts)"
      ],
      "metadata": {
        "id": "MuraB8Eqefts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "r-j5pYqupkAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dismantle_entries = []\n",
        "\n",
        "for id, parsed_dict in dismantles.items():\n",
        "  dismantle_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"id\": \"id\",\n",
        "      \"item_id\": \"item_id\",\n",
        "      \"lower_item\": 'lower_item',\n",
        "      \"need_num\": 'need_num'\n",
        "  }\n",
        "\n",
        "  dismantle_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      dismantle_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  dismantle_entries.append(dismantle_entry)\n",
        "\n",
        "dismantle_df = pd.DataFrame(dismantle_entries)"
      ],
      "metadata": {
        "id": "kvsK4-qcer1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data manipulation"
      ],
      "metadata": {
        "id": "WzqjUmT-qNI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dismantle_df[\"need_num\"] = dismantle_df[\"need_num\"].apply(lambda d: d if isinstance(d, list) else [2])\n",
        "dismantle_df[\"lower_item\"] = dismantle_df[\"lower_item\"].apply(lambda d: d if isinstance(d, list) else [1016])\n",
        "\n",
        "dismantle_df[\"item_id\"] = dismantle_df[\"item_id\"].fillna(dismantle_df[\"id\"])\n",
        "\n",
        "for col in [\"need_num\", \"lower_item\"]:\n",
        "  dismantle_df[col] = dismantle_df[col].apply(lambda x: x[0])\n",
        "\n",
        "dismantle_df = dismantle_df.rename(columns={\n",
        "    \"need_num\": \"dismantle_num\",\n",
        "    \"item_id\" : \"material_id\",\n",
        "    \"lower_item\": \"dismantle_id\"\n",
        "})"
      ],
      "metadata": {
        "id": "lkwVNZL-pQEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "izI4DOngrVq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intersections = set(dismantle_df[\"material_id\"].astype(float)).intersection(set(material_final_df[\"id\"].astype(float)))\n",
        "dismantle_df = dismantle_df[dismantle_df[\"material_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "intersections = set(dismantle_df[\"dismantle_id\"].astype(float)).intersection(set(material_final_df[\"id\"].astype(float)))\n",
        "dismantle_df = dismantle_df[dismantle_df[\"dismantle_id\"].astype(float).isin(intersections)]"
      ],
      "metadata": {
        "id": "V2zU9iFXpLdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dismantle_df.to_csv(f\"{MAIN_PARSED_DIR}/material_dismantle_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "wLXta0mSsLXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lCpn-rc7bh2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Item Combine"
      ],
      "metadata": {
        "id": "FtFgkrLKrtIV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "QMPeqFbAr1ZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_equip_ItemCombine.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for text in filename.readlines():\n",
        "    texts.append(text.strip())\n",
        "    \n",
        "texts = \" \".join(texts)\n",
        "\n",
        "texts = re.sub(r'\\[([\\w\\\"]+)\\] =', '\\g<1>:', texts)\n",
        "texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\{([\\d\\, ]+)\\}', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "# print(texts)\n",
        "\n",
        "texts = texts.replace(\"{ {\", \"AAAAA\")\n",
        "texts = texts.replace(\"}, }, },\", \"BBBBB\")\n",
        "texts = texts.replace(\"}, }, {\", \"DDDDD\")\n",
        "texts = re.sub(r'\\}, \\}, (\\d)', 'FFFFF \\g<1>', texts)\n",
        "texts = re.sub(r'\\}, \\},$', 'EEEEE', texts)\n",
        "texts = texts.replace(\"}, },\", \"CCCCC\")\n",
        "\n",
        "texts = texts.replace(\"AAAAA\", \"[ {\")\n",
        "texts = texts.replace(\"BBBBB\", \"}, }, ],\")\n",
        "texts = texts.replace(\"CCCCC\", \"}, ],\")\n",
        "texts = texts.replace(\"DDDDD\", \"}, }, {\")\n",
        "texts = texts.replace(\"EEEEE\", \"}, },\")\n",
        "texts = texts.replace(\"FFFFF\", \"}, }, \")\n",
        "\n",
        "texts = \"{\" + texts + \"}\"\n",
        "\n",
        "\n",
        "item_combinations = literal_eval(texts)"
      ],
      "metadata": {
        "id": "LHoscrXMe_qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "MDkHhX5ysLrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "item_combination_entries = []\n",
        "\n",
        "for id, parsed_dict in item_combinations.items():\n",
        "  item_combination_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"id\": \"Id\",\n",
        "      \"if_combine\": \"if_combine\",\n",
        "      \"lower_item\": 'lower_item',\n",
        "      \"need_num\": 'need_num',\n",
        "      'condition': \"condition\",\n",
        "      \"add_luck\": \"add_luck\",\n",
        "  }\n",
        "\n",
        "  item_combination_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      item_combination_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  item_combination_entries.append(item_combination_entry)\n",
        "\n",
        "item_combination_df = pd.DataFrame(item_combination_entries)"
      ],
      "metadata": {
        "id": "F0t6KwKqfIs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data manipulation"
      ],
      "metadata": {
        "id": "7qq0yxvhsfiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "item_combination_df = item_combination_df[~item_combination_df[\"lower_item\"].isnull()]\n",
        "item_combination_df = item_combination_df[~item_combination_df[\"need_num\"].isnull()]\n",
        "item_combination_entries = item_combination_df[[\"id\", \"lower_item\", \"need_num\"]].to_dict(orient=\"records\")\n",
        "\n",
        "item_combination_entries[0]\n",
        "\n",
        "item_combination_final_entries = []\n",
        "\n",
        "for item_combination_entry in item_combination_entries:\n",
        "  for i, req_item_id in enumerate(item_combination_entry[\"lower_item\"]):\n",
        "    item_combination_final_entry = {}\n",
        "    item_combination_final_entry[\"item_id\"] = item_combination_entry[\"id\"]\n",
        "    item_combination_final_entry[\"req_item_id\"] = req_item_id\n",
        "    item_combination_final_entry[\"item_num\"] = item_combination_entry[\"need_num\"][i]\n",
        "\n",
        "    item_combination_final_entries.append(item_combination_final_entry)\n",
        "\n",
        "item_combination_df = pd.DataFrame(item_combination_final_entries)"
      ],
      "metadata": {
        "id": "cJxhPzSPsOvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_combination_df = item_combination_df.reset_index().rename(columns={\"index\": \"id\"})\n",
        "\n",
        "intersections = set(item_combination_df[\"item_id\"].astype(float)).intersection(set(item_final_df[\"id\"].astype(float)))\n",
        "item_combination_df = item_combination_df[item_combination_df[\"item_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "intersections = set(item_combination_df[\"req_item_id\"].astype(float)).intersection(set(item_final_df[\"id\"].astype(float)))\n",
        "item_combination_df = item_combination_df[item_combination_df[\"req_item_id\"].astype(float).isin(intersections)]"
      ],
      "metadata": {
        "id": "hC9tN7sWphkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_combination_df.to_csv(f\"{MAIN_PARSED_DIR}/item_combination_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "c_Exr5VqshdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c8lRnHpWcBXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Card"
      ],
      "metadata": {
        "id": "r-etOMfNt8Hm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data from Item"
      ],
      "metadata": {
        "id": "4pxLw3PxuPPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "card_info_df = item_df[~item_df[\"item_name\"].isnull()]\n",
        "card_info_df = card_info_df[((card_info_df[\"item_name\"].str.contains(\"Card\")) & (~card_info_df[\"item_name\"].str.contains(\"Fragment\")) & (~card_info_df[\"item_type_en\"].isnull()) | (card_info_df[\"item_name\"].str.contains(\"卡片\")))]\n",
        "\n",
        "card_main_df = card_info_df[[\"id\", \"card_coordinate_point\", \"is_mvp_card\", \"unlock_adventure_exp\", \"card_quality\", \"monster\"]]\n",
        "card_main_df = card_main_df[~card_main_df[\"card_coordinate_point\"].isnull()]"
      ],
      "metadata": {
        "id": "DpW4n58Qsxf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "s8C4JWwCxfvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "card_main_df = card_main_df[~card_main_df[\"monster\"].isnull()]\n",
        "card_main_df[\"monster\"] = card_main_df[\"monster\"].apply(lambda x: next(iter(x)))\n",
        "\n",
        "card_df = card_main_df.rename(columns={\"monster\": \"creature_id\"})\n",
        "intersections = set(card_df[\"creature_id\"].astype(float)).intersection(set(creature_df[\"id\"].astype(float)))\n",
        "card_df = card_df[card_df[\"creature_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "intersections = set(card_df[\"id\"].astype(float)).intersection(set(item_final_df[\"id\"].astype(float)))\n",
        "card_df = card_df[card_df[\"id\"].astype(float).isin(intersections)]\n",
        "\n",
        "card_df.to_csv(f\"{MAIN_PARSED_DIR}/card_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "lahiM8pjqRvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Card Attributes"
      ],
      "metadata": {
        "id": "8JoEPiAYx-dr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data from Card"
      ],
      "metadata": {
        "id": "vHJBH3ssyAW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "card_attr_entries = card_info_df[[\"id\", \"card_attrs\"]].to_dict(orient=\"records\")"
      ],
      "metadata": {
        "id": "wcjQ3_yqxoU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "12y-o-SIyXjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "card_attr_final_entries = []\n",
        "\n",
        "for card_attr_entry in card_attr_entries:\n",
        "  try:\n",
        "    for card_attr in card_attr_entry[\"card_attrs\"]:\n",
        "      card_attr_final_entry = {}\n",
        "      card_attr_final_entry[\"id\"] = card_attr_entry[\"id\"]\n",
        "      card_attr_final_entry[\"attr_desc\"] = card_attr[\"attrDesc\"]\n",
        "\n",
        "      card_attr_final_entries.append(card_attr_final_entry)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "card_attr_df = pd.DataFrame(card_attr_final_entries)"
      ],
      "metadata": {
        "id": "XZqIlbqCyDtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge with information from `en_langs`"
      ],
      "metadata": {
        "id": "DA742WRL3OVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Attribute Description"
      ],
      "metadata": {
        "id": "D7-P8-Vp3eTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "card_attr_desc_df = pd.DataFrame(parsed_data[\"card_attr_desc\"])\n",
        "card_attr_desc_df[\"id\"] = card_attr_desc_df[\"id\"].apply(lambda x: f\"CardAttributeDescription_{x}\")\n",
        "card_attr_desc_df = card_attr_desc_df.rename(columns={\"id\": \"attr_desc\"})\n",
        "\n",
        "card_fin_df = pd.merge(card_attr_df, card_attr_desc_df, how=\"left\", left_on=[\"attr_desc\"], right_on=[\"attr_desc\"])\n",
        "card_fin_df = card_fin_df.drop(\"attr_desc\", axis=1).rename(columns={\"value\": \"attribute\"})"
      ],
      "metadata": {
        "id": "2_fETroRycCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "lvJ3yLVP3nFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "card_fin_df = card_fin_df.rename(columns={\n",
        "  \"id\": \"card_id\",    \n",
        "})\n",
        "\n",
        "card_fin_df = card_fin_df.reset_index(drop=True)\n",
        "card_fin_df[\"id\"] = pd.Series(range(0,card_fin_df.shape[0]))\n",
        "\n",
        "card_fin_df = card_fin_df[~card_fin_df[\"attribute\"].isnull()]\n",
        "intersections = set(card_fin_df[\"card_id\"].astype(float)).intersection(set(card_df[\"id\"].astype(float)))\n",
        "card_fin_df = card_fin_df[card_fin_df[\"card_id\"].astype(float).isin(intersections)]"
      ],
      "metadata": {
        "id": "ku48PsaE3gcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "card_fin_df.to_csv(f\"{MAIN_PARSED_DIR}/card_attributes_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "dC7jhb4Ns6Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "385AqUn2c5Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Card Awakening"
      ],
      "metadata": {
        "id": "L3Z2MALI3wdX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "oCCyxSDi3zKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_item_CardCoordinates.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for text in filename.readlines():\n",
        "    texts.append(text.strip())\n",
        "    \n",
        "texts = \" \".join(texts)\n",
        "\n",
        "texts = re.sub(r'\\[([\\w\\\"]+)\\] =', '\\g<1>:', texts)\n",
        "texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\{([\\d\\, ]+)\\}', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "# print(texts)\n",
        "\n",
        "texts = texts.replace(\"{ {\", \"AAAAA\")\n",
        "texts = texts.replace(\"}, }, },\", \"BBBBB\")\n",
        "texts = texts.replace(\"}, }, {\", \"DDDDD\")\n",
        "texts = re.sub(r'\\}, \\}, (\\d)', 'FFFFF \\g<1>', texts)\n",
        "texts = re.sub(r'\\}, \\},$', 'EEEEE', texts)\n",
        "texts = texts.replace(\"}, },\", \"CCCCC\")\n",
        "\n",
        "texts = texts.replace(\"AAAAA\", \"[ {\")\n",
        "texts = texts.replace(\"BBBBB\", \"}, }, ],\")\n",
        "texts = texts.replace(\"CCCCC\", \"}, ],\")\n",
        "texts = texts.replace(\"DDDDD\", \"}, }, {\")\n",
        "texts = texts.replace(\"EEEEE\", \"}, },\")\n",
        "texts = texts.replace(\"FFFFF\", \"}, }, \")\n",
        "\n",
        "texts = \"{\" + texts + \"}\"\n",
        "\n",
        "card_coordinates = literal_eval(texts)"
      ],
      "metadata": {
        "id": "PbJ8GiJf3t7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "WXqMwBC14BM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "card_coordinate_entries = []\n",
        "\n",
        "for id, parsed_dict in card_coordinates.items():\n",
        "  card_coordinate_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"name\": \"name\",\n",
        "      \"attr_id\": \"attrId\",\n",
        "      \"card\": 'card',\n",
        "      \"icon\": 'icon',\n",
        "      'staticId': \"static_id\",\n",
        "      \"type\": \"type\",\n",
        "  }\n",
        "\n",
        "  card_coordinate_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      card_coordinate_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  card_coordinate_entries.append(card_coordinate_entry)\n",
        "\n",
        "card_coordinates_df = pd.DataFrame(card_coordinate_entries)"
      ],
      "metadata": {
        "id": "OHDFZoxF3-3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split entries to granularize"
      ],
      "metadata": {
        "id": "wbhXcvOf4XnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "card_coordinate_entries = card_coordinates_df[[\"id\", \"name\", \"card\", \"icon\"]].to_dict(orient=\"records\")\n",
        "\n",
        "card_coordinate_final_entries = []\n",
        "\n",
        "for card_coordinate_entry in card_coordinate_entries:\n",
        "  for card in card_coordinate_entry[\"card\"]:\n",
        "    card_coordinate_final_entry = {}\n",
        "    card_coordinate_final_entry[\"name\"] = card_coordinate_entry[\"name\"]\n",
        "    card_coordinate_final_entry[\"card\"] = card\n",
        "    card_coordinate_final_entry[\"icon\"] = card_coordinate_entry[\"icon\"]\n",
        "\n",
        "    card_coordinate_final_entries.append(card_coordinate_final_entry)\n",
        "\n",
        "card_coordinates_df = pd.DataFrame(card_coordinate_final_entries)"
      ],
      "metadata": {
        "id": "blslqfB54TVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge with `en_langs`"
      ],
      "metadata": {
        "id": "HFHrWjUqNjBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "card_coordinate_names_df = pd.DataFrame(parsed_data[\"card_coordinates\"]).rename(columns={\"value\": \"name\"})\n",
        "card_coordinate_names_df[\"id\"] = card_coordinate_names_df[\"id\"].apply(int)\n",
        "card_coordinates_df = card_coordinates_df[card_coordinates_df[\"name\"].str.contains(\"CardCoordinates\")]\n",
        "card_coordinates_df[\"name\"] = card_coordinates_df[\"name\"].str.replace(\"CardCoordinates_\", \"\").apply(int)\n",
        "card_coordinates_df = card_coordinates_df.rename(columns={\"name\": \"id\"})\n",
        "card_coordinates_df = pd.merge(card_coordinates_df, card_coordinate_names_df, how=\"left\").drop(\"id\", axis=1)"
      ],
      "metadata": {
        "id": "K6_mBFcSNakm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "AWk9DayQ5FmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "card_coordinates_df = card_coordinates_df.reset_index(drop=True)\n",
        "card_coordinates_df[\"id\"] = pd.Series(range(0, card_coordinates_df.shape[0]))\n",
        "\n",
        "card_coordinates_df = card_coordinates_df.rename(columns={\n",
        "    \"card\": \"card_id\",\n",
        "    \"name\": \"category\",\n",
        "})\n",
        "\n",
        "intersections = set(card_coordinates_df[\"card_id\"].astype(float)).intersection(set(card_df[\"id\"].astype(float)))\n",
        "card_coordinates_df = card_coordinates_df[card_coordinates_df[\"card_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "card_coordinates_df.to_csv(f\"{MAIN_PARSED_DIR}/card_awakening_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "AAxiH3AD45F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qib4Jqogd0T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Equipment Formula"
      ],
      "metadata": {
        "id": "kCxJ4vUuf3aI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "OOnr0nBEf_40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_equip_EquipmentFormula.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for text in filename.readlines():\n",
        "    texts.append(text.strip())\n",
        "    \n",
        "texts = \" \".join(texts)\n",
        "\n",
        "texts = re.sub(r'\\[([\\w\\\"]+)\\] =', '\\g<1>:', texts)\n",
        "texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\{([\\d\\, ]+)\\}', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "# print(texts)\n",
        "\n",
        "texts = texts.replace(\"{ {\", \"AAAAA\")\n",
        "texts = texts.replace(\"}, }, },\", \"BBBBB\")\n",
        "texts = texts.replace(\"}, }, {\", \"DDDDD\")\n",
        "texts = re.sub(r'\\}, \\}, (\\d)', 'FFFFF \\g<1>', texts)\n",
        "texts = re.sub(r'\\}, \\},$', 'EEEEE', texts)\n",
        "texts = texts.replace(\"}, },\", \"CCCCC\")\n",
        "\n",
        "texts = texts.replace(\"AAAAA\", \"[ {\")\n",
        "texts = texts.replace(\"BBBBB\", \"}, }, ],\")\n",
        "texts = texts.replace(\"CCCCC\", \"}, ],\")\n",
        "texts = texts.replace(\"DDDDD\", \"}, }, {\")\n",
        "texts = texts.replace(\"EEEEE\", \"}, },\")\n",
        "texts = texts.replace(\"FFFFF\", \"}, }, \")\n",
        "\n",
        "texts = \"{\" + texts + \"}\"\n",
        "\n",
        "equipment_formulas = literal_eval(texts)"
      ],
      "metadata": {
        "id": "9mocZOsHf5aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "e7lrmPN8gWCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equipment_formula_entries = []\n",
        "\n",
        "for id, parsed_dict in equipment_formulas.items():\n",
        "  equipment_formula_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"id\": \"id\",\n",
        "      \"curreny_value\": \"currencyValue\",\n",
        "      \"dynamic_npc_id\": \"dynamicNpcId\",\n",
        "      \"equip_type\": \"equipType\",\n",
        "      \"formula_type\": \"formulaType\",\n",
        "      \"material_id\": \"materialId\",\n",
        "      \"material_num\": \"materialNum\",\n",
        "      \"equip_id\": \"productionEquipId\",\n",
        "  }\n",
        "\n",
        "  equipment_formula_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      equipment_formula_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  equipment_formula_entries.append(equipment_formula_entry)\n",
        "\n",
        "equip_formula_df = pd.DataFrame(equipment_formula_entries)"
      ],
      "metadata": {
        "id": "JaaS2JIogK0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter data"
      ],
      "metadata": {
        "id": "JA5m_6o6gjaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_formula_df = equip_formula_df[~equip_formula_df[\"equip_id\"].isnull()]\n",
        "equip_formula_df = equip_formula_df[~equip_formula_df[\"material_num\"].isnull()]\n",
        "equip_formula_df = equip_formula_df[~equip_formula_df[\"material_id\"].isnull()]"
      ],
      "metadata": {
        "id": "PWRPkgGFgYn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Break entries down"
      ],
      "metadata": {
        "id": "moVKrMt4gwG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_formula_req_df = equip_formula_df[[\"id\", \"equip_id\", \"material_id\", \"material_num\"]]\n",
        "equip_formula_reqs = equip_formula_req_df.to_dict(orient=\"records\")\n",
        "\n",
        "equip_formula_req_news = []\n",
        "for equip_formula_req in equip_formula_reqs:\n",
        "  for i, material_id in enumerate(equip_formula_req[\"material_id\"]):\n",
        "    new_entry = {}\n",
        "    new_entry[\"equip_id\"] = equip_formula_req[\"equip_id\"]\n",
        "    new_entry[\"material_id\"] = material_id\n",
        "    new_entry[\"material_num\"] = equip_formula_req[\"material_num\"][i]\n",
        "  \n",
        "    equip_formula_req_news.append(new_entry)\n",
        "\n",
        "equip_formula_final_df = pd.DataFrame(equip_formula_req_news)\n",
        "equip_formula_zeny_df = equip_formula_df[[\"curreny_value\", \"equip_id\"]]\n",
        "equip_formula_zeny_df[\"material_id\"] = 1001\n",
        "equip_formula_zeny_df = equip_formula_zeny_df.rename(columns={\"curreny_value\": \"material_num\"})\n",
        "\n",
        "equip_formula_final_df = equip_formula_final_df.append(equip_formula_zeny_df, ignore_index=True)"
      ],
      "metadata": {
        "id": "gljgtL2igoRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "2HXE9z-EhG2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# equip_formula_final_df = equip_formula_final_df.rename(columns={\n",
        "#     \"material_id\": \"mat_id\",\n",
        "#     \"material_num\": \"mat_num\"\n",
        "# })\n",
        "\n",
        "equip_formula_final_df = equip_formula_final_df.reset_index(drop=True)\n",
        "equip_formula_final_df[\"id\"] = pd.Series(range(0, equip_formula_final_df.shape[0]))"
      ],
      "metadata": {
        "id": "23XG1vb0g3qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intersections = set(equip_formula_final_df[\"equip_id\"].astype(float)).intersection(set(equip_final_df[\"id\"].astype(float)))\n",
        "equip_formula_final_df = equip_formula_final_df[equip_formula_final_df[\"equip_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "intersections = set(equip_formula_final_df[\"material_id\"].astype(float)).intersection(set(material_final_df[\"id\"].astype(float)))\n",
        "equip_formula_final_df = equip_formula_final_df[equip_formula_final_df[\"material_id\"].astype(float).isin(intersections)]"
      ],
      "metadata": {
        "id": "f4lhFo04tne3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equip_formula_final_df.to_csv(f\"{MAIN_PARSED_DIR}/equip_craft_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "LxrnyLMGtmXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Equipment Decomposition"
      ],
      "metadata": {
        "id": "7WDRf8j6inhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "uJvgOuwWiqto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_equip_EquipmentDecomposition.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "# with open(f\"test.txt\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for text in filename.readlines():\n",
        "    texts.append(text.strip())\n",
        "    \n",
        "texts = \" \".join(texts)\n",
        "\n",
        "texts = re.sub(r'\\[([\\w\\\"]+)\\] =', '\\g<1>:', texts)\n",
        "texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\{([\\d\\, ]+)\\}', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "# print(texts)\n",
        "\n",
        "texts = texts.replace(\"{ {\", \"AAAAA\")\n",
        "texts = texts.replace(\"}, }, },\", \"BBBBB\")\n",
        "texts = texts.replace(\"}, }, {\", \"DDDDD\")\n",
        "texts = re.sub(r'\\}, \\}, (\\d)', 'FFFFF \\g<1>', texts)\n",
        "texts = re.sub(r'\\}, \\},$', 'EEEEE', texts)\n",
        "texts = texts.replace(\"}, },\", \"CCCCC\")\n",
        "\n",
        "texts = texts.replace(\"AAAAA\", \"[ {\")\n",
        "texts = texts.replace(\"BBBBB\", \"}, }, ],\")\n",
        "texts = texts.replace(\"CCCCC\", \"}, ],\")\n",
        "texts = texts.replace(\"DDDDD\", \"}, }, {\")\n",
        "texts = texts.replace(\"EEEEE\", \"}, },\")\n",
        "texts = texts.replace(\"FFFFF\", \"}, }, \")\n",
        "\n",
        "texts = \"{\" + texts + \"}\"\n",
        "\n",
        "equipment_decompositions = literal_eval(texts)"
      ],
      "metadata": {
        "id": "9ZJVBWVjhT8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "w6GuaCcTuDj8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_hFg-7fPeqW"
      },
      "outputs": [],
      "source": [
        "equipment_decomposition_entries = []\n",
        "\n",
        "for id, parsed_dict in equipment_decompositions.items():\n",
        "  equipment_decomposition_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"decomposition_id\": \"Id\",\n",
        "      \"material_id\": \"materialId\",\n",
        "      \"material_num\": \"materialNum\",\n",
        "  }\n",
        "\n",
        "  equipment_decomposition_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      equipment_decomposition_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  equipment_decomposition_entries.append(equipment_decomposition_entry)\n",
        "\n",
        "equip_decomposition_df = pd.DataFrame(equipment_decomposition_entries)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Break entries down"
      ],
      "metadata": {
        "id": "1JBl5zA5uq9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# equip_decomposition_df[\"material_num\"] = equip_decomposition_df[\"material_num\"].apply(list)"
      ],
      "metadata": {
        "id": "6B_Rxl51ip9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "equip_decomposition_df = equip_decomposition_df[(~equip_decomposition_df[\"decomposition_id\"].isnull()) & (~equip_decomposition_df[\"material_num\"].isnull())]\n",
        "equip_decomposition_df = equip_decomposition_df.reset_index(drop=True)\n",
        "\n",
        "isnull = equip_decomposition_df[\"material_id\"].isnull()\n",
        "equip_decomposition_df.loc[isnull, 'material_id'] = pd.Series([[]] * isnull.sum()).values\n",
        "\n",
        "equip_decomposition_df[\"material_id\"] = equip_decomposition_df[\"material_id\"].apply(lambda x: [10204044] if x == [] else x)\n",
        "equip_decomposition_req_df = equip_decomposition_df[[\"decomposition_id\", \"material_id\", \"material_num\"]]\n",
        "equip_decomposition_reqs = equip_decomposition_req_df.to_dict(orient=\"records\")\n",
        "\n",
        "equip_decomposition_req_news = []\n",
        "\n",
        "for equip_decomposition_req in equip_decomposition_reqs:\n",
        "  for i, material_id in enumerate(equip_decomposition_req[\"material_id\"]):\n",
        "    new_entry = {}\n",
        "    new_entry[\"decomposition_id\"] = equip_decomposition_req[\"decomposition_id\"]\n",
        "    new_entry[\"material_id\"] = material_id\n",
        "    new_entry[\"material_num\"] = equip_decomposition_req[\"material_num\"][i]\n",
        "  \n",
        "    equip_decomposition_req_news.append(new_entry)\n",
        "\n",
        "equip_decomposition_final_df = pd.DataFrame(equip_decomposition_req_news)"
      ],
      "metadata": {
        "id": "1D3LNJFWu5_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data for database"
      ],
      "metadata": {
        "id": "1SvKrwMdveil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "equip_decomposition_final_df = equip_decomposition_final_df.reset_index(drop=True)\n",
        "equip_decomposition_final_df[\"id\"] = pd.Series(range(0, equip_decomposition_final_df.shape[0]))\n",
        "\n",
        "intersections = set(equip_decomposition_final_df[\"decomposition_id\"].astype(float)).intersection(set(equip_final_df[\"decomposition_id\"].astype(float)))\n",
        "equip_decomposition_final_df = equip_decomposition_final_df[equip_decomposition_final_df[\"decomposition_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "intersections = set(equip_decomposition_final_df[\"material_id\"].astype(float)).intersection(set(material_final_df[\"id\"].astype(float)))\n",
        "equip_decomposition_final_df = equip_decomposition_final_df[equip_decomposition_final_df[\"material_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "equip_decomposition_final_df.to_csv(f\"{MAIN_PARSED_DIR}/equip_decomposition_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "jB3x4T43vfsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z0morZove8AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Life Skill Area"
      ],
      "metadata": {
        "id": "T22iug6e70XT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data from `en_langs`"
      ],
      "metadata": {
        "id": "MUNND7X372kq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "area_name_df = pd.DataFrame(parsed_data[\"area_name_new\"]).rename(columns={\"id\": \"id\", \"value\": \"name\"})"
      ],
      "metadata": {
        "id": "p5-kSv_N72D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "area_name_df.to_csv(f\"{MAIN_PARSED_DIR}/life_skill_area_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "OEJBYwV_8HQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Life Skill Area Drop"
      ],
      "metadata": {
        "id": "URkwZDeJDftL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "3ExbHxlrDjB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_lifeSkill_AreaDrop.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for text in filename.readlines():\n",
        "    texts.append(text.strip())\n",
        "    \n",
        "texts = \" \".join(texts)\n",
        "\n",
        "texts = re.sub(r'\\[([\\w\\\"]+)\\] =', '\\g<1>:', texts)\n",
        "texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\{([\\d\\, ]+)\\}', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "# print(texts)\n",
        "\n",
        "texts = texts.replace(\"{ {\", \"AAAAA\")\n",
        "texts = texts.replace(\"}, }, },\", \"BBBBB\")\n",
        "texts = texts.replace(\"}, }, {\", \"DDDDD\")\n",
        "texts = re.sub(r'\\}, \\}, (\\d)', 'FFFFF \\g<1>', texts)\n",
        "texts = re.sub(r'\\}, \\},$', 'EEEEE', texts)\n",
        "texts = texts.replace(\"}, },\", \"CCCCC\")\n",
        "\n",
        "texts = texts.replace(\"AAAAA\", \"[ {\")\n",
        "texts = texts.replace(\"BBBBB\", \"}, }, ],\")\n",
        "texts = texts.replace(\"CCCCC\", \"}, ],\")\n",
        "texts = texts.replace(\"DDDDD\", \"}, }, {\")\n",
        "texts = texts.replace(\"EEEEE\", \"}, },\")\n",
        "texts = texts.replace(\"FFFFF\", \"}, }, \")\n",
        "\n",
        "texts = \"{\" + texts + \"}\"\n",
        "\n",
        "life_skill_area_drops = literal_eval(texts)"
      ],
      "metadata": {
        "id": "75BIAOqBDhnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "bsZVChf9L-iA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "life_skill_area_drop_entries = []\n",
        "\n",
        "for id, parsed_dict in life_skill_area_drops.items():\n",
        "  life_skill_area_drop_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"area_name\": 'Areaname',\n",
        "      \"bait_drop_id\": 'BaitDropId',\n",
        "      \"bait_id\": \"BaitId\",\n",
        "      \"drop_id\": 'Dropid',\n",
        "      \"extra_drop\": 'ExtraDrop',\n",
        "      \"fish_energy\": 'FishEnergy',\n",
        "      \"fish_exp\": 'FishExp',\n",
        "      \"get_fish_cd\": 'GetFishCD',\n",
        "      \"level_extra_drop\": 'LevelExtraDrop',\n",
        "      \"life_level_limit\": 'LifeLevelLimit',\n",
        "      \"pick_cd\": 'PickCD',\n",
        "      \"pick_energy\": 'PickEnergy',\n",
        "      \"pick_exp\" : 'PickExp',\n",
        "      \"life_level\": 'LifeLevel',\n",
        "      \"mine_level_energy\": 'MineLevelEnergy',\n",
        "      \"get_mine_cd\": 'GetMineCD',\n",
        "      \"mine_level_limit\": 'MineLevelLimit',\n",
        "      \"mine_level_limit_drop_id\": 'MineLevelLimitDropId',\n",
        "      \"mine_tool\": 'MineTool',\n",
        "      \"get_mine_cd\": 'GetMineCD',\n",
        "      \"rich_mine\": 'RichMine',\n",
        "      \"rich_mine_energy\": 'RichMineEnergy',\n",
        "      \"rich_mine_num\": 'RichMineNum'\n",
        "  }\n",
        "\n",
        "  life_skill_area_drop_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      life_skill_area_drop_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  life_skill_area_drop_entries.append(life_skill_area_drop_entry)\n",
        "\n",
        "life_skill_area_drop_df = pd.DataFrame(life_skill_area_drop_entries)"
      ],
      "metadata": {
        "id": "XzkvCe2iL-iF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge with `en_langs` Area Name information"
      ],
      "metadata": {
        "id": "2B89ZrDnEE1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "area_name_df = area_name_df.rename(columns={\"id\": \"area_id\", \"name\": \"area_name\"})\n",
        "area_name_df[\"area_id\"] = area_name_df[\"area_id\"].apply(lambda x: f\"Areaname{x}\")\n",
        "\n",
        "life_skill_area_drop_df = life_skill_area_drop_df.rename(columns={\"area_name\": \"area_id\"})\n",
        "life_skill_area_drop_df = pd.merge(life_skill_area_drop_df, area_name_df, how=\"left\", left_on=[\"area_id\"], right_on=[\"area_id\"])"
      ],
      "metadata": {
        "id": "tmbJtMulEYl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fishing"
      ],
      "metadata": {
        "id": "r_CuMvbvKptV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data from Life Skill Area Drop"
      ],
      "metadata": {
        "id": "gRA72DjO-yP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fishing_df = life_skill_area_drop_df[~life_skill_area_drop_df[\"fish_energy\"].isnull()]"
      ],
      "metadata": {
        "id": "H-PhSvupGLyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fishing_df = fishing_df[[\"id\", \"area_id\", \"area_name\", \"bait_drop_id\",\t\"bait_id\",\t\"drop_id\",\t\"extra_drop\",\t\"fish_energy\",\t\"fish_exp\",\t\"get_fish_cd\",\t\"level_extra_drop\", \"life_level_limit\"]]"
      ],
      "metadata": {
        "id": "E2Q_LJbxPzou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "Wip-SOTKOPos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fishing_df = fishing_df[fishing_df[\"area_id\"].str.startswith(\"Areaname\")]"
      ],
      "metadata": {
        "id": "rhfCeVfTlSTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fishing_df[\"area_id\"] = fishing_df[\"area_id\"].str.replace(\"Areaname\", \"\").apply(int)\n",
        "fishing_df = fishing_df[~fishing_df[\"bait_id\"].isnull()]"
      ],
      "metadata": {
        "id": "yHxVs-WRZUvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fishing_infos = []\n",
        "for record in fishing_df.to_dict(orient=\"records\"):\n",
        "  for i, bait in enumerate(record[\"bait_id\"]):\n",
        "    for j, extra_drop in enumerate(record[\"extra_drop\"]):\n",
        "      fishing_info = {}\n",
        "      fishing_info[\"id\"] = record[\"id\"]\n",
        "      fishing_info[\"area_id\"] = record[\"area_id\"]\n",
        "      fishing_info[\"area_name\"] = record[\"area_name\"]\n",
        "      fishing_info[\"bait_drop_id\"] = record[\"bait_drop_id\"][i]\n",
        "      fishing_info[\"bait_id\"] = bait\n",
        "      fishing_info[\"drop_id\"] = record[\"drop_id\"]\n",
        "      fishing_info[\"fish_energy\"] = record[\"fish_energy\"]\n",
        "      fishing_info[\"fish_exp\"] = record[\"fish_exp\"]\n",
        "      fishing_info[\"get_fish_cd\"] = record[\"get_fish_cd\"]\n",
        "      fishing_info[\"level_extra_drop\"] = record[\"level_extra_drop\"][0][\"Drop\"][0]\n",
        "      fishing_info[\"extra_drop\"] = record[\"extra_drop\"][j]\n",
        "      fishing_info[\"life_level_limit\"] = record[\"life_level_limit\"]\n",
        "\n",
        "      fishing_infos.append(fishing_info)\n",
        "\n",
        "fishing_info_df = pd.DataFrame(fishing_infos)"
      ],
      "metadata": {
        "id": "1IAc_yfOOPox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fishing_info_df = fishing_info_df[fishing_info_df[\"bait_drop_id\"] > 0]\n",
        "fishing_info_df = fishing_info_df[~fishing_info_df[\"life_level_limit\"].isnull()]"
      ],
      "metadata": {
        "id": "Bgb5jCFA4oYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fishing Pond Information"
      ],
      "metadata": {
        "id": "ysDyqPEi_FXX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YSexPHVXfll4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fishing_pond_df = fishing_info_df[[\"id\", \"area_id\", \"fish_energy\", \"fish_exp\", \"get_fish_cd\", \"level_extra_drop\", \"extra_drop\", \"life_level_limit\"]].drop_duplicates()\n",
        "fishing_pond_df = fishing_pond_df.rename(columns={\"area_id\": \"life_skill_area_id\"})\n",
        "\n",
        "intersections = set(fishing_pond_df[\"level_extra_drop\"].astype(float)).intersection(set(random_drop_main_df[\"id\"].astype(float)))\n",
        "fishing_pond_df = fishing_pond_df[fishing_pond_df[\"level_extra_drop\"].astype(float).isin(intersections)]\n",
        "\n",
        "intersections = set(fishing_pond_df[\"extra_drop\"].astype(float)).intersection(set(random_drop_main_df[\"id\"].astype(float)))\n",
        "fishing_pond_df = fishing_pond_df[fishing_pond_df[\"extra_drop\"].astype(float).isin(intersections)]\n",
        "\n",
        "fishing_pond_df = fishing_pond_df.rename(columns={\"level_extra_drop\": \"level_extra_drop_id\", \"extra_drop\": \"extra_drop_id\"})\n",
        "\n",
        "fishing_pond_df.to_csv(f\"{MAIN_PARSED_DIR}/fishing_pond_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "K-L-Xy1l6dq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fishing Pond Bait Drop Information"
      ],
      "metadata": {
        "id": "3UurIfvi_PQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fishing_pond_random_drop_df = fishing_info_df[[\"id\", \"bait_drop_id\", \"bait_id\", \"drop_id\"]].rename(columns={\"id\": \"fishing_pond_id\"}).reset_index().rename(columns={\"index\": \"id\"})\n",
        "\n",
        "intersections = set(fishing_pond_random_drop_df[\"bait_drop_id\"].astype(float)).intersection(set(random_drop_main_df[\"id\"].astype(float)))\n",
        "fishing_pond_random_drop_df = fishing_pond_random_drop_df[fishing_pond_random_drop_df[\"bait_drop_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "intersections = set(fishing_pond_random_drop_df[\"drop_id\"].astype(float)).intersection(set(random_drop_main_df[\"id\"].astype(float)))\n",
        "fishing_pond_random_drop_df = fishing_pond_random_drop_df[fishing_pond_random_drop_df[\"drop_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "intersections = set(fishing_pond_random_drop_df[\"bait_id\"].astype(float)).intersection(set(material_final_df[\"id\"].astype(float)))\n",
        "fishing_pond_random_drop_df = fishing_pond_random_drop_df[fishing_pond_random_drop_df[\"bait_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "fishing_pond_random_drop_df.to_csv(f\"{MAIN_PARSED_DIR}/fishing_pond_random_drop_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "1WRtqPRt5gDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mining"
      ],
      "metadata": {
        "id": "nv-vSRnh-GLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get data from Life Skill Area Drop"
      ],
      "metadata": {
        "id": "dpSZsQJj-GLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mining_df = life_skill_area_drop_df[~life_skill_area_drop_df[\"mine_level_energy\"].isnull()]\n",
        "mining_df = mining_df[mining_df[\"rich_mine_energy\"].apply(lambda x: len(x)) == 1]"
      ],
      "metadata": {
        "id": "J6iloHve-LTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mining_df = mining_df[[\"id\", \"area_id\", \"area_name\", \"extra_drop\", \"life_level_limit\", \"mine_level_energy\", \"get_mine_cd\", \"mine_level_limit\", \"mine_level_limit_drop_id\"]]\n",
        "\n",
        "for col in [\"mine_level_energy\", \"get_mine_cd\", \"mine_level_limit\", \"mine_level_limit_drop_id\"]:\n",
        "  mining_df[col] =   mining_df[col].apply(list).str[0]"
      ],
      "metadata": {
        "id": "x481sZuqGWqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "QuSEyRvyGDZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mining_df[\"area_id\"] = mining_df[\"area_id\"].str.replace(\"Areaname\", \"\").apply(int)\n",
        "\n",
        "mining_infos = []\n",
        "for record in mining_df.to_dict(orient=\"records\"):\n",
        "    for j, extra_drop in enumerate(record[\"extra_drop\"]):\n",
        "      mining_info = {}\n",
        "      mining_info[\"id\"] = record[\"id\"]\n",
        "      mining_info[\"area_id\"] = record[\"area_id\"]\n",
        "      mining_info[\"area_name\"] = record[\"area_name\"]\n",
        "      mining_info[\"extra_drop\"] = record[\"extra_drop\"][j]\n",
        "      mining_info[\"mine_level_limit\"] = record[\"mine_level_limit\"]\n",
        "      mining_info[\"mine_level_energy\"] = record[\"mine_level_energy\"]\n",
        "      mining_info[\"mine_exp\"] = record[\"mine_level_energy\"]\n",
        "      mining_info[\"get_mine_cd\"] = record[\"get_mine_cd\"]\n",
        "      mining_info[\"drop_id\"] = record[\"mine_level_limit_drop_id\"]\n",
        "      \n",
        "\n",
        "      mining_infos.append(mining_info)\n",
        "\n",
        "mining_info_df = pd.DataFrame(mining_infos)"
      ],
      "metadata": {
        "id": "wh6h4DrLGDZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mining Ore Information"
      ],
      "metadata": {
        "id": "lgeUqtWJIMpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mining_ore_df = mining_info_df[[\"id\", \"area_id\", \"mine_level_energy\", \"mine_exp\", \"get_mine_cd\", \"drop_id\", \"mine_level_limit\"]].drop_duplicates()\n",
        "mining_ore_df = mining_ore_df.rename(columns={\"area_id\": \"life_skill_area_id\"})\n",
        "\n",
        "intersections = set(mining_ore_df[\"drop_id\"].astype(float)).intersection(set(random_drop_main_df[\"id\"].astype(float)))\n",
        "mining_ore_df = mining_ore_df[mining_ore_df[\"drop_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "mining_ore_df.to_csv(f\"{MAIN_PARSED_DIR}/mining_ore_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "pScF9egwIMpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mining Ore Extra Drop"
      ],
      "metadata": {
        "id": "mc_Y6Uk1ULuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mining_ore_extra_drop_df = mining_info_df[[\"id\", \"extra_drop\"]].rename(columns={\"id\": \"mining_ore_id\", \"extra_drop\": \"extra_drop_id\"}).reset_index().rename(columns={\"index\": \"id\"})\n",
        "\n",
        "intersections = set(mining_ore_extra_drop_df[\"extra_drop_id\"].astype(float)).intersection(set(random_drop_main_df[\"id\"].astype(float)))\n",
        "mining_ore_extra_drop_df = mining_ore_extra_drop_df[mining_ore_extra_drop_df[\"extra_drop_id\"].astype(float).isin(intersections)]\n",
        "\n",
        "mining_ore_extra_drop_df.to_csv(f\"{MAIN_PARSED_DIR}/mining_ore_extra_drop_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "5NpYcJ25Sn7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HcIS0CMqg9xJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bapho Raid"
      ],
      "metadata": {
        "id": "VQ1Pay4rdvVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize fixed variable"
      ],
      "metadata": {
        "id": "NghkOs4jePk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data_raid_RaidInstance.bytes\n",
        "\n",
        "party_rewards = [\n",
        "  209011,\n",
        "  209012,\n",
        "  209013,\n",
        "  209014,\n",
        "  209015,\n",
        "  209027,\n",
        "  209028,\n",
        "]\n",
        "\n",
        "individual_rewards = [\n",
        "  209016,\n",
        "  209017,\n",
        "  209018,\n",
        "  209019,\n",
        "  209020,\n",
        "  209021,\n",
        "  209022,\n",
        "  209023,\n",
        "  209024,\n",
        "  209025,\n",
        "  209026\n",
        "]\n",
        "\n",
        "team_rewards = [\n",
        "  209006,\n",
        "  209007,\n",
        "  209008,\n",
        "  209009,\n",
        "  209010,\n",
        "]"
      ],
      "metadata": {
        "id": "SZe3ZNMkd02T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create DataFrame for drop and save it for database"
      ],
      "metadata": {
        "id": "h6GGVkjtiG6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "complex_baphomet_drop_df = pd.DataFrame({\"drop_id\": individual_rewards, \"reward_type\": 1})\n",
        "baphomet_party_drop_df = pd.DataFrame({\"drop_id\": party_rewards, \"reward_type\": 2})\n",
        "baphomet_team_drop_df = pd.DataFrame({\"drop_id\": party_rewards, \"reward_type\": 3})\n",
        "\n",
        "complex_baphomet_drop_df = complex_baphomet_drop_df.append(baphomet_party_drop_df, ignore_index=True)\n",
        "complex_baphomet_drop_df = complex_baphomet_drop_df.append(baphomet_team_drop_df, ignore_index=True)\n",
        "complex_baphomet_drop_df = complex_baphomet_drop_df.reset_index().rename(columns={\"index\": \"id\"})\n",
        "\n",
        "intersections = set(complex_baphomet_drop_df[\"drop_id\"].astype(int)).intersection(set(random_drop_main_df[\"id\"].astype(int)))\n",
        "complex_baphomet_drop_df = complex_baphomet_drop_df[complex_baphomet_drop_df[\"drop_id\"].astype(int).isin(intersections)]\n",
        "\n",
        "complex_baphomet_drop_df.to_csv(f\"{MAIN_PARSED_DIR}/baphomet_random_drop_{APK_DATE}.csv\", index=False)"
      ],
      "metadata": {
        "id": "iyp1CvBahAYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create DataFrame for information"
      ],
      "metadata": {
        "id": "Nb8zsQpWjVRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bapho_rules = \"Opening Time:\\nAll day\\n\\nEntry Requirements:\\n1. Adventurers can enter the Illusion Trial after completing the tutorial quest [Named Hero], and a corresponding Illusion Key is required.\\n2. Each time the Illusion Trial is cleared, a Illusion Key will be consumed. Every Monday at 05:00, the Illusion Keys obtained last week will be destroyed.\\n3. Adventurers can go to the Librarian Winry at the Geffen Library to access the Illusion Exchange Bureau, where they can exchange or purchase Illusion Keys and other Illusion Trial related items.\\n4. Adventurers can form a team to challenge the Illusion Trial. The team formed will be divided into 3 parties, with a maximum of 5 people per party.\\n5. There is a crystal ball at the entrance of the Illusion Trial, and Adventurers can summon their teammates to this place. Teammates who are in instances or special maps cannot be summoned.\\n6. The team members who newly enter the Illusion Trial will synchronize the current Illusion Trial progress.\\n\\nReward Rules:\\n1. Individual Reward: Adventurers will get rewards every time they clear the Illusion Trial.\\n2. Party Reward: Adventurers can tap the items they need in the ornate chests dropped by the BOSS and roll the dice. Adventurers with the highest number of dice in the party will get the item. The rewards of each chest differs and can only be shared by the party members.\\n3. Team Reward: After clearing the Illusion Trial, there is a chance that the Black Market Merchant will appear and issue rewards. The rewards will be unlocked by using the Illusion Certificates, and the rewards will be assigned according to the number of the Illusion Certificates given. Adventurers who do not get the rewards will reclaim the Illusion Certificates given by them previously.\\n4. Reward chances will be reset every Monday at 05:00. Each week, Adventurers can get a maximum of 1 individual reward, 1 party reward, and 1 team reward.\\n\\nCombat Rules:\\n1. When less than 15 Adventurers enter the Illusion Trial, the attributes and stats of the monsters will be increased. The fewer Adventurers enter the Illusion, the stronger the monsters will be!\\n2. In the Illusion Trial, Adventurers’ Damage and Damage Taken will be modified in line with the standard level of the Illusion.\\n3. Adventurers who die after entering the battle state cannot be resurrected immediately, they need to wait for the resurrection button to light up after the whole party/team is destroyed.\\n4. Adventurers who die more than 2x in the battle state be restricted from resurrecting, and cannot be resurrected by skills or items as well. Adventurers’ deaths will be reset after resurrection.\\n5. Players cannot use skills to play dead in the Illusion Trial.\""
      ],
      "metadata": {
        "id": "VIIV5G8yl8Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bapho_rules = bapho_rules.replace(\"\\n\", \"<br>\")"
      ],
      "metadata": {
        "id": "tmfPrDkMl_ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shadow Weapon"
      ],
      "metadata": {
        "id": "y6OIA4U7a2XR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "Y2Ls5mRia2Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "LIMIT = 999999\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_ShadowWeapon_ShadowWeapon.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for i, text in enumerate(filename.readlines()):\n",
        "    if i == LIMIT:\n",
        "      break\n",
        "    else:\n",
        "      texts.append(text.strip())\n",
        "    \n",
        "texts = \" \".join(texts)\n",
        "\n",
        "texts = re.sub(r'\\[([\\w\\\"]+)\\] =', '\\g<1>:', texts)\n",
        "texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\{([\\d\\, ]+)\\}', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "texts = texts.replace(\"{ {\", \"AAAAA\")\n",
        "texts = texts.replace(\"}, }, },\", \"BBBBB\")\n",
        "texts = texts.replace(\"}, }, {\", \"DDDDD\")\n",
        "texts = re.sub(r'\\}, \\}, (\\d)', 'FFFFF \\g<1>', texts)\n",
        "texts = re.sub(r'\\}, \\},$', 'EEEEE', texts)\n",
        "texts = texts.replace(\"}, },\", \"CCCCC\")\n",
        "\n",
        "texts = texts.replace(\"AAAAA\", \"[ {\")\n",
        "texts = texts.replace(\"BBBBB\", \"}, ], },\")\n",
        "texts = texts.replace(\"CCCCC\", \"}, ],\")\n",
        "texts = texts.replace(\"DDDDD\", \"}, }, {\")\n",
        "texts = texts.replace(\"EEEEE\", \"}, },\")\n",
        "texts = texts.replace(\"FFFFF\", \"}, }, \")\n",
        "\n",
        "texts = \"{\" + texts + \"}\"\n",
        "\n",
        "shadow_equipments = literal_eval(texts)"
      ],
      "metadata": {
        "id": "Tt1jyHUwa2Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "stiaDpj7a2Xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shadow_equipment_entries = []\n",
        "\n",
        "for id, parsed_dict in shadow_equipments.items():\n",
        "  shadow_equipment_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"id\": \"Id\",\n",
        "      \"artifact_name\": \"ArtifactName\",\n",
        "      \"class_branch\": \"ClassBranch\",\n",
        "      \"cost_item_id\": \"CostItemId\",\n",
        "      \"cost_num\": \"CostNum\",\n",
        "      \"cost_type\": \"CostType\",\n",
        "      \"job\": \"Job\",\n",
        "      \"name\": \"Name\",\n",
        "      \"require_weapon_type\": \"RequireWeaponType\",\n",
        "  }\n",
        "\n",
        "  shadow_equipment_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      shadow_equipment_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  shadow_equipment_entries.append(shadow_equipment_entry)\n",
        "\n",
        "shadow_equipment_df = pd.DataFrame(shadow_equipment_entries)"
      ],
      "metadata": {
        "id": "PhL9C6WKa2Xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shadow Weapon Prop"
      ],
      "metadata": {
        "id": "nR5CnAnchQ2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "NYWNNrPnhQ2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "LIMIT = 999999\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_ShadowWeapon_ShadowWeaponProp.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for i, text in enumerate(filename.readlines()):\n",
        "    if i == LIMIT:\n",
        "      break\n",
        "    else:\n",
        "      texts.append(text.strip())\n",
        "    \n",
        "texts = \" \".join(texts)\n",
        "\n",
        "texts = re.sub(r'\\[([\\w\\\"]+)\\] =', '\\g<1>:', texts)\n",
        "texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\{([\\d\\, ]+)\\}', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "texts = texts.replace(\"{ {\", \"AAAAA\")\n",
        "texts = texts.replace(\"}, }, },\", \"BBBBB\")\n",
        "texts = texts.replace(\"}, }, {\", \"DDDDD\")\n",
        "texts = re.sub(r'\\}, \\}, (\\d)', 'FFFFF \\g<1>', texts)\n",
        "texts = re.sub(r'\\}, \\},$', 'EEEEE', texts)\n",
        "texts = texts.replace(\"}, },\", \"CCCCC\")\n",
        "\n",
        "texts = texts.replace(\"AAAAA\", \"[ {\")\n",
        "texts = texts.replace(\"BBBBB\", \"}, ], },\")\n",
        "texts = texts.replace(\"CCCCC\", \"}, ],\")\n",
        "texts = texts.replace(\"DDDDD\", \"}, }, {\")\n",
        "texts = texts.replace(\"EEEEE\", \"}, },\")\n",
        "texts = texts.replace(\"FFFFF\", \"}, }, \")\n",
        "\n",
        "texts = \"{\" + texts + \"}\"\n",
        "\n",
        "shadow_equipment_skills = literal_eval(texts)"
      ],
      "metadata": {
        "id": "Wl6ci0o4hQ2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "WuN0PY0rhQ2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shadow_equipment_skill_entries = []\n",
        "\n",
        "for id, parsed_dict in shadow_equipment_skills.items():\n",
        "  shadow_equipment_skill_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"artifact_cost_item_id\": \"ArtifactCostItemId\",\n",
        "      \"artifact_cost_num\": \"ArtifactCostNum\",\n",
        "      \"artifact_cost_type\": \"ArtifactCostType\",\n",
        "      \"prop_group\": \"PropGroup\",\n",
        "      \"shadow_weapon_level_limit_list\": \"ShadowWeaponLevelLimitList\",\n",
        "      \"shadow_weapon_level_skill_id\": \"ShadowWeaponSkillId\",\n",
        "      \"skill_open_level\": \"SkillOpenLevel\",\n",
        "  }\n",
        "\n",
        "  shadow_equipment_skill_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      shadow_equipment_skill_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  shadow_equipment_skill_entries.append(shadow_equipment_skill_entry)\n",
        "\n",
        "shadow_equipment_skill_df = pd.DataFrame(shadow_equipment_skill_entries)"
      ],
      "metadata": {
        "id": "0dxllwD5hQ2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shadow_equipment_skill_df[\"skill_open_level\"] = shadow_equipment_skill_df[\"skill_open_level\"].fillna(1)"
      ],
      "metadata": {
        "id": "Oda73W-phQ2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shadow Weapon Skill"
      ],
      "metadata": {
        "id": "AQ6WJyqQeEv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "3HzgDvTeeEv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "LIMIT = 999999\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_ShadowWeapon_ShadowWeaponSkill.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for i, text in enumerate(filename.readlines()):\n",
        "    if i == LIMIT:\n",
        "      break\n",
        "    else:\n",
        "      texts.append(text.strip())\n",
        "    \n",
        "texts = \" \".join(texts)\n",
        "\n",
        "texts = re.sub(r'\\[([\\w\\\"]+)\\] =', '\\g<1>:', texts)\n",
        "texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\{([\\d\\, ]+)\\}', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "texts = texts.replace(\"{ {\", \"AAAAA\")\n",
        "texts = texts.replace(\"}, }, },\", \"BBBBB\")\n",
        "texts = texts.replace(\"}, }, {\", \"DDDDD\")\n",
        "texts = re.sub(r'\\}, \\}, (\\d)', 'FFFFF \\g<1>', texts)\n",
        "texts = re.sub(r'\\}, \\},$', 'EEEEE', texts)\n",
        "texts = texts.replace(\"}, },\", \"CCCCC\")\n",
        "\n",
        "texts = texts.replace(\"AAAAA\", \"[ {\")\n",
        "texts = texts.replace(\"BBBBB\", \"}, ], },\")\n",
        "texts = texts.replace(\"CCCCC\", \"}, ],\")\n",
        "texts = texts.replace(\"DDDDD\", \"}, }, {\")\n",
        "texts = texts.replace(\"EEEEE\", \"}, },\")\n",
        "texts = texts.replace(\"FFFFF\", \"}, }, \")\n",
        "\n",
        "texts = \"{\" + texts + \"}\"\n",
        "\n",
        "shadow_equipment_skills = literal_eval(texts)"
      ],
      "metadata": {
        "id": "7ekinnwCeEv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "vGdncYoReEv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shadow_equipment_skill_entries = []\n",
        "\n",
        "for id, parsed_dict in shadow_equipment_skills.items():\n",
        "  shadow_equipment_skill_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"artifact_cost_item_id\": \"ArtifactCostItemId\",\n",
        "      \"artifact_cost_num\": \"ArtifactCostNum\",\n",
        "      \"artifact_cost_type\": \"ArtifactCostType\",\n",
        "      \"prop_group\": \"PropGroup\",\n",
        "      \"shadow_weapon_level_limit_list\": \"ShadowWeaponLevelLimitList\",\n",
        "      \"shadow_weapon_level_skill_id\": \"ShadowWeaponSkillId\",\n",
        "      \"skill_open_level\": \"SkillOpenLevel\",\n",
        "  }\n",
        "\n",
        "  shadow_equipment_skill_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      shadow_equipment_skill_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  shadow_equipment_skill_entries.append(shadow_equipment_skill_entry)\n",
        "\n",
        "shadow_equipment_skill_df = pd.DataFrame(shadow_equipment_skill_entries)"
      ],
      "metadata": {
        "id": "1g-A4qoKeEwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shadow_equipment_skill_df[\"skill_open_level\"] = shadow_equipment_skill_df[\"skill_open_level\"].fillna(1)"
      ],
      "metadata": {
        "id": "gY4f5PxVe6Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shadow Weapon Skill Group"
      ],
      "metadata": {
        "id": "SLmVzNz0e8_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "DC9-i5mKe8_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "LIMIT = 999999\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_ShadowWeapon_ShadowWeaponSkillGroup.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for i, text in enumerate(filename.readlines()):\n",
        "    if i == LIMIT:\n",
        "      break\n",
        "    else:\n",
        "      texts.append(text.strip())\n",
        "    \n",
        "texts = \" \".join(texts)\n",
        "\n",
        "texts = re.sub(r'\\[([\\w\\\"]+)\\] =', '\\g<1>:', texts)\n",
        "texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\{([\\d\\, ]+)\\}', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "texts = texts.replace(\"{ {\", \"AAAAA\")\n",
        "texts = texts.replace(\"}, }, },\", \"BBBBB\")\n",
        "texts = texts.replace(\"}, }, {\", \"DDDDD\")\n",
        "texts = re.sub(r'\\}, \\}, (\\d)', 'FFFFF \\g<1>', texts)\n",
        "texts = re.sub(r'\\}, \\},$', 'EEEEE', texts)\n",
        "texts = texts.replace(\"}, },\", \"CCCCC\")\n",
        "\n",
        "texts = texts.replace(\"AAAAA\", \"[ {\")\n",
        "texts = texts.replace(\"BBBBB\", \"}, ], },\")\n",
        "texts = texts.replace(\"CCCCC\", \"}, ],\")\n",
        "texts = texts.replace(\"DDDDD\", \"}, }, {\")\n",
        "texts = texts.replace(\"EEEEE\", \"}, },\")\n",
        "texts = texts.replace(\"FFFFF\", \"}, }, \")\n",
        "\n",
        "texts = \"{\" + texts + \"}\"\n",
        "\n",
        "shadow_equipment_skill_groups = literal_eval(texts)"
      ],
      "metadata": {
        "id": "XdyYmVO4e8__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shadow_equipment_skill_groups[707]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAhjnKSwfFMl",
        "outputId": "0164c11c-f1e9-4cbd-cdad-72f0dffd4409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'GroupName': 'ShadowWeaponSkillGroup_007',\n",
              " 'Id': 707,\n",
              " 'Name': '坚锤羽盾-器灵',\n",
              " 'ShadowWeaponSkillIdList': [12000129, 12000130, 12000131, 12000132]}"
            ]
          },
          "metadata": {},
          "execution_count": 317
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "G5a6xHSme9AA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shadow_equipment_skill_group_entries = []\n",
        "\n",
        "for id, parsed_dict in shadow_equipment_skills.items():\n",
        "  shadow_equipment_skill_group_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"id\": \"Id\",\n",
        "      \"group_name\": \"GroupName\",\n",
        "      \"name\": \"Name\",\n",
        "      \"shadow_weapon_skill_id_list\": \"ShadowWeaponSkillIdList\",\n",
        "\n",
        "  }\n",
        "\n",
        "  shadow_equipment_skill_group_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      shadow_equipment_skill_group_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  shadow_equipment_skill_group_entries.append(shadow_equipment_skill_group_entry)\n",
        "\n",
        "shadow_equipment_skill_group_df = pd.DataFrame(shadow_equipment_skill_group_entries)"
      ],
      "metadata": {
        "id": "cuA5yBKQe9AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shadow Weapon Skill Group"
      ],
      "metadata": {
        "id": "M0VCKuY3gGaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parse data"
      ],
      "metadata": {
        "id": "WnDObQkxgGaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "\n",
        "LIMIT = 999999\n",
        "with open(f\"{MAIN_CLEANED_DIR}/data_ShadowWeapon_ShadowWeaponSkillGroup.bytes\", \"r\", encoding=\"utf8\") as filename:\n",
        "  for i, text in enumerate(filename.readlines()):\n",
        "    if i == LIMIT:\n",
        "      break\n",
        "    else:\n",
        "      texts.append(text.strip())\n",
        "    \n",
        "texts = \" \".join(texts)\n",
        "\n",
        "texts = re.sub(r'\\[([\\w\\\"]+)\\] =', '\\g<1>:', texts)\n",
        "texts = re.sub(r'{ ([\\d,]+) }', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\{([\\d\\, ]+)\\}', '[\\g<1>]', texts)\n",
        "texts = re.sub(r'\\:\\{([\\d\\,\\ ]+)\\}', ':[\\g<1>]', texts)\n",
        "\n",
        "texts = texts.replace(\"{ {\", \"AAAAA\")\n",
        "texts = texts.replace(\"}, }, },\", \"BBBBB\")\n",
        "texts = texts.replace(\"}, }, {\", \"DDDDD\")\n",
        "texts = re.sub(r'\\}, \\}, (\\d)', 'FFFFF \\g<1>', texts)\n",
        "texts = re.sub(r'\\}, \\},$', 'EEEEE', texts)\n",
        "texts = texts.replace(\"}, },\", \"CCCCC\")\n",
        "\n",
        "texts = texts.replace(\"AAAAA\", \"[ {\")\n",
        "texts = texts.replace(\"BBBBB\", \"}, ], },\")\n",
        "texts = texts.replace(\"CCCCC\", \"}, ],\")\n",
        "texts = texts.replace(\"DDDDD\", \"}, }, {\")\n",
        "texts = texts.replace(\"EEEEE\", \"}, },\")\n",
        "texts = texts.replace(\"FFFFF\", \"}, }, \")\n",
        "\n",
        "texts = \"{\" + texts + \"}\"\n",
        "\n",
        "shadow_equipment_skill_groups = literal_eval(texts)"
      ],
      "metadata": {
        "id": "_gvbFlyXgGaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shadow_equipment_skill_groups[707]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0164c11c-f1e9-4cbd-cdad-72f0dffd4409",
        "id": "3RzeKgTngGaO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'GroupName': 'ShadowWeaponSkillGroup_007',\n",
              " 'Id': 707,\n",
              " 'Name': '坚锤羽盾-器灵',\n",
              " 'ShadowWeaponSkillIdList': [12000129, 12000130, 12000131, 12000132]}"
            ]
          },
          "metadata": {},
          "execution_count": 317
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create entries for DataFrame creation"
      ],
      "metadata": {
        "id": "iOmO3MsigGaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shadow_equipment_skill_group_entries = []\n",
        "\n",
        "for id, parsed_dict in shadow_equipment_skills.items():\n",
        "  shadow_equipment_skill_group_entry = {}\n",
        "\n",
        "  default_key_dict = {\n",
        "      \"id\": \"Id\",\n",
        "      \"group_name\": \"GroupName\",\n",
        "      \"name\": \"Name\",\n",
        "      \"shadow_weapon_skill_id_list\": \"ShadowWeaponSkillIdList\",\n",
        "\n",
        "  }\n",
        "\n",
        "  shadow_equipment_skill_group_entry[\"id\"] = id\n",
        "  for col, def_key in default_key_dict.items():\n",
        "    try:\n",
        "      shadow_equipment_skill_group_entry[col] = parsed_dict[def_key]\n",
        "    except:\n",
        "      pass\n",
        "  shadow_equipment_skill_group_entries.append(shadow_equipment_skill_group_entry)\n",
        "\n",
        "shadow_equipment_skill_group_df = pd.DataFrame(shadow_equipment_skill_group_entries)"
      ],
      "metadata": {
        "id": "Hc2X4cmugGaS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}